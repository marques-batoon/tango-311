{"ast":null,"code":"import React from 'react';\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n    enumerableOnly && (symbols = symbols.filter(function (sym) {\n      return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n    })), keys.push.apply(keys, symbols);\n  }\n  return keys;\n}\nfunction _objectSpread2(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = null != arguments[i] ? arguments[i] : {};\n    i % 2 ? ownKeys(Object(source), !0).forEach(function (key) {\n      _defineProperty(target, key, source[key]);\n    }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) {\n      Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n    });\n  }\n  return target;\n}\nfunction _defineProperty(obj, key, value) {\n  if (key in obj) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n  } else {\n    obj[key] = value;\n  }\n  return obj;\n}\nfunction _extends() {\n  _extends = Object.assign || function (target) {\n    for (var i = 1; i < arguments.length; i++) {\n      var source = arguments[i];\n      for (var key in source) {\n        if (Object.prototype.hasOwnProperty.call(source, key)) {\n          target[key] = source[key];\n        }\n      }\n    }\n    return target;\n  };\n  return _extends.apply(this, arguments);\n}\nfunction _objectWithoutPropertiesLoose(source, excluded) {\n  if (source == null) return {};\n  var target = {};\n  var sourceKeys = Object.keys(source);\n  var key, i;\n  for (i = 0; i < sourceKeys.length; i++) {\n    key = sourceKeys[i];\n    if (excluded.indexOf(key) >= 0) continue;\n    target[key] = source[key];\n  }\n  return target;\n}\nfunction _objectWithoutProperties(source, excluded) {\n  if (source == null) return {};\n  var target = _objectWithoutPropertiesLoose(source, excluded);\n  var key, i;\n  if (Object.getOwnPropertySymbols) {\n    var sourceSymbolKeys = Object.getOwnPropertySymbols(source);\n    for (i = 0; i < sourceSymbolKeys.length; i++) {\n      key = sourceSymbolKeys[i];\n      if (excluded.indexOf(key) >= 0) continue;\n      if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue;\n      target[key] = source[key];\n    }\n  }\n  return target;\n}\nfunction _slicedToArray(arr, i) {\n  return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest();\n}\nfunction _toArray(arr) {\n  return _arrayWithHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableRest();\n}\nfunction _toConsumableArray(arr) {\n  return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread();\n}\nfunction _arrayWithoutHoles(arr) {\n  if (Array.isArray(arr)) return _arrayLikeToArray(arr);\n}\nfunction _arrayWithHoles(arr) {\n  if (Array.isArray(arr)) return arr;\n}\nfunction _iterableToArray(iter) {\n  if (typeof Symbol !== \"undefined\" && iter[Symbol.iterator] != null || iter[\"@@iterator\"] != null) return Array.from(iter);\n}\nfunction _iterableToArrayLimit(arr, i) {\n  var _i = arr == null ? null : typeof Symbol !== \"undefined\" && arr[Symbol.iterator] || arr[\"@@iterator\"];\n  if (_i == null) return;\n  var _arr = [];\n  var _n = true;\n  var _d = false;\n  var _s, _e;\n  try {\n    for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) {\n      _arr.push(_s.value);\n      if (i && _arr.length === i) break;\n    }\n  } catch (err) {\n    _d = true;\n    _e = err;\n  } finally {\n    try {\n      if (!_n && _i[\"return\"] != null) _i[\"return\"]();\n    } finally {\n      if (_d) throw _e;\n    }\n  }\n  return _arr;\n}\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return _arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen);\n}\nfunction _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n  for (var i = 0, arr2 = new Array(len); i < len; i++) arr2[i] = arr[i];\n  return arr2;\n}\nfunction _nonIterableSpread() {\n  throw new TypeError(\"Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\nfunction _nonIterableRest() {\n  throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\n\n/**\n * Returns detailed type as string (instead of just 'object' for arrays etc)\n * @private\n * @param {any} value js value\n * @returns {String} type of value\n * @example\n * typeOf({}); // 'object'\n * typeOf([]); // 'array'\n * typeOf(function() {}); // 'function'\n * typeOf(/a/); // 'regexp'\n * typeOf(new Date()); // 'date'\n * typeOf(null); // 'null'\n * typeOf(undefined); // 'undefined'\n * typeOf('a'); // 'string'\n * typeOf(1); // 'number'\n * typeOf(true); // 'boolean'\n * typeOf(new Map()); // 'map'\n * typeOf(new Set()); // 'map'\n */\nfunction typeOf(value) {\n  if (value === null) {\n    return 'null';\n  }\n  if (value !== Object(value)) {\n    return typeof value;\n  }\n  return {}.toString.call(value).slice(8, -1).toLowerCase();\n}\n\n/**\n * Checks if input string is empty\n * @param  {String} input text input\n * @return {Boolean} true if no input\n */\nfunction isEmpty(input) {\n  if (typeOf(input) !== 'string') {\n    return true;\n  }\n  return !input.length;\n}\n\n/**\n * Takes a character and a unicode range. Returns true if the char is in the range.\n * @param  {String}  char  unicode character\n * @param  {Number}  start unicode start range\n * @param  {Number}  end   unicode end range\n * @return {Boolean}\n */\nfunction isCharInRange(char = '', start, end) {\n  if (isEmpty(char)) return false;\n  const code = char.charCodeAt(0);\n  return start <= code && code <= end;\n}\nconst LOWERCASE_ZENKAKU_START = 0xff41;\nconst LOWERCASE_ZENKAKU_END = 0xff5a;\nconst UPPERCASE_ZENKAKU_START = 0xff21;\nconst UPPERCASE_ZENKAKU_END = 0xff3a;\nconst HIRAGANA_START = 0x3041;\nconst HIRAGANA_END = 0x3096;\nconst KATAKANA_START = 0x30a1;\nconst KATAKANA_END = 0x30fc;\nconst KANJI_START = 0x4e00;\nconst KANJI_END = 0x9faf;\nconst KANJI_ITERATION_MARK = 0x3005; // „ÄÖ\nconst PROLONGED_SOUND_MARK = 0x30fc; // „Éº\n\nconst ZENKAKU_NUMBERS = [0xff10, 0xff19];\nconst ZENKAKU_UPPERCASE = [UPPERCASE_ZENKAKU_START, UPPERCASE_ZENKAKU_END];\nconst ZENKAKU_LOWERCASE = [LOWERCASE_ZENKAKU_START, LOWERCASE_ZENKAKU_END];\nconst ZENKAKU_PUNCTUATION_1 = [0xff01, 0xff0f];\nconst ZENKAKU_PUNCTUATION_2 = [0xff1a, 0xff1f];\nconst ZENKAKU_PUNCTUATION_3 = [0xff3b, 0xff3f];\nconst ZENKAKU_PUNCTUATION_4 = [0xff5b, 0xff60];\nconst ZENKAKU_SYMBOLS_CURRENCY = [0xffe0, 0xffee];\nconst HIRAGANA_CHARS = [0x3040, 0x309f];\nconst KATAKANA_CHARS = [0x30a0, 0x30ff];\nconst HANKAKU_KATAKANA = [0xff66, 0xff9f];\nconst KATAKANA_PUNCTUATION = [0x30fb, 0x30fc];\nconst KANA_PUNCTUATION = [0xff61, 0xff65];\nconst CJK_SYMBOLS_PUNCTUATION = [0x3000, 0x303f];\nconst COMMON_CJK = [0x4e00, 0x9fff];\nconst RARE_CJK = [0x3400, 0x4dbf];\nconst KANA_RANGES = [HIRAGANA_CHARS, KATAKANA_CHARS, KANA_PUNCTUATION, HANKAKU_KATAKANA];\nconst JA_PUNCTUATION_RANGES = [CJK_SYMBOLS_PUNCTUATION, KANA_PUNCTUATION, KATAKANA_PUNCTUATION, ZENKAKU_PUNCTUATION_1, ZENKAKU_PUNCTUATION_2, ZENKAKU_PUNCTUATION_3, ZENKAKU_PUNCTUATION_4, ZENKAKU_SYMBOLS_CURRENCY];\n\n// All Japanese unicode start and end ranges\n// Includes kanji, kana, zenkaku latin chars, punctuation, and number ranges.\nconst JAPANESE_RANGES = [...KANA_RANGES, ...JA_PUNCTUATION_RANGES, ZENKAKU_UPPERCASE, ZENKAKU_LOWERCASE, ZENKAKU_NUMBERS, COMMON_CJK, RARE_CJK];\nconst MODERN_ENGLISH = [0x0000, 0x007f];\nconst HEPBURN_MACRON_RANGES = [[0x0100, 0x0101],\n// ƒÄ ƒÅ\n[0x0112, 0x0113],\n// ƒí ƒì\n[0x012a, 0x012b],\n// ƒ™ ƒ´\n[0x014c, 0x014d],\n// ≈å ≈ç\n[0x016a, 0x016b] // ≈™ ≈´\n];\n\nconst SMART_QUOTE_RANGES = [[0x2018, 0x2019],\n// ‚Äò ‚Äô\n[0x201c, 0x201d] // ‚Äú ‚Äù\n];\n\nconst ROMAJI_RANGES = [MODERN_ENGLISH, ...HEPBURN_MACRON_RANGES];\nconst EN_PUNCTUATION_RANGES = [[0x20, 0x2f], [0x3a, 0x3f], [0x5b, 0x60], [0x7b, 0x7e], ...SMART_QUOTE_RANGES];\n\n/**\n * Tests a character. Returns true if the character is [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharJapanese(char = '') {\n  return JAPANESE_RANGES.some(([start, end]) => isCharInRange(char, start, end));\n}\n\n/**\n * Test if `input` only includes [Kanji](https://en.wikipedia.org/wiki/Kanji), [Kana](https://en.wikipedia.org/wiki/Kana), zenkaku numbers, and JA punctuation/symbols.‚Äù\n * @param  {String} [input=''] text\n * @param  {Regexp} [allowed] additional test allowed to pass for each char\n * @return {Boolean} true if passes checks\n * @example\n * isJapanese('Ê≥£„ÅçËô´')\n * // => true\n * isJapanese('„ÅÇ„Ç¢')\n * // => true\n * isJapanese('ÔºíÊúà') // Zenkaku numbers allowed\n * // => true\n * isJapanese('Ê≥£„ÅçËô´„ÄÇÔºÅ„ÄúÔºÑ') // Zenkaku/JA punctuation\n * // => true\n * isJapanese('Ê≥£„ÅçËô´.!~$') // Latin punctuation fails\n * // => false\n * isJapanese('AÊ≥£„ÅçËô´')\n * // => false\n * isJapanese('‚â™ÂÅΩÊã¨Âºß‚â´', /[‚â™‚â´]/);\n * // => true\n */\nfunction isJapanese(input = '', allowed) {\n  const augmented = typeOf(allowed) === 'regexp';\n  return isEmpty(input) ? false : [...input].every(char => {\n    const isJa = isCharJapanese(char);\n    return !augmented ? isJa : isJa || allowed.test(char);\n  });\n}\n\n/**\n * Creates a custom mapping tree, returns a function that accepts a defaultMap which the newly created customMapping will be merged with and returned\n * (customMap) => (defaultMap) => mergedMap\n * @param  {Object} customMap { 'ka' : '„Å™' }\n * @return {Function} (defaultMap) => defaultMergedWithCustomMap\n * @example\n * const sillyMap = createCustomMapping({ '„Å°„ÇÉ': 'time', 'Ëåé': 'cookie'„ÄÄ});\n * // sillyMap is passed defaultMapping to merge with when called in toRomaji()\n * toRomaji(\"It's Ëåé „Å°„ÇÉ „Çà\", { customRomajiMapping: sillyMap });\n * // => 'It's cookie time yo';\n */\nfunction createCustomMapping(customMap = {}) {\n  const customTree = {};\n  if (typeOf(customMap) === 'object') {\n    Object.entries(customMap).forEach(([roma, kana]) => {\n      let subTree = customTree;\n      roma.split('').forEach(char => {\n        if (subTree[char] === undefined) {\n          subTree[char] = {};\n        }\n        subTree = subTree[char];\n      });\n      subTree[''] = kana;\n    });\n  }\n  return function makeMap(map) {\n    const mapCopy = JSON.parse(JSON.stringify(map));\n    function transformMap(mapSubtree, customSubtree) {\n      if (mapSubtree === undefined || typeOf(mapSubtree) === 'string') {\n        return customSubtree;\n      }\n      return Object.entries(customSubtree).reduce((newSubtree, [char, subtree]) => {\n        // eslint-disable-next-line no-param-reassign\n        newSubtree[char] = transformMap(mapSubtree[char], subtree);\n        return newSubtree;\n      }, mapSubtree);\n    }\n    return transformMap(mapCopy, customTree);\n  };\n}\nconst SMALL_Y$1 = {\n  ya: '„ÇÉ',\n  yi: '„ÅÉ',\n  yu: '„ÇÖ',\n  ye: '„Åá',\n  yo: '„Çá'\n};\nconst SMALL_VOWELS = {\n  a: '„ÅÅ',\n  i: '„ÅÉ',\n  u: '„ÅÖ',\n  e: '„Åá',\n  o: '„Åâ'\n};\n\n// xtu -> „Å£\nObject.assign({\n  tu: '„Å£',\n  wa: '„Çé',\n  ka: '„Éµ',\n  ke: '„É∂'\n}, SMALL_VOWELS, SMALL_Y$1);\ncreateCustomMapping({\n  wi: '„Çê',\n  we: '„Çë'\n});\n\n/**\n * Returns true if char is '„Éº'\n * @param  {String} char to test\n * @return {Boolean}\n */\nfunction isCharLongDash(char = '') {\n  if (isEmpty(char)) return false;\n  return char.charCodeAt(0) === PROLONGED_SOUND_MARK;\n}\n\n/**\n * Tests a character. Returns true if the character is [Hiragana](https://en.wikipedia.org/wiki/Hiragana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharHiragana(char = '') {\n  if (isEmpty(char)) return false;\n  if (isCharLongDash(char)) return true;\n  return isCharInRange(char, HIRAGANA_START, HIRAGANA_END);\n}\n\n/**\n * Tests a character. Returns true if the character is [Romaji](https://en.wikipedia.org/wiki/Romaji) (allowing [Hepburn romanisation](https://en.wikipedia.org/wiki/Hepburn_romanization))\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharRomaji(char = '') {\n  if (isEmpty(char)) return false;\n  return ROMAJI_RANGES.some(([start, end]) => isCharInRange(char, start, end));\n}\n\n/**\n * Tests a character. Returns true if the character is [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharKatakana(char = '') {\n  return isCharInRange(char, KATAKANA_START, KATAKANA_END);\n}\n\n/**\n * Tests a character. Returns true if the character is [Hiragana](https://en.wikipedia.org/wiki/Hiragana) or [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharKana(char = '') {\n  if (isEmpty(char)) return false;\n  return isCharHiragana(char) || isCharKatakana(char);\n}\n\n/**\n * Test if `input` is [Kana](https://en.wikipedia.org/wiki/Kana) ([Katakana](https://en.wikipedia.org/wiki/Katakana) and/or [Hiragana](https://en.wikipedia.org/wiki/Hiragana))\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Kana](https://en.wikipedia.org/wiki/Kana)\n * @example\n * isKana('„ÅÇ')\n * // => true\n * isKana('„Ç¢')\n * // => true\n * isKana('„ÅÇ„Éº„Ç¢')\n * // => true\n * isKana('A')\n * // => false\n * isKana('„ÅÇA„Ç¢')\n * // => false\n */\nfunction isKana(input = '') {\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharKana);\n}\n\n/**\n * Test if `input` is [Hiragana](https://en.wikipedia.org/wiki/Hiragana)\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Hiragana](https://en.wikipedia.org/wiki/Hiragana)\n * @example\n * isHiragana('„Åí„Éº„ÇÄ')\n * // => true\n * isHiragana('A')\n * // => false\n * isHiragana('„ÅÇ„Ç¢')\n * // => false\n */\nfunction isHiragana(input = '') {\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharHiragana);\n}\n\n/**\n * Test if `input` is [Katakana](https://en.wikipedia.org/wiki/Katakana)\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Katakana](https://en.wikipedia.org/wiki/Katakana)\n * @example\n * isKatakana('„Ç≤„Éº„É†')\n * // => true\n * isKatakana('„ÅÇ')\n * // => false\n * isKatakana('A')\n * // => false\n * isKatakana('„ÅÇ„Ç¢')\n * // => false\n */\nfunction isKatakana(input = '') {\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharKatakana);\n}\n\n/**\n * Returns true if char is '„ÄÖ'\n * @param  {String} char to test\n * @return {Boolean}\n */\nfunction isCharIterationMark(char = '') {\n  if (isEmpty(char)) return false;\n  return char.charCodeAt(0) === KANJI_ITERATION_MARK;\n}\n\n/**\n * Tests a character. Returns true if the character is a CJK ideograph (kanji).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharKanji(char = '') {\n  return isCharInRange(char, KANJI_START, KANJI_END) || isCharIterationMark(char);\n}\n\n/**\n * Tests if `input` is [Kanji](https://en.wikipedia.org/wiki/Kanji) ([Japanese CJK ideographs](https://en.wikipedia.org/wiki/CJK_Unified_Ideographs))\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Kanji](https://en.wikipedia.org/wiki/Kanji)\n * @example\n * isKanji('ÂàÄ')\n * // => true\n * isKanji('ÂàáËÖπ')\n * // => true\n * isKanji('Âã¢„ÅÑ')\n * // => false\n * isKanji('„ÅÇA„Ç¢')\n * // => false\n * isKanji('üê∏')\n * // => false\n */\nfunction isKanji(input = '') {\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharKanji);\n}\n\n/**\n * Tests a character. Returns true if the character is considered English punctuation.\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharEnglishPunctuation(char = '') {\n  if (isEmpty(char)) return false;\n  return EN_PUNCTUATION_RANGES.some(([start, end]) => isCharInRange(char, start, end));\n}\n\n/**\n * Tests a character. Returns true if the character is considered Japanese punctuation.\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharJapanesePunctuation(char = '') {\n  if (isEmpty(char) || isCharIterationMark(char)) return false;\n  return JA_PUNCTUATION_RANGES.some(([start, end]) => isCharInRange(char, start, end));\n}\nconst isCharEnSpace = x => x === ' ';\nconst isCharJaSpace = x => x === '„ÄÄ';\nconst isCharJaNum = x => /[Ôºê-Ôºô]/.test(x);\nconst isCharEnNum = x => /[0-9]/.test(x);\nconst TOKEN_TYPES = {\n  EN: 'en',\n  JA: 'ja',\n  EN_NUM: 'englishNumeral',\n  JA_NUM: 'japaneseNumeral',\n  EN_PUNC: 'englishPunctuation',\n  JA_PUNC: 'japanesePunctuation',\n  KANJI: 'kanji',\n  HIRAGANA: 'hiragana',\n  KATAKANA: 'katakana',\n  SPACE: 'space',\n  OTHER: 'other'\n};\n\n// prettier-ignore\nfunction getType(input, compact = false) {\n  const {\n    EN,\n    JA,\n    EN_NUM,\n    JA_NUM,\n    EN_PUNC,\n    JA_PUNC,\n    KANJI,\n    HIRAGANA,\n    KATAKANA,\n    SPACE,\n    OTHER\n  } = TOKEN_TYPES;\n  if (compact) {\n    switch (true) {\n      case isCharJaNum(input):\n        return OTHER;\n      case isCharEnNum(input):\n        return OTHER;\n      case isCharEnSpace(input):\n        return EN;\n      case isCharEnglishPunctuation(input):\n        return OTHER;\n      case isCharJaSpace(input):\n        return JA;\n      case isCharJapanesePunctuation(input):\n        return OTHER;\n      case isCharJapanese(input):\n        return JA;\n      case isCharRomaji(input):\n        return EN;\n      default:\n        return OTHER;\n    }\n  } else {\n    switch (true) {\n      case isCharJaSpace(input):\n        return SPACE;\n      case isCharEnSpace(input):\n        return SPACE;\n      case isCharJaNum(input):\n        return JA_NUM;\n      case isCharEnNum(input):\n        return EN_NUM;\n      case isCharEnglishPunctuation(input):\n        return EN_PUNC;\n      case isCharJapanesePunctuation(input):\n        return JA_PUNC;\n      case isCharKanji(input):\n        return KANJI;\n      case isCharHiragana(input):\n        return HIRAGANA;\n      case isCharKatakana(input):\n        return KATAKANA;\n      case isCharJapanese(input):\n        return JA;\n      case isCharRomaji(input):\n        return EN;\n      default:\n        return OTHER;\n    }\n  }\n}\n\n/**\n * Splits input into array of strings separated by opinionated token types\n * `'en', 'ja', 'englishNumeral', 'japaneseNumeral','englishPunctuation', 'japanesePunctuation','kanji', 'hiragana', 'katakana', 'space', 'other'`.\n * If `{ compact: true }` then many same-language tokens are combined (spaces + text, kanji + kana, numeral + punctuation).\n * If `{ detailed: true }` then return array will contain `{ type, value }` instead of `'value'`\n * @param  {String} input text\n * @param  {Object} [options={ compact: false, detailed: false}] options to modify output style\n * @return {String|Object[]} text split into tokens containing values, or detailed object\n * @example\n * tokenize('„Åµ„Åµ„Éï„Éï')\n * // ['„Åµ„Åµ', '„Éï„Éï']\n *\n * tokenize('ÊÑü„Åò')\n * // ['ÊÑü', '„Åò']\n *\n * tokenize('‰∫∫„ÄÖ')\n * // ['‰∫∫„ÄÖ']\n *\n * tokenize('truly ÁßÅ„ÅØÊÇ≤„Åó„ÅÑ')\n * // ['truly', ' ', 'ÁßÅ', '„ÅØ', 'ÊÇ≤', '„Åó„ÅÑ']\n *\n * tokenize('truly ÁßÅ„ÅØÊÇ≤„Åó„ÅÑ', { compact: true })\n * // ['truly ', 'ÁßÅ„ÅØÊÇ≤„Åó„ÅÑ']\n *\n * tokenize('5romaji here...!?‰∫∫„ÄÖÊº¢Â≠ó„Å≤„Çâ„Åå„Å™„Ç´„Çø„ÄÄ„Ç´„ÉäÔºî„ÄåÔº≥Ôº®Ôº©ÔºØ„Äç„ÄÇÔºÅ')\n * // [ '5', 'romaji', ' ', 'here', '...!?', '‰∫∫„ÄÖÊº¢Â≠ó', '„Å≤„Çâ„Åå„Å™', '„Ç´„Çø', '„ÄÄ', '„Ç´„Éä', 'Ôºî', '„Äå', 'Ôº≥Ôº®Ôº©ÔºØ', '„Äç„ÄÇÔºÅ']\n *\n * tokenize('5romaji here...!?‰∫∫„ÄÖÊº¢Â≠ó„Å≤„Çâ„Åå„Å™„Ç´„Çø„ÄÄ„Ç´„ÉäÔºî„ÄåÔº≥Ôº®Ôº©ÔºØ„Äç„ÄÇÔºÅ', { compact: true })\n * // [ '5', 'romaji here', '...!?', '‰∫∫„ÄÖÊº¢Â≠ó„Å≤„Çâ„Åå„Å™„Ç´„Çø„ÄÄ„Ç´„Éä', 'Ôºî„Äå', 'Ôº≥Ôº®Ôº©ÔºØ', '„Äç„ÄÇÔºÅ']\n *\n * tokenize('5romaji here...!?‰∫∫„ÄÖÊº¢Â≠ó„Å≤„Çâ„Åå„Å™„Ç´„Çø„ÄÄ„Ç´„ÉäÔºî„ÄåÔº≥Ôº®Ôº©ÔºØ„Äç„ÄÇÔºÅ ŸÑŸÜÿ∞Ÿáÿ®', { detailed: true })\n * // [\n *  { type: 'englishNumeral', value: '5' },\n *  { type: 'en', value: 'romaji' },\n *  { type: 'space', value: ' ' },\n *  { type: 'en', value: 'here' },\n *  { type: 'englishPunctuation', value: '...!?' },\n *  { type: 'kanji', value: '‰∫∫„ÄÖÊº¢Â≠ó' },\n *  { type: 'hiragana', value: '„Å≤„Çâ„Åå„Å™' },\n *  { type: 'katakana', value: '„Ç´„Çø' },\n *  { type: 'space', value: '„ÄÄ' },\n *  { type: 'katakana', value: '„Ç´„Éä' },\n *  { type: 'japaneseNumeral', value: 'Ôºî' },\n *  { type: 'japanesePunctuation', value: '„Äå' },\n *  { type: 'ja', value: 'Ôº≥Ôº®Ôº©ÔºØ' },\n *  { type: 'japanesePunctuation', value: '„Äç„ÄÇÔºÅ' },\n *  { type: 'space', value: ' ' },\n *  { type: 'other', value: 'ŸÑŸÜÿ∞Ÿáÿ®' },\n * ]\n *\n * tokenize('5romaji here...!?‰∫∫„ÄÖÊº¢Â≠ó„Å≤„Çâ„Åå„Å™„Ç´„Çø„ÄÄ„Ç´„ÉäÔºî„ÄåÔº≥Ôº®Ôº©ÔºØ„Äç„ÄÇÔºÅ ŸÑŸÜÿ∞Ÿáÿ®', { compact: true, detailed: true})\n * // [\n *  { type: 'other', value: '5' },\n *  { type: 'en', value: 'romaji here' },\n *  { type: 'other', value: '...!?' },\n *  { type: 'ja', value: '‰∫∫„ÄÖÊº¢Â≠ó„Å≤„Çâ„Åå„Å™„Ç´„Çø„ÄÄ„Ç´„Éä' },\n *  { type: 'other', value: 'Ôºî„Äå' },\n *  { type: 'ja', value: 'Ôº≥Ôº®Ôº©ÔºØ' },\n *  { type: 'other', value: '„Äç„ÄÇÔºÅ' },\n *  { type: 'en', value: ' ' },\n *  { type: 'other', value: 'ŸÑŸÜÿ∞Ÿáÿ®' },\n *]\n */\nfunction tokenize(input, {\n  compact = false,\n  detailed = false\n} = {}) {\n  if (input == null || isEmpty(input)) {\n    return [];\n  }\n  const chars = [...input];\n  let initial = chars.shift();\n  let prevType = getType(initial, compact);\n  initial = detailed ? {\n    type: prevType,\n    value: initial\n  } : initial;\n  const result = chars.reduce((tokens, char) => {\n    const currType = getType(char, compact);\n    const sameType = currType === prevType;\n    prevType = currType;\n    let newValue = char;\n    if (sameType) {\n      newValue = (detailed ? tokens.pop().value : tokens.pop()) + newValue;\n    }\n    return detailed ? tokens.concat({\n      type: currType,\n      value: newValue\n    }) : tokens.concat(newValue);\n  }, [initial]);\n  return result;\n}\nconst isLeadingWithoutInitialKana = (input, leading) => leading && !isKana(input[0]);\nconst isTrailingWithoutFinalKana = (input, leading) => !leading && !isKana(input[input.length - 1]);\nconst isInvalidMatcher = (input, matchKanji) => matchKanji && ![...matchKanji].some(isKanji) || !matchKanji && isKana(input);\n\n/**\n * Strips [Okurigana](https://en.wikipedia.org/wiki/Okurigana)\n * @param  {String} input text\n * @param  {Object} [options={ leading: false, matchKanji: '' }] optional config\n * @return {String} text with okurigana removed\n * @example\n * stripOkurigana('Ë∏è„ÅøËæº„ÇÄ')\n * // => 'Ë∏è„ÅøËæº'\n * stripOkurigana('„ÅäÁ•ù„ÅÑ')\n * // => '„ÅäÁ•ù'\n * stripOkurigana('„ÅäËÖπ', { leading: true });\n * // => 'ËÖπ'\n * stripOkurigana('„Åµ„Åø„Åì„ÇÄ', { matchKanji: 'Ë∏è„ÅøËæº„ÇÄ' });\n * // => '„Åµ„Åø„Åì'\n * stripOkurigana('„Åä„Åø„Åæ„ÅÑ', { matchKanji: '„ÅäÁ•ù„ÅÑ', leading: true });\n * // => '„Åø„Åæ„ÅÑ'\n */\nfunction stripOkurigana(input = '', {\n  leading = false,\n  matchKanji = ''\n} = {}) {\n  if (!isJapanese(input) || isLeadingWithoutInitialKana(input, leading) || isTrailingWithoutFinalKana(input, leading) || isInvalidMatcher(input, matchKanji)) {\n    return input;\n  }\n  const chars = matchKanji || input;\n  const okuriganaRegex = new RegExp(leading ? `^${tokenize(chars).shift()}` : `${tokenize(chars).pop()}$`);\n  return input.replace(okuriganaRegex, '');\n}\nvar arrayZip = zip;\n\n/*\n  zip([1, 2, 3]); // [[1], [2], [3]]\n  zip([1, 2, 3], ['a', 'b', 'c']); // [[1, 'a'], [2, 'b'], [3, 'c']]\n  zip([1, 2], ['a', 'b'], [true, false]); //[[1, 'a', true], [2, 'b', false]]\n\n  zip([1, 2, 3], ['a', 'b'], [true]);\n  // [[1, 'a', true], [2, 'b', undefined], [3, undefined, undefined]]\n\n  zip(undefined, {}, false, 1, 'foo'); // throws\n  zip([1, 2], ['a', 'b'], undefined, {}, false, 1, 'foo'); // throws\n*/\n\nfunction zip() {\n  var result = [];\n  var args = Array.prototype.slice.call(arguments);\n  var argsLen = args.length;\n  var maxLen = 0;\n  var i, j;\n  if (!argsLen) {\n    throw new Error('zip requires at least one argument');\n  }\n  for (i = 0; i < argsLen; i++) {\n    if (!Array.isArray(args[i])) {\n      throw new Error('all arguments must be arrays');\n    }\n    var arrLen = args[i].length;\n    if (arrLen > maxLen) {\n      maxLen = arrLen;\n    }\n  }\n  for (i = 0; i < maxLen; i++) {\n    var group = [];\n    for (j = 0; j < argsLen; j++) {\n      if (!Array.isArray(args[j])) {\n        throw new Error('all arguments must be arrays');\n      }\n      group[j] = args[j][i];\n    }\n    result[i] = group;\n  }\n  return result;\n}\n\n/**\n * Combines furigana with kanji into an array of string pairs.\n * @param  {String} word vocab kanji word\n * @param  {String} reading vocab kana reading\n * @param  {String|Object} furi furigana placement info\n * @return {Array} furigana/kanji pairs\n * @example\n * combineFuri('„Åä‰∏ñËæû', '„Åä„Åõ„Åò', '1:„Åõ;2:„Åò')\n * // => [['', '„Åä'], ['„Åõ', '‰∏ñ'], ['„Åò', 'Ëæû']]\n * combineFuri('Â§ß‰∫∫„Åó„ÅÑ', '„Åä„Å®„Å™„Åó„ÅÑ') // smart fallbacks\n * // => [['„Åä„Å®„Å™', 'Â§ß‰∫∫'], ['', '„Åó„ÅÑ']]\n * combineFuri('‰Ωø„ÅÑÊñπ', '„Å§„Åã„ÅÑ„Åã„Åü') // smart fallbacks\n * // => [['„Å§„Åã', '‰Ωø'], ['', '„ÅÑ'], ['„Åã„Åü', 'Êñπ']]\n *\n * // special compound readings (Áæ©Ë®ì/ÁÜüÂ≠óË®ì) are spread across relevant kanji\n * combineFuri('ËÉ°Â∫ß', '„ÅÇ„Åê„Çâ', '0:„ÅÇ„Åê„Çâ')\n * // => [['„ÅÇ„Åê„Çâ', 'ËÉ°Â∫ß']]\n */\n\nfunction combineFuri() {\n  var word = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  var reading = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n  var furi = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : '';\n  var furiLocs = parseFuri(furi); // Áæ©Ë®ì/ÁÜüÂ≠óË®ì words with a single furi loc: ‰ªäÊó• \"0:„Åç„Çá„ÅÜ\"\n\n  var isSpecialReading = furiLocs.length === 1 && _toConsumableArray(word).every(isKanji);\n  var isKanaWord = _toConsumableArray(word).every(isKana);\n  var isWanikaniMadness = _toConsumableArray(reading).some(isHiragana) && _toConsumableArray(reading).some(isKatakana);\n  if (word === reading || isKanaWord) {\n    return [['', word]];\n  }\n  if (!furi || isSpecialReading || isWanikaniMadness) {\n    return basicFuri(word, reading);\n  }\n  return generatePairs(word, furiLocs);\n}\n/**\n * Displays simple furigana by removing redundant kana\n * @param  {String} [word=''] '„ÅäË¶ãËàû„ÅÑ'\n * @param  {String} [reading=''] '„Åä„Åø„Åæ„ÅÑ'\n * @return {Array} [['', '„Åä'], ['Ë¶ãËàû', '„Åø„Åæ'], ['', '„ÅÑ']]\n */\n\nfunction basicFuri() {\n  var word = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  var reading = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n\n  // early return + guard against words like ÔºëÊó• which are tokenized unfavourably\n  if (_toConsumableArray(word).every(function (c) {\n    return !isKana(c);\n  })) {\n    return [[reading, word]];\n  }\n  var _ref = [reading.slice(0, word.length - stripOkurigana(word, {\n      leading: true\n    }).length), reading.slice(stripOkurigana(reading, {\n      matchKanji: word\n    }).length)],\n    bikago = _ref[0],\n    okurigana = _ref[1];\n  var innerWordTokens = tokenize(removeExtraneousKana(word, bikago, okurigana));\n  var innerReadingChars = removeExtraneousKana(reading, bikago, okurigana);\n  var kanjiOddKanaEvenRegex = RegExp(innerWordTokens.map(function (_char) {\n    return isKanji(_char) ? '(.*)' : \"(\".concat(_char, \")\");\n  }).join(''));\n  var _ref2 = innerReadingChars.match(kanjiOddKanaEvenRegex) || [];\n  var _ref3 = _toArray(_ref2);\n  innerReadingChars = _ref3.slice(1);\n  var ret = arrayZip(innerReadingChars, innerWordTokens).map(skipRedundantReadings);\n  if (bikago) {\n    ret.unshift(['', bikago]);\n  }\n  if (okurigana) {\n    ret.push(['', okurigana]);\n  }\n  return ret;\n}\nfunction removeExtraneousKana() {\n  var str = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  var leading = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n  var trailing = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : '';\n  return str.replace(RegExp(\"^\".concat(leading)), '').replace(RegExp(\"\".concat(trailing, \"$\")), '');\n}\nfunction skipRedundantReadings(_ref4) {\n  var _ref5 = _slicedToArray(_ref4, 2),\n    reading = _ref5[0],\n    _ref5$ = _ref5[1],\n    word = _ref5$ === void 0 ? '' : _ref5$;\n  return !reading || reading === word ? ['', word] : [reading, word];\n}\nfunction parseFuri(data) {\n  return typeof data === 'string' ? parseFuriString(data) : parseFuriObject(data);\n}\n/**\n * Parses furigana placement object\n * @param  {Object} [locations={}] { 1:'„Åõ', 2:'„Åò' }\n * @return {Array} [ [[1, 2], '„Åõ'], [[2, 3], '„Åò'] ]\n */\n\nfunction parseFuriObject() {\n  var locations = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  return Object.entries(locations).map(function (_ref6) {\n    var _ref7 = _slicedToArray(_ref6, 2),\n      start = _ref7[0],\n      content = _ref7[1];\n    return [[Number(start), Number(start) + 1], content];\n  });\n}\n/**\n * Parses furigana placement string\n * @param  {String} [locations=''] '1:„Åõ;2:„Åò'\n * @return {Array} [ [[1, 2], '„Åõ'], [[2, 3], '„Åò'] ]\n */\n\nfunction parseFuriString() {\n  var locations = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  return locations.split(';').map(function (entry) {\n    var _entry$split = entry.split(':'),\n      _entry$split2 = _slicedToArray(_entry$split, 2),\n      indexes = _entry$split2[0],\n      content = _entry$split2[1];\n    var _indexes$split$map = indexes.split('-').map(Number),\n      _indexes$split$map2 = _slicedToArray(_indexes$split$map, 2),\n      start = _indexes$split$map2[0],\n      end = _indexes$split$map2[1]; // NOTE: in the JMDict furistring data, the end index is either missing\n    // or it is listed as the *start* index of the final char ¬Ø\\_(„ÉÑ)_/¬Ø\n    // so we need to bump it either way to encompass that char\n\n    return [[start, end ? end + 1 : start + 1], content];\n  });\n}\n/**\n * Generates array pairs via furigana location data\n * @param  {String} word '„Åä‰∏ñËæû'\n * @param  {Array} furiLocs [[[1, 2], '„Åõ'], [[2, 3], '„Åò']]\n * @return {Array} [['', '„Åä'], ['„Åõ', '‰∏ñ'], ['„Åò', 'Ëæû']]\n */\n\nfunction generatePairs() {\n  var word = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  var furiLocs = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n  var prevCharEnd = 0;\n  return furiLocs.reduce(function (pairs, _ref8, index, source) {\n    var _ref9 = _slicedToArray(_ref8, 2),\n      _ref9$ = _slicedToArray(_ref9[0], 2),\n      start = _ref9$[0],\n      end = _ref9$[1],\n      furiText = _ref9[1];\n\n    // if no furigana at this index, add intervening chars\n    if (start !== prevCharEnd) {\n      pairs.push(['', word.slice(prevCharEnd, start)]);\n    } // add furigana and associated chars\n\n    pairs.push([furiText, word.slice(start, end)]); // if no more furigana left, add any remaining chars/okurigana with blank furi\n\n    if (end < word.length && !source[index + 1]) {\n      pairs.push(['', word.slice(end)]);\n    }\n    prevCharEnd = end;\n    return pairs;\n  }, []);\n}\nfunction useFuriPairs(word, reading, furi) {\n  return React.useMemo(function () {\n    return combineFuri(word, reading, furi);\n  }, [word, reading, furi]);\n}\nvar _excluded = [\"style\"],\n  _excluded2 = [\"style\"],\n  _excluded3 = [\"style\"],\n  _excluded4 = [\"style\"],\n  _excluded5 = [\"word\", \"reading\", \"furi\", \"showFuri\", \"render\"];\nvar wrapperStyle = {\n  display: 'inline-flex',\n  flexFlow: 'row wrap',\n  fontFamily: \"'\\u30D2\\u30E9\\u30AE\\u30CE\\u89D2\\u30B4 ProN', 'Hiragino Kaku Gothic ProN', 'TakaoP\\u30B4\\u30B7\\u30C3\\u30AF', TakaoPGothic, '\\u6E38\\u30B4\\u30B7\\u30C3\\u30AF', '\\u6E38\\u30B4\\u30B7\\u30C3\\u30AF\\u4F53', YuGothic, 'Yu Gothic', '\\u30E1\\u30A4\\u30EA\\u30AA', Meiryo, '\\uFF2D\\uFF33 \\u30B4\\u30B7\\u30C3\\u30AF', 'MS Gothic', HiraKakuProN-W3, 'MotoyaLCedar', 'Droid Sans Japanese', sans-serif\"\n};\nvar pairStyle = {\n  display: 'inline-flex',\n  fontSize: '24px',\n  lineHeight: '1',\n  flexFlow: 'column nowrap',\n  justifyContent: 'flex-end',\n  alignItems: 'center',\n  alignSelf: 'flex-end'\n};\nvar furiStyle = {\n  display: 'block',\n  fontSize: '0.5em',\n  letterSpacing: '-0.02em',\n  margin: '0 0.1em',\n  paddingTop: '0.2em',\n  paddingBottom: '0.1em',\n  // don't interfere with selection of the content text\n  userSelect: 'none',\n  opacity: '0.9'\n};\nvar textStyle = {\n  display: 'block'\n};\nfunction Wrapper(_ref) {\n  var style = _ref.style,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return /*#__PURE__*/React.createElement(\"span\", _extends({\n    lang: \"ja\",\n    style: _objectSpread2(_objectSpread2({}, wrapperStyle), style)\n  }, props));\n}\nfunction Pair(_ref2) {\n  var style = _ref2.style,\n    props = _objectWithoutProperties(_ref2, _excluded2);\n  return /*#__PURE__*/React.createElement(\"span\", _extends({\n    lang: \"ja\",\n    style: _objectSpread2(_objectSpread2({}, pairStyle), style)\n  }, props));\n}\nfunction Furi(_ref3) {\n  var style = _ref3.style,\n    props = _objectWithoutProperties(_ref3, _excluded3);\n  return /*#__PURE__*/React.createElement(\"span\", _extends({\n    lang: \"ja\",\n    style: _objectSpread2(_objectSpread2({}, furiStyle), style)\n  }, props));\n}\nfunction Text(_ref4) {\n  var style = _ref4.style,\n    props = _objectWithoutProperties(_ref4, _excluded4);\n  return /*#__PURE__*/React.createElement(\"span\", _extends({\n    lang: \"ja\",\n    style: _objectSpread2(_objectSpread2({}, textStyle), style)\n  }, props));\n}\nfunction ReactFuri(_ref5) {\n  var word = _ref5.word,\n    reading = _ref5.reading,\n    furi = _ref5.furi,\n    showFuri = _ref5.showFuri,\n    render = _ref5.render,\n    props = _objectWithoutProperties(_ref5, _excluded5);\n  var pairs = useFuriPairs(word, reading, furi);\n  return typeof render === 'function' ? render({\n    pairs: pairs\n  }) : /*#__PURE__*/React.createElement(Wrapper, props, pairs.map(function (_ref6, index) {\n    var _ref7 = _slicedToArray(_ref6, 2),\n      furiText = _ref7[0],\n      text = _ref7[1];\n    var uniquePairKey = text + index;\n    return /*#__PURE__*/React.createElement(Pair, {\n      key: uniquePairKey\n    }, showFuri && /*#__PURE__*/React.createElement(Furi, null, furiText), /*#__PURE__*/React.createElement(Text, null, text));\n  }));\n}\nReactFuri.defaultProps = {\n  word: '',\n  reading: '',\n  furi: '',\n  showFuri: true\n};\nexport { Furi, Pair, ReactFuri, Text, Wrapper, combineFuri, useFuriPairs };","map":{"version":3,"names":["typeOf","value","Object","toString","call","slice","toLowerCase","isEmpty","input","length","isCharInRange","char","start","end","code","charCodeAt","LOWERCASE_ZENKAKU_START","LOWERCASE_ZENKAKU_END","UPPERCASE_ZENKAKU_START","UPPERCASE_ZENKAKU_END","HIRAGANA_START","HIRAGANA_END","KATAKANA_START","KATAKANA_END","KANJI_START","KANJI_END","KANJI_ITERATION_MARK","PROLONGED_SOUND_MARK","ZENKAKU_NUMBERS","ZENKAKU_UPPERCASE","ZENKAKU_LOWERCASE","ZENKAKU_PUNCTUATION_1","ZENKAKU_PUNCTUATION_2","ZENKAKU_PUNCTUATION_3","ZENKAKU_PUNCTUATION_4","ZENKAKU_SYMBOLS_CURRENCY","HIRAGANA_CHARS","KATAKANA_CHARS","HANKAKU_KATAKANA","KATAKANA_PUNCTUATION","KANA_PUNCTUATION","CJK_SYMBOLS_PUNCTUATION","COMMON_CJK","RARE_CJK","KANA_RANGES","JA_PUNCTUATION_RANGES","JAPANESE_RANGES","MODERN_ENGLISH","HEPBURN_MACRON_RANGES","SMART_QUOTE_RANGES","ROMAJI_RANGES","EN_PUNCTUATION_RANGES","isCharJapanese","some","isJapanese","allowed","augmented","every","isJa","test","createCustomMapping","customMap","customTree","entries","forEach","roma","kana","subTree","split","undefined","makeMap","map","mapCopy","JSON","parse","stringify","transformMap","mapSubtree","customSubtree","reduce","newSubtree","subtree","SMALL_Y$1","ya","yi","yu","ye","yo","SMALL_VOWELS","a","i","u","e","o","assign","tu","wa","ka","ke","wi","we","isCharLongDash","isCharHiragana","isCharRomaji","isCharKatakana","isCharKana","isKana","isHiragana","isKatakana","isCharIterationMark","isCharKanji","isKanji","isCharEnglishPunctuation","isCharJapanesePunctuation","isCharEnSpace","x","isCharJaSpace","isCharJaNum","isCharEnNum","TOKEN_TYPES","EN","JA","EN_NUM","JA_NUM","EN_PUNC","JA_PUNC","KANJI","HIRAGANA","KATAKANA","SPACE","OTHER","getType","compact","tokenize","detailed","chars","initial","shift","prevType","type","result","tokens","currType","sameType","newValue","pop","concat","isLeadingWithoutInitialKana","leading","isTrailingWithoutFinalKana","isInvalidMatcher","matchKanji","stripOkurigana","okuriganaRegex","RegExp","replace","arrayZip","zip","args","Array","prototype","arguments","argsLen","maxLen","j","Error","isArray","arrLen","group","combineFuri","word","reading","furi","furiLocs","parseFuri","isSpecialReading","_toConsumableArray","isKanaWord","isWanikaniMadness","basicFuri","generatePairs","c","_ref","bikago","okurigana","innerWordTokens","removeExtraneousKana","innerReadingChars","kanjiOddKanaEvenRegex","_char","join","_ref2","match","_ref3","_toArray","ret","skipRedundantReadings","unshift","push","str","trailing","_ref4","_ref5","_slicedToArray","_ref5$","data","parseFuriString","parseFuriObject","locations","_ref6","_ref7","content","Number","entry","_entry$split","_entry$split2","indexes","_indexes$split$map","_indexes$split$map2","prevCharEnd","pairs","_ref8","index","source","_ref9","_ref9$","furiText","useFuriPairs","React","useMemo","wrapperStyle","display","flexFlow","fontFamily","pairStyle","fontSize","lineHeight","justifyContent","alignItems","alignSelf","furiStyle","letterSpacing","margin","paddingTop","paddingBottom","userSelect","opacity","textStyle","Wrapper","style","props","_objectWithoutProperties","_excluded","createElement","_extends","lang","_objectSpread2","Pair","_excluded2","Furi","_excluded3","Text","_excluded4","ReactFuri","showFuri","render","_excluded5","text","uniquePairKey","key","defaultProps"],"sources":["../node_modules/wanakana/esm/index.js","../node_modules/just-zip-it/index.mjs","../src/utils.js","../src/hooks.js","../src/components.js"],"sourcesContent":["/**\n * Returns detailed type as string (instead of just 'object' for arrays etc)\n * @private\n * @param {any} value js value\n * @returns {String} type of value\n * @example\n * typeOf({}); // 'object'\n * typeOf([]); // 'array'\n * typeOf(function() {}); // 'function'\n * typeOf(/a/); // 'regexp'\n * typeOf(new Date()); // 'date'\n * typeOf(null); // 'null'\n * typeOf(undefined); // 'undefined'\n * typeOf('a'); // 'string'\n * typeOf(1); // 'number'\n * typeOf(true); // 'boolean'\n * typeOf(new Map()); // 'map'\n * typeOf(new Set()); // 'map'\n */\nfunction typeOf(value) {\n  if (value === null) {\n    return 'null';\n  }\n  if (value !== Object(value)) {\n    return typeof value;\n  }\n  return {}.toString\n    .call(value)\n    .slice(8, -1)\n    .toLowerCase();\n}\n\n/**\n * Checks if input string is empty\n * @param  {String} input text input\n * @return {Boolean} true if no input\n */\nfunction isEmpty(input) {\n  if (typeOf(input) !== 'string') {\n    return true;\n  }\n  return !input.length;\n}\n\n/**\n * Takes a character and a unicode range. Returns true if the char is in the range.\n * @param  {String}  char  unicode character\n * @param  {Number}  start unicode start range\n * @param  {Number}  end   unicode end range\n * @return {Boolean}\n */\nfunction isCharInRange(char = '', start, end) {\n  if (isEmpty(char)) return false;\n  const code = char.charCodeAt(0);\n  return start <= code && code <= end;\n}\n\nconst VERSION = '5.2.0';\n\nconst TO_KANA_METHODS = {\n  HIRAGANA: 'toHiragana',\n  KATAKANA: 'toKatakana',\n};\n\nconst ROMANIZATIONS = {\n  HEPBURN: 'hepburn',\n};\n\n/**\n * Default config for WanaKana, user passed options will be merged with these\n * @type {DefaultOptions}\n * @name defaultOptions\n * @property {Boolean} [useObsoleteKana=false] - Set to true to use obsolete characters, such as „Çê and „Çë.\n * @example\n * toHiragana('we', { useObsoleteKana: true })\n * // => '„Çë'\n * @property {Boolean} [passRomaji=false] - Set to true to pass romaji when using mixed syllabaries with toKatakana() or toHiragana()\n * @example\n * toHiragana('only convert the katakana: „Éí„É©„Ç¨„Éä', { passRomaji: true })\n * // => \"only convert the katakana: „Å≤„Çâ„Åå„Å™\"\n * @property {Object} [convertLongVowelMark=true] - Set to false to prevent conversions of '„Éº' to extended vowels with toHiragana()\n * @example\n * toHiragana('„É©„Éº„É°„É≥', { convertLongVowelMark: false });\n * // => '„Çâ„Éº„ÇÅ„Çì\n * @property {Boolean} [upcaseKatakana=false] - Set to true to convert katakana to uppercase using toRomaji()\n * @example\n * toRomaji('„Å≤„Çâ„Åå„Å™ „Ç´„Çø„Ç´„Éä', { upcaseKatakana: true })\n * // => \"hiragana KATAKANA\"\n * @property {Boolean|String} [IMEMode=false] - Set to true, 'toHiragana', or 'toKatakana' to handle conversion while it is being typed.\n * @property {String} [romanization='hepburn'] - choose toRomaji() romanization map (currently only 'hepburn')\n * @property {Object} [customKanaMapping] - custom map will be merged with default conversion\n * @example\n * toKana('wanakana', { customKanaMapping: { na: '„Å´', ka: 'Bana' }) };\n * // => '„Çè„Å´Bana„Å´'\n * @property {Object} [customRomajiMapping] - custom map will be merged with default conversion\n * @example\n * toRomaji('„Å§„Åò„Åé„Çä', { customRomajiMapping: { „Åò: 'zi', „Å§: 'tu', „Çä: 'li' }) };\n * // => 'tuzigili'\n */\nconst DEFAULT_OPTIONS = {\n  useObsoleteKana: false,\n  passRomaji: false,\n  upcaseKatakana: false,\n  IMEMode: false,\n  convertLongVowelMark: true,\n  romanization: ROMANIZATIONS.HEPBURN,\n};\nconst LATIN_UPPERCASE_START = 0x41;\nconst LATIN_UPPERCASE_END = 0x5a;\nconst LOWERCASE_ZENKAKU_START = 0xff41;\nconst LOWERCASE_ZENKAKU_END = 0xff5a;\nconst UPPERCASE_ZENKAKU_START = 0xff21;\nconst UPPERCASE_ZENKAKU_END = 0xff3a;\nconst HIRAGANA_START = 0x3041;\nconst HIRAGANA_END = 0x3096;\nconst KATAKANA_START = 0x30a1;\nconst KATAKANA_END = 0x30fc;\nconst KANJI_START = 0x4e00;\nconst KANJI_END = 0x9faf;\n\nconst KANJI_ITERATION_MARK = 0x3005; // „ÄÖ\nconst PROLONGED_SOUND_MARK = 0x30fc; // „Éº\nconst KANA_SLASH_DOT = 0x30fb; // „Éª\n\nconst ZENKAKU_NUMBERS = [0xff10, 0xff19];\nconst ZENKAKU_UPPERCASE = [UPPERCASE_ZENKAKU_START, UPPERCASE_ZENKAKU_END];\nconst ZENKAKU_LOWERCASE = [LOWERCASE_ZENKAKU_START, LOWERCASE_ZENKAKU_END];\nconst ZENKAKU_PUNCTUATION_1 = [0xff01, 0xff0f];\nconst ZENKAKU_PUNCTUATION_2 = [0xff1a, 0xff1f];\nconst ZENKAKU_PUNCTUATION_3 = [0xff3b, 0xff3f];\nconst ZENKAKU_PUNCTUATION_4 = [0xff5b, 0xff60];\nconst ZENKAKU_SYMBOLS_CURRENCY = [0xffe0, 0xffee];\n\nconst HIRAGANA_CHARS = [0x3040, 0x309f];\nconst KATAKANA_CHARS = [0x30a0, 0x30ff];\nconst HANKAKU_KATAKANA = [0xff66, 0xff9f];\nconst KATAKANA_PUNCTUATION = [0x30fb, 0x30fc];\nconst KANA_PUNCTUATION = [0xff61, 0xff65];\nconst CJK_SYMBOLS_PUNCTUATION = [0x3000, 0x303f];\nconst COMMON_CJK = [0x4e00, 0x9fff];\nconst RARE_CJK = [0x3400, 0x4dbf];\n\nconst KANA_RANGES = [\n  HIRAGANA_CHARS,\n  KATAKANA_CHARS,\n  KANA_PUNCTUATION,\n  HANKAKU_KATAKANA,\n];\n\nconst JA_PUNCTUATION_RANGES = [\n  CJK_SYMBOLS_PUNCTUATION,\n  KANA_PUNCTUATION,\n  KATAKANA_PUNCTUATION,\n  ZENKAKU_PUNCTUATION_1,\n  ZENKAKU_PUNCTUATION_2,\n  ZENKAKU_PUNCTUATION_3,\n  ZENKAKU_PUNCTUATION_4,\n  ZENKAKU_SYMBOLS_CURRENCY,\n];\n\n// All Japanese unicode start and end ranges\n// Includes kanji, kana, zenkaku latin chars, punctuation, and number ranges.\nconst JAPANESE_RANGES = [\n  ...KANA_RANGES,\n  ...JA_PUNCTUATION_RANGES,\n  ZENKAKU_UPPERCASE,\n  ZENKAKU_LOWERCASE,\n  ZENKAKU_NUMBERS,\n  COMMON_CJK,\n  RARE_CJK,\n];\n\nconst MODERN_ENGLISH = [0x0000, 0x007f];\nconst HEPBURN_MACRON_RANGES = [\n  [0x0100, 0x0101], // ƒÄ ƒÅ\n  [0x0112, 0x0113], // ƒí ƒì\n  [0x012a, 0x012b], // ƒ™ ƒ´\n  [0x014c, 0x014d], // ≈å ≈ç\n  [0x016a, 0x016b], // ≈™ ≈´\n];\nconst SMART_QUOTE_RANGES = [\n  [0x2018, 0x2019], // ‚Äò ‚Äô\n  [0x201c, 0x201d], // ‚Äú ‚Äù\n];\n\nconst ROMAJI_RANGES = [MODERN_ENGLISH, ...HEPBURN_MACRON_RANGES];\n\nconst EN_PUNCTUATION_RANGES = [\n  [0x20, 0x2f],\n  [0x3a, 0x3f],\n  [0x5b, 0x60],\n  [0x7b, 0x7e],\n  ...SMART_QUOTE_RANGES,\n];\n\n/**\n * Tests a character. Returns true if the character is [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharJapanese(char = '') {\n  return JAPANESE_RANGES.some(([start, end]) => isCharInRange(char, start, end));\n}\n\n/**\n * Test if `input` only includes [Kanji](https://en.wikipedia.org/wiki/Kanji), [Kana](https://en.wikipedia.org/wiki/Kana), zenkaku numbers, and JA punctuation/symbols.‚Äù\n * @param  {String} [input=''] text\n * @param  {Regexp} [allowed] additional test allowed to pass for each char\n * @return {Boolean} true if passes checks\n * @example\n * isJapanese('Ê≥£„ÅçËô´')\n * // => true\n * isJapanese('„ÅÇ„Ç¢')\n * // => true\n * isJapanese('ÔºíÊúà') // Zenkaku numbers allowed\n * // => true\n * isJapanese('Ê≥£„ÅçËô´„ÄÇÔºÅ„ÄúÔºÑ') // Zenkaku/JA punctuation\n * // => true\n * isJapanese('Ê≥£„ÅçËô´.!~$') // Latin punctuation fails\n * // => false\n * isJapanese('AÊ≥£„ÅçËô´')\n * // => false\n * isJapanese('‚â™ÂÅΩÊã¨Âºß‚â´', /[‚â™‚â´]/);\n * // => true\n */\nfunction isJapanese(input = '', allowed) {\n  const augmented = typeOf(allowed) === 'regexp';\n  return isEmpty(input)\n    ? false\n    : [...input].every((char) => {\n      const isJa = isCharJapanese(char);\n      return !augmented ? isJa : isJa || allowed.test(char);\n    });\n}\n\nvar safeIsNaN = Number.isNaN ||\n    function ponyfill(value) {\n        return typeof value === 'number' && value !== value;\n    };\nfunction isEqual(first, second) {\n    if (first === second) {\n        return true;\n    }\n    if (safeIsNaN(first) && safeIsNaN(second)) {\n        return true;\n    }\n    return false;\n}\nfunction areInputsEqual(newInputs, lastInputs) {\n    if (newInputs.length !== lastInputs.length) {\n        return false;\n    }\n    for (var i = 0; i < newInputs.length; i++) {\n        if (!isEqual(newInputs[i], lastInputs[i])) {\n            return false;\n        }\n    }\n    return true;\n}\n\nfunction memoizeOne(resultFn, isEqual) {\n    if (isEqual === void 0) { isEqual = areInputsEqual; }\n    var cache = null;\n    function memoized() {\n        var newArgs = [];\n        for (var _i = 0; _i < arguments.length; _i++) {\n            newArgs[_i] = arguments[_i];\n        }\n        if (cache && cache.lastThis === this && isEqual(newArgs, cache.lastArgs)) {\n            return cache.lastResult;\n        }\n        var lastResult = resultFn.apply(this, newArgs);\n        cache = {\n            lastResult: lastResult,\n            lastArgs: newArgs,\n            lastThis: this,\n        };\n        return lastResult;\n    }\n    memoized.clear = function clear() {\n        cache = null;\n    };\n    return memoized;\n}\n\nvar has = Object.prototype.hasOwnProperty;\n\nfunction find(iter, tar, key) {\n\tfor (key of iter.keys()) {\n\t\tif (dequal(key, tar)) return key;\n\t}\n}\n\nfunction dequal(foo, bar) {\n\tvar ctor, len, tmp;\n\tif (foo === bar) return true;\n\n\tif (foo && bar && (ctor=foo.constructor) === bar.constructor) {\n\t\tif (ctor === Date) return foo.getTime() === bar.getTime();\n\t\tif (ctor === RegExp) return foo.toString() === bar.toString();\n\n\t\tif (ctor === Array) {\n\t\t\tif ((len=foo.length) === bar.length) {\n\t\t\t\twhile (len-- && dequal(foo[len], bar[len]));\n\t\t\t}\n\t\t\treturn len === -1;\n\t\t}\n\n\t\tif (ctor === Set) {\n\t\t\tif (foo.size !== bar.size) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tfor (len of foo) {\n\t\t\t\ttmp = len;\n\t\t\t\tif (tmp && typeof tmp === 'object') {\n\t\t\t\t\ttmp = find(bar, tmp);\n\t\t\t\t\tif (!tmp) return false;\n\t\t\t\t}\n\t\t\t\tif (!bar.has(tmp)) return false;\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\n\t\tif (ctor === Map) {\n\t\t\tif (foo.size !== bar.size) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tfor (len of foo) {\n\t\t\t\ttmp = len[0];\n\t\t\t\tif (tmp && typeof tmp === 'object') {\n\t\t\t\t\ttmp = find(bar, tmp);\n\t\t\t\t\tif (!tmp) return false;\n\t\t\t\t}\n\t\t\t\tif (!dequal(len[1], bar.get(tmp))) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\n\t\tif (ctor === ArrayBuffer) {\n\t\t\tfoo = new Uint8Array(foo);\n\t\t\tbar = new Uint8Array(bar);\n\t\t} else if (ctor === DataView) {\n\t\t\tif ((len=foo.byteLength) === bar.byteLength) {\n\t\t\t\twhile (len-- && foo.getInt8(len) === bar.getInt8(len));\n\t\t\t}\n\t\t\treturn len === -1;\n\t\t}\n\n\t\tif (ArrayBuffer.isView(foo)) {\n\t\t\tif ((len=foo.byteLength) === bar.byteLength) {\n\t\t\t\twhile (len-- && foo[len] === bar[len]);\n\t\t\t}\n\t\t\treturn len === -1;\n\t\t}\n\n\t\tif (!ctor || typeof foo === 'object') {\n\t\t\tlen = 0;\n\t\t\tfor (ctor in foo) {\n\t\t\t\tif (has.call(foo, ctor) && ++len && !has.call(bar, ctor)) return false;\n\t\t\t\tif (!(ctor in bar) || !dequal(foo[ctor], bar[ctor])) return false;\n\t\t\t}\n\t\t\treturn Object.keys(bar).length === len;\n\t\t}\n\t}\n\n\treturn foo !== foo && bar !== bar;\n}\n\n/**\n * Easy re-use of merging with default options\n * @param {Object} opts user options\n * @returns user options merged over default options\n */\nconst mergeWithDefaultOptions = (opts = {}) => Object.assign({}, DEFAULT_OPTIONS, opts);\n\nfunction applyMapping(string, mapping, convertEnding) {\n  const root = mapping;\n\n  function nextSubtree(tree, nextChar) {\n    const subtree = tree[nextChar];\n    if (subtree === undefined) {\n      return undefined;\n    }\n    // if the next child node does not have a node value, set its node value to the input\n    return Object.assign({ '': tree[''] + nextChar }, tree[nextChar]);\n  }\n\n  function newChunk(remaining, currentCursor) {\n    // start parsing a new chunk\n    const firstChar = remaining.charAt(0);\n\n    return parse(\n      Object.assign({ '': firstChar }, root[firstChar]),\n      remaining.slice(1),\n      currentCursor,\n      currentCursor + 1\n    );\n  }\n\n  function parse(tree, remaining, lastCursor, currentCursor) {\n    if (!remaining) {\n      if (convertEnding || Object.keys(tree).length === 1) {\n        // nothing more to consume, just commit the last chunk and return it\n        // so as to not have an empty element at the end of the result\n        return tree[''] ? [[lastCursor, currentCursor, tree['']]] : [];\n      }\n      // if we don't want to convert the ending, because there are still possible continuations\n      // return null as the final node value\n      return [[lastCursor, currentCursor, null]];\n    }\n\n    if (Object.keys(tree).length === 1) {\n      return [[lastCursor, currentCursor, tree['']]].concat(\n        newChunk(remaining, currentCursor)\n      );\n    }\n\n    const subtree = nextSubtree(tree, remaining.charAt(0));\n\n    if (subtree === undefined) {\n      return [[lastCursor, currentCursor, tree['']]].concat(\n        newChunk(remaining, currentCursor)\n      );\n    }\n    // continue current branch\n    return parse(subtree, remaining.slice(1), lastCursor, currentCursor + 1);\n  }\n\n  return newChunk(string, 0);\n}\n\n// transform the tree, so that for example hepburnTree['„Çî']['„ÅÅ'][''] === 'va'\n// or kanaTree['k']['y']['a'][''] === '„Åç„ÇÉ'\nfunction transform(tree) {\n  return Object.entries(tree).reduce((map, [char, subtree]) => {\n    const endOfBranch = typeOf(subtree) === 'string';\n    // eslint-disable-next-line no-param-reassign\n    map[char] = endOfBranch ? { '': subtree } : transform(subtree);\n    return map;\n  }, {});\n}\n\nfunction getSubTreeOf(tree, string) {\n  return string.split('').reduce((correctSubTree, char) => {\n    if (correctSubTree[char] === undefined) {\n      // eslint-disable-next-line no-param-reassign\n      correctSubTree[char] = {};\n    }\n    return correctSubTree[char];\n  }, tree);\n}\n\n/**\n * Creates a custom mapping tree, returns a function that accepts a defaultMap which the newly created customMapping will be merged with and returned\n * (customMap) => (defaultMap) => mergedMap\n * @param  {Object} customMap { 'ka' : '„Å™' }\n * @return {Function} (defaultMap) => defaultMergedWithCustomMap\n * @example\n * const sillyMap = createCustomMapping({ '„Å°„ÇÉ': 'time', 'Ëåé': 'cookie'„ÄÄ});\n * // sillyMap is passed defaultMapping to merge with when called in toRomaji()\n * toRomaji(\"It's Ëåé „Å°„ÇÉ „Çà\", { customRomajiMapping: sillyMap });\n * // => 'It's cookie time yo';\n */\nfunction createCustomMapping(customMap = {}) {\n  const customTree = {};\n\n  if (typeOf(customMap) === 'object') {\n    Object.entries(customMap).forEach(([roma, kana]) => {\n      let subTree = customTree;\n      roma.split('').forEach((char) => {\n        if (subTree[char] === undefined) {\n          subTree[char] = {};\n        }\n        subTree = subTree[char];\n      });\n      subTree[''] = kana;\n    });\n  }\n\n  return function makeMap(map) {\n    const mapCopy = JSON.parse(JSON.stringify(map));\n\n    function transformMap(mapSubtree, customSubtree) {\n      if (mapSubtree === undefined || typeOf(mapSubtree) === 'string') {\n        return customSubtree;\n      }\n      return Object.entries(customSubtree).reduce(\n        (newSubtree, [char, subtree]) => {\n          // eslint-disable-next-line no-param-reassign\n          newSubtree[char] = transformMap(mapSubtree[char], subtree);\n          return newSubtree;\n        },\n        mapSubtree\n      );\n    }\n\n    return transformMap(mapCopy, customTree);\n  };\n}\n\n// allow consumer to pass either function or object as customMapping\nfunction mergeCustomMapping(map, customMapping) {\n  if (!customMapping) {\n    return map;\n  }\n  return typeOf(customMapping) === 'function'\n    ? customMapping(map)\n    : createCustomMapping(customMapping)(map);\n}\n\n// NOTE: not exactly kunrei shiki, for example „Å¢„ÇÉ -> dya instead of zya, to avoid name clashing\n/* eslint-disable */\n// prettier-ignore\nconst BASIC_KUNREI = {\n  a: '„ÅÇ', i: '„ÅÑ', u: '„ÅÜ', e: '„Åà', o: '„Åä',\n  k: { a: '„Åã', i: '„Åç', u: '„Åè', e: '„Åë', o: '„Åì', },\n  s: { a: '„Åï', i: '„Åó', u: '„Åô', e: '„Åõ', o: '„Åù', },\n  t: { a: '„Åü', i: '„Å°', u: '„Å§', e: '„Å¶', o: '„Å®', },\n  n: { a: '„Å™', i: '„Å´', u: '„Å¨', e: '„Å≠', o: '„ÅÆ', },\n  h: { a: '„ÅØ', i: '„Å≤', u: '„Åµ', e: '„Å∏', o: '„Åª', },\n  m: { a: '„Åæ', i: '„Åø', u: '„ÇÄ', e: '„ÇÅ', o: '„ÇÇ', },\n  y: { a: '„ÇÑ', u: '„ÇÜ', o: '„Çà' },\n  r: { a: '„Çâ', i: '„Çä', u: '„Çã', e: '„Çå', o: '„Çç', },\n  w: { a: '„Çè', i: '„Çê', e: '„Çë', o: '„Çí', },\n  g: { a: '„Åå', i: '„Åé', u: '„Åê', e: '„Åí', o: '„Åî', },\n  z: { a: '„Åñ', i: '„Åò', u: '„Åö', e: '„Åú', o: '„Åû', },\n  d: { a: '„Å†', i: '„Å¢', u: '„Å•', e: '„Åß', o: '„Å©', },\n  b: { a: '„Å∞', i: '„Å≥', u: '„Å∂', e: '„Åπ', o: '„Åº', },\n  p: { a: '„Å±', i: '„Å¥', u: '„Å∑', e: '„Å∫', o: '„ÅΩ', },\n  v: { a: '„Çî„ÅÅ', i: '„Çî„ÅÉ', u: '„Çî', e: '„Çî„Åá', o: '„Çî„Åâ', },\n};\n\nconst SPECIAL_SYMBOLS$1 = {\n  '.': '„ÄÇ',\n  ',': '„ÄÅ',\n  ':': 'Ôºö',\n  '/': '„Éª',\n  '!': 'ÔºÅ',\n  '?': 'Ôºü',\n  '~': '„Äú',\n  '-': '„Éº',\n  '‚Äò': '„Äå',\n  '‚Äô': '„Äç',\n  '‚Äú': '„Äé',\n  '‚Äù': '„Äè',\n  '[': 'Ôºª',\n  ']': 'ÔºΩ',\n  '(': 'Ôºà',\n  ')': 'Ôºâ',\n  '{': 'ÔΩõ',\n  '}': 'ÔΩù',\n};\n\nconst CONSONANTS = {\n  k: '„Åç',\n  s: '„Åó',\n  t: '„Å°',\n  n: '„Å´',\n  h: '„Å≤',\n  m: '„Åø',\n  r: '„Çä',\n  g: '„Åé',\n  z: '„Åò',\n  d: '„Å¢',\n  b: '„Å≥',\n  p: '„Å¥',\n  v: '„Çî',\n  q: '„Åè',\n  f: '„Åµ',\n};\nconst SMALL_Y$1 = { ya: '„ÇÉ', yi: '„ÅÉ', yu: '„ÇÖ', ye: '„Åá', yo: '„Çá' };\nconst SMALL_VOWELS = { a: '„ÅÅ', i: '„ÅÉ', u: '„ÅÖ', e: '„Åá', o: '„Åâ' };\n\n// typing one should be the same as having typed the other instead\nconst ALIASES = {\n  sh: 'sy', // sha -> sya\n  ch: 'ty', // cho -> tyo\n  cy: 'ty', // cyo -> tyo\n  chy: 'ty', // chyu -> tyu\n  shy: 'sy', // shya -> sya\n  j: 'zy', // ja -> zya\n  jy: 'zy', // jye -> zye\n\n  // exceptions to above rules\n  shi: 'si',\n  chi: 'ti',\n  tsu: 'tu',\n  ji: 'zi',\n  fu: 'hu',\n};\n\n// xtu -> „Å£\nconst SMALL_LETTERS = Object.assign(\n  {\n    tu: '„Å£',\n    wa: '„Çé',\n    ka: '„Éµ',\n    ke: '„É∂',\n  },\n  SMALL_VOWELS,\n  SMALL_Y$1\n);\n\n// don't follow any notable patterns\nconst SPECIAL_CASES = {\n  yi: '„ÅÑ',\n  wu: '„ÅÜ',\n  ye: '„ÅÑ„Åá',\n  wi: '„ÅÜ„ÅÉ',\n  we: '„ÅÜ„Åá',\n  kwa: '„Åè„ÅÅ',\n  whu: '„ÅÜ',\n  // because it's not thya for „Å¶„ÇÉ but tha\n  // and tha is not „Å¶„ÅÅ, but „Å¶„ÇÉ\n  tha: '„Å¶„ÇÉ',\n  thu: '„Å¶„ÇÖ',\n  tho: '„Å¶„Çá',\n  dha: '„Åß„ÇÉ',\n  dhu: '„Åß„ÇÖ',\n  dho: '„Åß„Çá',\n};\n\nconst AIUEO_CONSTRUCTIONS = {\n  wh: '„ÅÜ',\n  kw: '„Åè',\n  qw: '„Åè',\n  q: '„Åè',\n  gw: '„Åê',\n  sw: '„Åô',\n  ts: '„Å§',\n  th: '„Å¶',\n  tw: '„Å®',\n  dh: '„Åß',\n  dw: '„Å©',\n  fw: '„Åµ',\n  f: '„Åµ',\n};\n\n/* eslint-enable */\nfunction createRomajiToKanaMap$1() {\n  const kanaTree = transform(BASIC_KUNREI);\n  // pseudo partial application\n  const subtreeOf = (string) => getSubTreeOf(kanaTree, string);\n\n  // add tya, sya, etc.\n  Object.entries(CONSONANTS).forEach(([consonant, yKana]) => {\n    Object.entries(SMALL_Y$1).forEach(([roma, kana]) => {\n      // for example kyo -> „Åç + „Çá\n      subtreeOf(consonant + roma)[''] = yKana + kana;\n    });\n  });\n\n  Object.entries(SPECIAL_SYMBOLS$1).forEach(([symbol, jsymbol]) => {\n    subtreeOf(symbol)[''] = jsymbol;\n  });\n\n  // things like „ÅÜ„ÅÉ, „Åè„ÅÉ, etc.\n  Object.entries(AIUEO_CONSTRUCTIONS).forEach(([consonant, aiueoKana]) => {\n    Object.entries(SMALL_VOWELS).forEach(([vowel, kana]) => {\n      const subtree = subtreeOf(consonant + vowel);\n      subtree[''] = aiueoKana + kana;\n    });\n  });\n\n  // different ways to write „Çì\n  ['n', \"n'\", 'xn'].forEach((nChar) => {\n    subtreeOf(nChar)[''] = '„Çì';\n  });\n\n  // c is equivalent to k, but not for chi, cha, etc. that's why we have to make a copy of k\n  kanaTree.c = JSON.parse(JSON.stringify(kanaTree.k));\n\n  Object.entries(ALIASES).forEach(([string, alternative]) => {\n    const allExceptLast = string.slice(0, string.length - 1);\n    const last = string.charAt(string.length - 1);\n    const parentTree = subtreeOf(allExceptLast);\n    // copy to avoid recursive containment\n    parentTree[last] = JSON.parse(JSON.stringify(subtreeOf(alternative)));\n  });\n\n  function getAlternatives(string) {\n    return [...Object.entries(ALIASES), ...[['c', 'k']]].reduce(\n      (list, [alt, roma]) => (string.startsWith(roma) ? list.concat(string.replace(roma, alt)) : list),\n      []\n    );\n  }\n\n  Object.entries(SMALL_LETTERS).forEach(([kunreiRoma, kana]) => {\n    const last = (char) => char.charAt(char.length - 1);\n    const allExceptLast = (chars) => chars.slice(0, chars.length - 1);\n    const xRoma = `x${kunreiRoma}`;\n    const xSubtree = subtreeOf(xRoma);\n    xSubtree[''] = kana;\n\n    // ltu -> xtu -> „Å£\n    const parentTree = subtreeOf(`l${allExceptLast(kunreiRoma)}`);\n    parentTree[last(kunreiRoma)] = xSubtree;\n\n    // ltsu -> ltu -> „Å£\n    getAlternatives(kunreiRoma).forEach((altRoma) => {\n      ['l', 'x'].forEach((prefix) => {\n        const altParentTree = subtreeOf(prefix + allExceptLast(altRoma));\n        altParentTree[last(altRoma)] = subtreeOf(prefix + kunreiRoma);\n      });\n    });\n  });\n\n  Object.entries(SPECIAL_CASES).forEach(([string, kana]) => {\n    subtreeOf(string)[''] = kana;\n  });\n\n  // add kka, tta, etc.\n  function addTsu(tree) {\n    return Object.entries(tree).reduce((tsuTree, [key, value]) => {\n      if (!key) {\n        // we have reached the bottom of this branch\n        // eslint-disable-next-line no-param-reassign\n        tsuTree[key] = `„Å£${value}`;\n      } else {\n        // more subtrees\n        // eslint-disable-next-line no-param-reassign\n        tsuTree[key] = addTsu(value);\n      }\n      return tsuTree;\n    }, {});\n  }\n  // have to explicitly name c here, because we made it a copy of k, not a reference\n  [...Object.keys(CONSONANTS), 'c', 'y', 'w', 'j'].forEach((consonant) => {\n    const subtree = kanaTree[consonant];\n    subtree[consonant] = addTsu(subtree);\n  });\n  // nn should not be „Å£„Çì\n  delete kanaTree.n.n;\n  // solidify the results, so that there there is referential transparency within the tree\n  return Object.freeze(JSON.parse(JSON.stringify(kanaTree)));\n}\n\nlet romajiToKanaMap = null;\n\nfunction getRomajiToKanaTree() {\n  if (romajiToKanaMap == null) {\n    romajiToKanaMap = createRomajiToKanaMap$1();\n  }\n  return romajiToKanaMap;\n}\n\nconst USE_OBSOLETE_KANA_MAP = createCustomMapping({\n  wi: '„Çê',\n  we: '„Çë',\n});\n\nfunction IME_MODE_MAP(map) {\n  // in IME mode, we do not want to convert single ns\n  const mapCopy = JSON.parse(JSON.stringify(map));\n  mapCopy.n.n = { '': '„Çì' };\n  mapCopy.n[' '] = { '': '„Çì' };\n  return mapCopy;\n}\n\n/**\n * Tests if char is in English unicode uppercase range\n * @param  {String} char\n * @return {Boolean}\n */\nfunction isCharUpperCase(char = '') {\n  if (isEmpty(char)) return false;\n  return isCharInRange(char, LATIN_UPPERCASE_START, LATIN_UPPERCASE_END);\n}\n\n/**\n * Returns true if char is '„Éº'\n * @param  {String} char to test\n * @return {Boolean}\n */\nfunction isCharLongDash(char = '') {\n  if (isEmpty(char)) return false;\n  return char.charCodeAt(0) === PROLONGED_SOUND_MARK;\n}\n\n/**\n * Tests if char is '„Éª'\n * @param  {String} char\n * @return {Boolean} true if '„Éª'\n */\nfunction isCharSlashDot(char = '') {\n  if (isEmpty(char)) return false;\n  return char.charCodeAt(0) === KANA_SLASH_DOT;\n}\n\n/**\n * Tests a character. Returns true if the character is [Hiragana](https://en.wikipedia.org/wiki/Hiragana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharHiragana(char = '') {\n  if (isEmpty(char)) return false;\n  if (isCharLongDash(char)) return true;\n  return isCharInRange(char, HIRAGANA_START, HIRAGANA_END);\n}\n\n/**\n * Convert [Hiragana](https://en.wikipedia.org/wiki/Hiragana) to [Katakana](https://en.wikipedia.org/wiki/Katakana)\n * Passes through any non-hiragana chars\n * @private\n * @param  {String} [input=''] text input\n * @return {String} converted text\n * @example\n * hiraganaToKatakana('„Å≤„Çâ„Åå„Å™')\n * // => \"„Éí„É©„Ç¨„Éä\"\n * hiraganaToKatakana('„Å≤„Çâ„Åå„Å™ is a type of kana')\n * // => \"„Éí„É©„Ç¨„Éä is a type of kana\"\n */\nfunction hiraganaToKatakana(input = '') {\n  const kata = [];\n  input.split('').forEach((char) => {\n    // Short circuit to avoid incorrect codeshift for '„Éº' and '„Éª'\n    if (isCharLongDash(char) || isCharSlashDot(char)) {\n      kata.push(char);\n    } else if (isCharHiragana(char)) {\n      // Shift charcode.\n      const code = char.charCodeAt(0) + (KATAKANA_START - HIRAGANA_START);\n      const kataChar = String.fromCharCode(code);\n      kata.push(kataChar);\n    } else {\n      // Pass non-hiragana chars through\n      kata.push(char);\n    }\n  });\n  return kata.join('');\n}\n\n// memoize and deeply compare args so we only recreate when necessary\nconst createRomajiToKanaMap = memoizeOne(\n  (IMEMode, useObsoleteKana, customKanaMapping) => {\n    let map = getRomajiToKanaTree();\n\n    map = IMEMode ? IME_MODE_MAP(map) : map;\n    map = useObsoleteKana ? USE_OBSOLETE_KANA_MAP(map) : map;\n\n    if (customKanaMapping) {\n      map = mergeCustomMapping(map, customKanaMapping);\n    }\n\n    return map;\n  },\n  dequal\n);\n\n/**\n * Convert [Romaji](https://en.wikipedia.org/wiki/Romaji) to [Kana](https://en.wikipedia.org/wiki/Kana), lowercase text will result in [Hiragana](https://en.wikipedia.org/wiki/Hiragana) and uppercase text will result in [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} [input=''] text\n * @param  {DefaultOptions} [options=defaultOptions]\n * @return {String} converted text\n * @example\n * toKana('onaji BUTTSUUJI')\n * // => '„Åä„Å™„Åò „Éñ„ÉÉ„ÉÑ„Ç¶„Ç∏'\n * toKana('ONAJI buttsuuji')\n * // => '„Ç™„Éä„Ç∏ „Å∂„Å£„Å§„ÅÜ„Åò'\n * toKana('Â∫ßÁ¶Ö‚Äòzazen‚Äô„Çπ„Çø„Ç§„É´')\n * // => 'Â∫ßÁ¶Ö„Äå„Åñ„Åú„Çì„Äç„Çπ„Çø„Ç§„É´'\n * toKana('batsuge-mu')\n * // => '„Å∞„Å§„Åí„Éº„ÇÄ'\n * toKana('!?.:/,~-‚Äò‚Äô‚Äú‚Äù[](){}') // Punctuation conversion\n * // => 'ÔºÅÔºü„ÄÇÔºö„Éª„ÄÅ„Äú„Éº„Äå„Äç„Äé„ÄèÔºªÔºΩÔºàÔºâÔΩõÔΩù'\n * toKana('we', { useObsoleteKana: true })\n * // => '„Çë'\n * toKana('wanakana', { customKanaMapping: { na: '„Å´', ka: 'bana' } });\n * // => '„Çè„Å´bana„Å´'\n */\nfunction toKana(input = '', options = {}, map) {\n  let config;\n  if (!map) {\n    config = mergeWithDefaultOptions(options);\n    map = createRomajiToKanaMap(\n      config.IMEMode,\n      config.useObsoleteKana,\n      config.customKanaMapping\n    );\n  } else {\n    config = options;\n  }\n\n  // throw away the substring index information and just concatenate all the kana\n  return splitIntoConvertedKana(input, config, map)\n    .map((kanaToken) => {\n      const [start, end, kana] = kanaToken;\n      if (kana === null) {\n        // haven't converted the end of the string, since we are in IME mode\n        return input.slice(start);\n      }\n      const enforceHiragana = config.IMEMode === TO_KANA_METHODS.HIRAGANA;\n      const enforceKatakana = config.IMEMode === TO_KANA_METHODS.KATAKANA\n        || [...input.slice(start, end)].every(isCharUpperCase);\n\n      return enforceHiragana || !enforceKatakana\n        ? kana\n        : hiraganaToKatakana(kana);\n    })\n    .join('');\n}\n\n/**\n *\n * @private\n * @param {String} [input=''] input text\n * @param {DefaultOptions} [options=defaultOptions] toKana options\n * @param {Object} [map] custom mapping\n * @returns {Array[]} [[start, end, token]]\n * @example\n * splitIntoConvertedKana('buttsuuji')\n * // => [[0, 2, '„Å∂'], [2, 6, '„Å£„Å§'], [6, 7, '„ÅÜ'], [7, 9, '„Åò']]\n */\nfunction splitIntoConvertedKana(input = '', options = {}, map) {\n  const { IMEMode, useObsoleteKana, customKanaMapping } = options;\n\n  if (!map) {\n    map = createRomajiToKanaMap(IMEMode, useObsoleteKana, customKanaMapping);\n  }\n\n  return applyMapping(input.toLowerCase(), map, !IMEMode);\n}\n\nlet LISTENERS = [];\n/**\n * Automagically replaces input values with converted text to kana\n * @param  {defaultOptions} [options] user config overrides, default conversion is toKana()\n * @return {Function} event handler with bound options\n * @private\n */\nfunction makeOnInput(options) {\n  let prevInput;\n\n  // Enforce IMEMode if not already specified\n  const mergedConfig = Object.assign({}, mergeWithDefaultOptions(options), {\n    IMEMode: options.IMEMode || true,\n  });\n\n  const preConfiguredMap = createRomajiToKanaMap(\n    mergedConfig.IMEMode,\n    mergedConfig.useObsoleteKana,\n    mergedConfig.customKanaMapping\n  );\n\n  const triggers = [\n    ...Object.keys(preConfiguredMap),\n    ...Object.keys(preConfiguredMap).map((char) => char.toUpperCase()),\n  ];\n\n  return function onInput({ target }) {\n    if (\n      target.value !== prevInput\n      && target.dataset.ignoreComposition !== 'true'\n    ) {\n      convertInput(target, mergedConfig, preConfiguredMap, triggers);\n    }\n  };\n}\n\nfunction convertInput(target, options, map, triggers, prevInput) {\n  const [head, textToConvert, tail] = splitInput(\n    target.value,\n    target.selectionEnd,\n    triggers\n  );\n  const convertedText = toKana(textToConvert, options, map);\n  const changed = textToConvert !== convertedText;\n\n  if (changed) {\n    const newCursor = head.length + convertedText.length;\n    const newValue = head + convertedText + tail;\n    // eslint-disable-next-line no-param-reassign\n    target.value = newValue;\n\n    if (tail.length) {\n      // push later on event loop (otherwise mid-text insertion can be 1 char too far to the right)\n      setTimeout(() => target.setSelectionRange(newCursor, newCursor), 1);\n    } else {\n      target.setSelectionRange(newCursor, newCursor);\n    }\n  }\n}\n\nfunction onComposition({ type, target, data }) {\n  // navigator.platform is not 100% reliable for singling out all OS,\n  // but for determining desktop \"Mac OS\" it is effective enough.\n  const isMacOS = /Mac/.test(window.navigator && window.navigator.platform);\n  // We don't want to ignore on Android:\n  // https://github.com/WaniKani/WanaKana/issues/82\n  // But MacOS IME auto-closes if we don't ignore:\n  // https://github.com/WaniKani/WanaKana/issues/71\n  // Other platform Japanese IMEs pass through happily\n  if (isMacOS) {\n    if (type === 'compositionupdate' && isJapanese(data)) {\n      // eslint-disable-next-line no-param-reassign\n      target.dataset.ignoreComposition = 'true';\n    }\n\n    if (type === 'compositionend') {\n      // eslint-disable-next-line no-param-reassign\n      target.dataset.ignoreComposition = 'false';\n    }\n  }\n}\n\nfunction trackListeners(id, inputHandler, compositionHandler) {\n  LISTENERS = LISTENERS.concat({\n    id,\n    inputHandler,\n    compositionHandler,\n  });\n}\n\nfunction untrackListeners({ id: targetId }) {\n  LISTENERS = LISTENERS.filter(({ id }) => id !== targetId);\n}\n\nfunction findListeners(el) {\n  return (\n    el && LISTENERS.find(({ id }) => id === el.getAttribute('data-wanakana-id'))\n  );\n}\n\n// Handle non-terminal inserted input conversion:\n// | -> „Çè| -> „Çè„Å≥| -> „Çè|„Å≥ -> „Çès|„Å≥ -> „Çèsh|„Å≥ -> „Çèshi|„Å≥ -> „Çè„Åó|„Å≥\n// or multiple ambiguous positioning (to select which \"s\" to work from)\n// „Åìs„Åìs|„Åìs„Åì -> „Åìs„Åìso|„Åìs„Åì -> „Åìs„Åì„Åù|„Åìs„Åì\nfunction splitInput(text = '', cursor = 0, triggers = []) {\n  let head;\n  let toConvert;\n  let tail;\n\n  if (cursor === 0 && triggers.includes(text[0])) {\n    [head, toConvert, tail] = workFromStart(text, triggers);\n  } else if (cursor > 0) {\n    [head, toConvert, tail] = workBackwards(text, cursor);\n  } else {\n    [head, toConvert] = takeWhileAndSlice(\n      text,\n      (char) => !triggers.includes(char)\n    );\n    [toConvert, tail] = takeWhileAndSlice(\n      toConvert,\n      (char) => !isJapanese(char)\n    );\n  }\n\n  return [head, toConvert, tail];\n}\n\nfunction workFromStart(text, catalystChars) {\n  return [\n    '',\n    ...takeWhileAndSlice(\n      text,\n      (char) => catalystChars.includes(char) || !isJapanese(char, /[0-9]/)\n    ),\n  ];\n}\n\nfunction workBackwards(text = '', startIndex = 0) {\n  const [toConvert, head] = takeWhileAndSlice(\n    [...text.slice(0, startIndex)].reverse(),\n    (char) => !isJapanese(char)\n  );\n  return [\n    head.reverse().join(''),\n    toConvert\n      .split('')\n      .reverse()\n      .join(''),\n    text.slice(startIndex),\n  ];\n}\n\nfunction takeWhileAndSlice(source = {}, predicate = (x) => !!x) {\n  const result = [];\n  const { length } = source;\n  let i = 0;\n  while (i < length && predicate(source[i], i)) {\n    result.push(source[i]);\n    i += 1;\n  }\n  return [result.join(''), source.slice(i)];\n}\n\n/* eslint-disable no-console */\nconst onInput = ({ target: { value, selectionStart, selectionEnd } }) => console.log('input:', { value, selectionStart, selectionEnd });\nconst onCompositionStart = () => console.log('compositionstart');\nconst onCompositionUpdate = ({\n  target: { value, selectionStart, selectionEnd },\n  data,\n}) => console.log('compositionupdate', {\n  data,\n  value,\n  selectionStart,\n  selectionEnd,\n});\nconst onCompositionEnd = () => console.log('compositionend');\n\nconst events = {\n  input: onInput,\n  compositionstart: onCompositionStart,\n  compositionupdate: onCompositionUpdate,\n  compositionend: onCompositionEnd,\n};\n\nconst addDebugListeners = (input) => {\n  Object.entries(events).forEach(([event, handler]) => input.addEventListener(event, handler)\n  );\n};\n\nconst removeDebugListeners = (input) => {\n  Object.entries(events).forEach(([event, handler]) => input.removeEventListener(event, handler)\n  );\n};\n\nconst ELEMENTS = ['TEXTAREA', 'INPUT'];\n\nlet idCounter = 0;\nconst newId = () => {\n  idCounter += 1;\n  return `${Date.now()}${idCounter}`;\n};\n\n/**\n * Binds eventListener for 'input' events to an input field to automagically replace values with kana\n * Can pass `{ IMEMode: 'toHiragana' || 'toKatakana' }` to enforce kana conversion type\n * @param  {HTMLElement} element textarea, input[type=\"text\"] etc\n * @param  {DefaultOptions} [options=defaultOptions] defaults to { IMEMode: true } using `toKana`\n * @example\n * bind(document.querySelector('#myInput'));\n */\nfunction bind(element = {}, options = {}, debug = false) {\n  if (!ELEMENTS.includes(element.nodeName)) {\n    throw new Error(\n      `Element provided to Wanakana bind() was not a valid input or textarea element.\\n Received: (${JSON.stringify(\n        element\n      )})`\n    );\n  }\n  if (element.hasAttribute('data-wanakana-id')) {\n    return;\n  }\n  const onInput = makeOnInput(options);\n  const id = newId();\n  const attributes = [\n    { name: 'data-wanakana-id', value: id },\n    { name: 'lang', value: 'ja' },\n    { name: 'autoCapitalize', value: 'none' },\n    { name: 'autoCorrect', value: 'off' },\n    { name: 'autoComplete', value: 'off' },\n    { name: 'spellCheck', value: 'false' },\n  ];\n  const previousAttributes = {};\n  attributes.forEach((attribute) => {\n    previousAttributes[attribute.name] = element.getAttribute(attribute.name);\n    element.setAttribute(attribute.name, attribute.value);\n  });\n  element.dataset.previousAttributes = JSON.stringify(previousAttributes);\n  element.addEventListener('input', onInput);\n  element.addEventListener('compositionupdate', onComposition);\n  element.addEventListener('compositionend', onComposition);\n  trackListeners(id, onInput, onComposition);\n  if (debug === true) {\n    addDebugListeners(element);\n  }\n}\n\n/**\n * Unbinds eventListener from input field\n * @param  {HTMLElement} element textarea, input\n */\nfunction unbind(element, debug = false) {\n  const listeners = findListeners(element);\n  if (listeners == null) {\n    throw new Error(\n      `Element provided to Wanakana unbind() had no listener registered.\\n Received: ${JSON.stringify(\n        element\n      )}`\n    );\n  }\n  const { inputHandler, compositionHandler } = listeners;\n  const attributes = JSON.parse(element.dataset.previousAttributes);\n  Object.keys(attributes).forEach((key) => {\n    if (attributes[key]) {\n      element.setAttribute(key, attributes[key]);\n    } else {\n      element.removeAttribute(key);\n    }\n  });\n  element.removeAttribute('data-previous-attributes');\n  element.removeAttribute('data-ignore-composition');\n  element.removeEventListener('input', inputHandler);\n  element.removeEventListener('compositionstart', compositionHandler);\n  element.removeEventListener('compositionupdate', compositionHandler);\n  element.removeEventListener('compositionend', compositionHandler);\n  untrackListeners(listeners);\n  if (debug === true) {\n    removeDebugListeners(element);\n  }\n}\n\n/**\n * Tests a character. Returns true if the character is [Romaji](https://en.wikipedia.org/wiki/Romaji) (allowing [Hepburn romanisation](https://en.wikipedia.org/wiki/Hepburn_romanization))\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharRomaji(char = '') {\n  if (isEmpty(char)) return false;\n  return ROMAJI_RANGES.some(([start, end]) => isCharInRange(char, start, end));\n}\n\n/**\n * Test if `input` is [Romaji](https://en.wikipedia.org/wiki/Romaji) (allowing [Hepburn romanisation](https://en.wikipedia.org/wiki/Hepburn_romanization))\n * @param  {String} [input=''] text\n * @param  {Regexp} [allowed] additional test allowed to pass for each char\n * @return {Boolean} true if [Romaji](https://en.wikipedia.org/wiki/Romaji)\n * @example\n * isRomaji('T≈çky≈ç and ≈åsaka')\n * // => true\n * isRomaji('12a*b&c-d')\n * // => true\n * isRomaji('„ÅÇ„Ç¢A')\n * // => false\n * isRomaji('„ÅäÈ°ò„ÅÑ')\n * // => false\n * isRomaji('aÔºÅb&c„Éºd') // Zenkaku punctuation fails\n * // => false\n * isRomaji('aÔºÅb&c„Éºd', /[ÔºÅ„Éº]/)\n * // => true\n */\nfunction isRomaji(input = '', allowed) {\n  const augmented = typeOf(allowed) === 'regexp';\n  return isEmpty(input)\n    ? false\n    : [...input].every((char) => {\n      const isRoma = isCharRomaji(char);\n      return !augmented ? isRoma : isRoma || allowed.test(char);\n    });\n}\n\n/**\n * Tests a character. Returns true if the character is [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharKatakana(char = '') {\n  return isCharInRange(char, KATAKANA_START, KATAKANA_END);\n}\n\n/**\n * Tests a character. Returns true if the character is [Hiragana](https://en.wikipedia.org/wiki/Hiragana) or [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharKana(char = '') {\n  if (isEmpty(char)) return false;\n  return isCharHiragana(char) || isCharKatakana(char);\n}\n\n/**\n * Test if `input` is [Kana](https://en.wikipedia.org/wiki/Kana) ([Katakana](https://en.wikipedia.org/wiki/Katakana) and/or [Hiragana](https://en.wikipedia.org/wiki/Hiragana))\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Kana](https://en.wikipedia.org/wiki/Kana)\n * @example\n * isKana('„ÅÇ')\n * // => true\n * isKana('„Ç¢')\n * // => true\n * isKana('„ÅÇ„Éº„Ç¢')\n * // => true\n * isKana('A')\n * // => false\n * isKana('„ÅÇA„Ç¢')\n * // => false\n */\nfunction isKana(input = '') {\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharKana);\n}\n\n/**\n * Test if `input` is [Hiragana](https://en.wikipedia.org/wiki/Hiragana)\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Hiragana](https://en.wikipedia.org/wiki/Hiragana)\n * @example\n * isHiragana('„Åí„Éº„ÇÄ')\n * // => true\n * isHiragana('A')\n * // => false\n * isHiragana('„ÅÇ„Ç¢')\n * // => false\n */\nfunction isHiragana(input = '') {\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharHiragana);\n}\n\n/**\n * Test if `input` is [Katakana](https://en.wikipedia.org/wiki/Katakana)\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Katakana](https://en.wikipedia.org/wiki/Katakana)\n * @example\n * isKatakana('„Ç≤„Éº„É†')\n * // => true\n * isKatakana('„ÅÇ')\n * // => false\n * isKatakana('A')\n * // => false\n * isKatakana('„ÅÇ„Ç¢')\n * // => false\n */\nfunction isKatakana(input = '') {\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharKatakana);\n}\n\n/**\n * Returns true if char is '„ÄÖ'\n * @param  {String} char to test\n * @return {Boolean}\n */\nfunction isCharIterationMark(char = '') {\n  if (isEmpty(char)) return false;\n  return char.charCodeAt(0) === KANJI_ITERATION_MARK;\n}\n\n/**\n * Tests a character. Returns true if the character is a CJK ideograph (kanji).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharKanji(char = '') {\n  return isCharInRange(char, KANJI_START, KANJI_END) || isCharIterationMark(char);\n}\n\n/**\n * Tests if `input` is [Kanji](https://en.wikipedia.org/wiki/Kanji) ([Japanese CJK ideographs](https://en.wikipedia.org/wiki/CJK_Unified_Ideographs))\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Kanji](https://en.wikipedia.org/wiki/Kanji)\n * @example\n * isKanji('ÂàÄ')\n * // => true\n * isKanji('ÂàáËÖπ')\n * // => true\n * isKanji('Âã¢„ÅÑ')\n * // => false\n * isKanji('„ÅÇA„Ç¢')\n * // => false\n * isKanji('üê∏')\n * // => false\n */\nfunction isKanji(input = '') {\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharKanji);\n}\n\n/**\n * Test if `input` contains a mix of [Romaji](https://en.wikipedia.org/wiki/Romaji) *and* [Kana](https://en.wikipedia.org/wiki/Kana), defaults to pass through [Kanji](https://en.wikipedia.org/wiki/Kanji)\n * @param  {String} input text\n * @param  {Object} [options={ passKanji: true }] optional config to pass through kanji\n * @return {Boolean} true if mixed\n * @example\n * isMixed('Ab„ÅÇ„Ç¢'))\n * // => true\n * isMixed('„ÅäËÖπA')) // ignores kanji by default\n * // => true\n * isMixed('„ÅäËÖπA', { passKanji: false }))\n * // => false\n * isMixed('ab'))\n * // => false\n * isMixed('„ÅÇ„Ç¢'))\n * // => false\n */\nfunction isMixed(input = '', options = { passKanji: true }) {\n  const chars = [...input];\n  let hasKanji = false;\n  if (!options.passKanji) {\n    hasKanji = chars.some(isKanji);\n  }\n  return (chars.some(isHiragana) || chars.some(isKatakana)) && chars.some(isRomaji) && !hasKanji;\n}\n\nconst isCharInitialLongDash = (char, index) => isCharLongDash(char) && index < 1;\nconst isCharInnerLongDash = (char, index) => isCharLongDash(char) && index > 0;\nconst isKanaAsSymbol = (char) => ['„É∂', '„Éµ'].includes(char);\nconst LONG_VOWELS = {\n  a: '„ÅÇ',\n  i: '„ÅÑ',\n  u: '„ÅÜ',\n  e: '„Åà',\n  o: '„ÅÜ',\n};\n\n// inject toRomaji to avoid circular dependency between toRomaji <-> katakanaToHiragana\nfunction katakanaToHiragana(\n  input = '',\n  toRomaji,\n  { isDestinationRomaji, convertLongVowelMark } = {}\n) {\n  let previousKana = '';\n\n  return input\n    .split('')\n    .reduce((hira, char, index) => {\n      // Short circuit to avoid incorrect codeshift for '„Éº' and '„Éª'\n      if (\n        isCharSlashDot(char)\n        || isCharInitialLongDash(char, index)\n        || isKanaAsSymbol(char)\n      ) {\n        return hira.concat(char);\n      }\n\n      // Transform long vowels: '„Ç™„Éº' to '„Åä„ÅÜ'\n      if (\n        convertLongVowelMark\n        && previousKana\n        && isCharInnerLongDash(char, index)\n      ) {\n        // Transform previousKana back to romaji, and slice off the vowel\n        const romaji = toRomaji(previousKana).slice(-1);\n        // However, ensure '„Ç™„Éº' => '„Åä„Åä' => 'oo' if this is a transform on the way to romaji\n        if (\n          isCharKatakana(input[index - 1])\n          && romaji === 'o'\n          && isDestinationRomaji\n        ) {\n          return hira.concat('„Åä');\n        }\n        return hira.concat(LONG_VOWELS[romaji]);\n        // Transform all other chars\n      }\n\n      if (!isCharLongDash(char) && isCharKatakana(char)) {\n        const code = char.charCodeAt(0) + (HIRAGANA_START - KATAKANA_START);\n        const hiraChar = String.fromCharCode(code);\n        previousKana = hiraChar;\n        return hira.concat(hiraChar);\n      }\n\n      // Pass non katakana chars through\n      previousKana = '';\n      return hira.concat(char);\n    }, [])\n    .join('');\n}\n\nlet kanaToHepburnMap = null;\n\n/* eslint-disable */\n// prettier-ignore\nconst BASIC_ROMAJI = {\n  „ÅÇ:'a',    „ÅÑ:'i',   „ÅÜ:'u',   „Åà:'e',    „Åä:'o',\n  „Åã:'ka',   „Åç:'ki',  „Åè:'ku',  „Åë:'ke',   „Åì:'ko',\n  „Åï:'sa',   „Åó:'shi', „Åô:'su',  „Åõ:'se',   „Åù:'so',\n  „Åü:'ta',   „Å°:'chi', „Å§:'tsu', „Å¶:'te',   „Å®:'to',\n  „Å™:'na',   „Å´:'ni',  „Å¨:'nu',  „Å≠:'ne',   „ÅÆ:'no',\n  „ÅØ:'ha',   „Å≤:'hi',  „Åµ:'fu',  „Å∏:'he',   „Åª:'ho',\n  „Åæ:'ma',   „Åø:'mi',  „ÇÄ:'mu',  „ÇÅ:'me',   „ÇÇ:'mo',\n  „Çâ:'ra',   „Çä:'ri',  „Çã:'ru',  „Çå:'re',   „Çç:'ro',\n  „ÇÑ:'ya',   „ÇÜ:'yu',  „Çà:'yo',\n  „Çè:'wa',   „Çê:'wi',  „Çë:'we',  „Çí:'wo',\n  „Çì: 'n',\n  „Åå:'ga',   „Åé:'gi',  „Åê:'gu',  „Åí:'ge',   „Åî:'go',\n  „Åñ:'za',   „Åò:'ji',  „Åö:'zu',  „Åú:'ze',   „Åû:'zo',\n  „Å†:'da',   „Å¢:'ji',  „Å•:'zu',  „Åß:'de',   „Å©:'do',\n  „Å∞:'ba',   „Å≥:'bi',  „Å∂:'bu',  „Åπ:'be',   „Åº:'bo',\n  „Å±:'pa',   „Å¥:'pi',  „Å∑:'pu',  „Å∫:'pe',   „ÅΩ:'po',\n  „Çî„ÅÅ:'va', „Çî„ÅÉ:'vi', „Çî:'vu',  „Çî„Åá:'ve', „Çî„Åâ:'vo',\n};\n/* eslint-enable  */\n\nconst SPECIAL_SYMBOLS = {\n  '„ÄÇ': '.',\n  '„ÄÅ': ',',\n  'Ôºö': ':',\n  '„Éª': '/',\n  'ÔºÅ': '!',\n  'Ôºü': '?',\n  '„Äú': '~',\n  '„Éº': '-',\n  '„Äå': '‚Äò',\n  '„Äç': '‚Äô',\n  '„Äé': '‚Äú',\n  '„Äè': '‚Äù',\n  'Ôºª': '[',\n  'ÔºΩ': ']',\n  'Ôºà': '(',\n  'Ôºâ': ')',\n  'ÔΩõ': '{',\n  'ÔΩù': '}',\n  '„ÄÄ': ' ',\n};\n\n// „Çì„ÅÑ -> n'i\nconst AMBIGUOUS_VOWELS = ['„ÅÇ', '„ÅÑ', '„ÅÜ', '„Åà', '„Åä', '„ÇÑ', '„ÇÜ', '„Çà'];\nconst SMALL_Y = { „ÇÉ: 'ya', „ÇÖ: 'yu', „Çá: 'yo' };\nconst SMALL_Y_EXTRA = { „ÅÉ: 'yi', „Åá: 'ye' };\nconst SMALL_AIUEO = {\n  „ÅÅ: 'a',\n  „ÅÉ: 'i',\n  „ÅÖ: 'u',\n  „Åá: 'e',\n  „Åâ: 'o',\n};\nconst YOON_KANA = [\n  '„Åç',\n  '„Å´',\n  '„Å≤',\n  '„Åø',\n  '„Çä',\n  '„Åé',\n  '„Å≥',\n  '„Å¥',\n  '„Çî',\n  '„Åè',\n  '„Åµ',\n];\nconst YOON_EXCEPTIONS = {\n  „Åó: 'sh',\n  „Å°: 'ch',\n  „Åò: 'j',\n  „Å¢: 'j',\n};\nconst SMALL_KANA = {\n  „Å£: '',\n  „ÇÉ: 'ya',\n  „ÇÖ: 'yu',\n  „Çá: 'yo',\n  „ÅÅ: 'a',\n  „ÅÉ: 'i',\n  „ÅÖ: 'u',\n  „Åá: 'e',\n  „Åâ: 'o',\n};\n\n// going with the intuitive (yet incorrect) solution where „Å£„ÇÑ -> yya and „Å£„ÅÉ -> ii\n// in other words, just assume the sokuon could have been applied to anything\nconst SOKUON_WHITELIST = {\n  b: 'b',\n  c: 't',\n  d: 'd',\n  f: 'f',\n  g: 'g',\n  h: 'h',\n  j: 'j',\n  k: 'k',\n  m: 'm',\n  p: 'p',\n  q: 'q',\n  r: 'r',\n  s: 's',\n  t: 't',\n  v: 'v',\n  w: 'w',\n  x: 'x',\n  z: 'z',\n};\n\nfunction getKanaToHepburnTree() {\n  if (kanaToHepburnMap == null) {\n    kanaToHepburnMap = createKanaToHepburnMap();\n  }\n  return kanaToHepburnMap;\n}\n\nfunction getKanaToRomajiTree(romanization) {\n  switch (romanization) {\n    case ROMANIZATIONS.HEPBURN:\n      return getKanaToHepburnTree();\n    default:\n      return {};\n  }\n}\n\nfunction createKanaToHepburnMap() {\n  const romajiTree = transform(BASIC_ROMAJI);\n\n  const subtreeOf = (string) => getSubTreeOf(romajiTree, string);\n  const setTrans = (string, transliteration) => {\n    subtreeOf(string)[''] = transliteration;\n  };\n\n  Object.entries(SPECIAL_SYMBOLS).forEach(([jsymbol, symbol]) => {\n    subtreeOf(jsymbol)[''] = symbol;\n  });\n\n  [...Object.entries(SMALL_Y), ...Object.entries(SMALL_AIUEO)].forEach(\n    ([roma, kana]) => {\n      setTrans(roma, kana);\n    }\n  );\n\n  // „Åç„ÇÉ -> kya\n  YOON_KANA.forEach((kana) => {\n    const firstRomajiChar = subtreeOf(kana)[''][0];\n    Object.entries(SMALL_Y).forEach(([yKana, yRoma]) => {\n      setTrans(kana + yKana, firstRomajiChar + yRoma);\n    });\n    // „Åç„ÅÉ -> kyi\n    Object.entries(SMALL_Y_EXTRA).forEach(([yKana, yRoma]) => {\n      setTrans(kana + yKana, firstRomajiChar + yRoma);\n    });\n  });\n\n  Object.entries(YOON_EXCEPTIONS).forEach(([kana, roma]) => {\n    // „Åò„ÇÉ -> ja\n    Object.entries(SMALL_Y).forEach(([yKana, yRoma]) => {\n      setTrans(kana + yKana, roma + yRoma[1]);\n    });\n    // „Åò„ÅÉ -> jyi, „Åò„Åá -> je\n    setTrans(`${kana}„ÅÉ`, `${roma}yi`);\n    setTrans(`${kana}„Åá`, `${roma}e`);\n  });\n\n  romajiTree['„Å£'] = resolveTsu(romajiTree);\n\n  Object.entries(SMALL_KANA).forEach(([kana, roma]) => {\n    setTrans(kana, roma);\n  });\n\n  AMBIGUOUS_VOWELS.forEach((kana) => {\n    setTrans(`„Çì${kana}`, `n'${subtreeOf(kana)['']}`);\n  });\n\n  // NOTE: could be re-enabled with an option?\n  // // „Çì„Å∞ -> mbo\n  // const LABIAL = [\n  //   '„Å∞', '„Å≥', '„Å∂', '„Åπ', '„Åº',\n  //   '„Å±', '„Å¥', '„Å∑', '„Å∫', '„ÅΩ',\n  //   '„Åæ', '„Åø', '„ÇÄ', '„ÇÅ', '„ÇÇ',\n  // ];\n  // LABIAL.forEach((kana) => {\n  //   setTrans(`„Çì${kana}`, `m${subtreeOf(kana)['']}`);\n  // });\n\n  return Object.freeze(JSON.parse(JSON.stringify(romajiTree)));\n}\n\nfunction resolveTsu(tree) {\n  return Object.entries(tree).reduce((tsuTree, [key, value]) => {\n    if (!key) {\n      // we have reached the bottom of this branch\n      const consonant = value.charAt(0);\n      // eslint-disable-next-line no-param-reassign\n      tsuTree[key] = Object.keys(SOKUON_WHITELIST).includes(consonant)\n        ? SOKUON_WHITELIST[consonant] + value\n        : value;\n    } else {\n      // more subtrees\n      // eslint-disable-next-line no-param-reassign\n      tsuTree[key] = resolveTsu(value);\n    }\n    return tsuTree;\n  }, {});\n}\n\n// memoize and deeply compare args so we only recreate when necessary\nconst createKanaToRomajiMap = memoizeOne(\n  (romanization, customRomajiMapping) => {\n    let map = getKanaToRomajiTree(romanization);\n\n    if (customRomajiMapping) {\n      map = mergeCustomMapping(map, customRomajiMapping);\n    }\n\n    return map;\n  },\n  dequal\n);\n\n/**\n * Convert kana to romaji\n * @param  {String} kana text input\n * @param  {DefaultOptions} [options=defaultOptions]\n * @param  {Object} map custom mapping\n * @return {String} converted text\n * @example\n * toRomaji('„Å≤„Çâ„Åå„Å™„ÄÄ„Ç´„Çø„Ç´„Éä')\n * // => 'hiragana katakana'\n * toRomaji('„Åí„Éº„ÇÄ„ÄÄ„Ç≤„Éº„É†')\n * // => 'ge-mu geemu'\n * toRomaji('„Å≤„Çâ„Åå„Å™„ÄÄ„Ç´„Çø„Ç´„Éä', { upcaseKatakana: true })\n * // => 'hiragana KATAKANA'\n * toRomaji('„Å§„Åò„Åé„Çä', { customRomajiMapping: { „Åò: 'zi', „Å§: 'tu', „Çä: 'li' } });\n * // => 'tuzigili'\n */\nfunction toRomaji(input = '', options = {}, map) {\n  const config = mergeWithDefaultOptions(options);\n\n  if (!map) {\n    map = createKanaToRomajiMap(\n      config.romanization,\n      config.customRomajiMapping\n    );\n  }\n\n  // just throw away the substring index information and simply concatenate all the kana\n  return splitIntoRomaji(input, config, map)\n    .map((romajiToken) => {\n      const [start, end, romaji] = romajiToken;\n      const makeUpperCase = config.upcaseKatakana && isKatakana(input.slice(start, end));\n      return makeUpperCase ? romaji.toUpperCase() : romaji;\n    })\n    .join('');\n}\n\nfunction splitIntoRomaji(input, options, map) {\n  if (!map) {\n    map = createKanaToRomajiMap(\n      options.romanization,\n      options.customRomajiMapping\n    );\n  }\n\n  const config = Object.assign({}, { isDestinationRomaji: true }, options);\n\n  return applyMapping(\n    katakanaToHiragana(input, toRomaji, config),\n    map,\n    !options.IMEMode\n  );\n}\n\n/**\n * Tests a character. Returns true if the character is considered English punctuation.\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharEnglishPunctuation(char = '') {\n  if (isEmpty(char)) return false;\n  return EN_PUNCTUATION_RANGES.some(([start, end]) => isCharInRange(char, start, end));\n}\n\n/**\n * Convert input to [Hiragana](https://en.wikipedia.org/wiki/Hiragana)\n * @param  {String} [input=''] text\n * @param  {DefaultOptions} [options=defaultOptions]\n * @return {String} converted text\n * @example\n * toHiragana('toukyou, „Ç™„Ç™„Çµ„Ç´')\n * // => '„Å®„ÅÜ„Åç„Çá„ÅÜ„ÄÅ„ÄÄ„Åä„Åä„Åï„Åã'\n * toHiragana('only „Ç´„Éä', { passRomaji: true })\n * // => 'only „Åã„Å™'\n * toHiragana('wi')\n * // => '„ÅÜ„ÅÉ'\n * toHiragana('wi', { useObsoleteKana: true })\n * // => '„Çê'\n */\nfunction toHiragana(input = '', options = {}) {\n  const config = mergeWithDefaultOptions(options);\n  if (config.passRomaji) {\n    return katakanaToHiragana(input, toRomaji, config);\n  }\n\n  if (isMixed(input, { passKanji: true })) {\n    const convertedKatakana = katakanaToHiragana(input, toRomaji, config);\n    return toKana(convertedKatakana.toLowerCase(), config);\n  }\n\n  if (isRomaji(input) || isCharEnglishPunctuation(input)) {\n    return toKana(input.toLowerCase(), config);\n  }\n\n  return katakanaToHiragana(input, toRomaji, config);\n}\n\n/**\n * Convert input to [Katakana](https://en.wikipedia.org/wiki/Katakana)\n * @param  {String} [input=''] text\n * @param  {DefaultOptions} [options=defaultOptions]\n * @return {String} converted text\n * @example\n * toKatakana('toukyou, „Åä„Åä„Åï„Åã')\n * // => '„Éà„Ç¶„Ç≠„Éß„Ç¶„ÄÅ„ÄÄ„Ç™„Ç™„Çµ„Ç´'\n * toKatakana('only „Åã„Å™', { passRomaji: true })\n * // => 'only „Ç´„Éä'\n * toKatakana('wi')\n * // => '„Ç¶„Ç£'\n * toKatakana('wi', { useObsoleteKana: true })\n * // => '„É∞'\n */\nfunction toKatakana(input = '', options = {}) {\n  const mergedOptions = mergeWithDefaultOptions(options);\n  if (mergedOptions.passRomaji) {\n    return hiraganaToKatakana(input);\n  }\n\n  if (isMixed(input) || isRomaji(input) || isCharEnglishPunctuation(input)) {\n    const hiragana = toKana(input.toLowerCase(), mergedOptions);\n    return hiraganaToKatakana(hiragana);\n  }\n\n  return hiraganaToKatakana(input);\n}\n\n/**\n * Tests a character. Returns true if the character is considered Japanese punctuation.\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharJapanesePunctuation(char = '') {\n  if (isEmpty(char) || isCharIterationMark(char)) return false;\n  return JA_PUNCTUATION_RANGES.some(([start, end]) => isCharInRange(char, start, end));\n}\n\nconst isCharEnSpace = (x) => x === ' ';\nconst isCharJaSpace = (x) => x === '„ÄÄ';\nconst isCharJaNum = (x) => /[Ôºê-Ôºô]/.test(x);\nconst isCharEnNum = (x) => /[0-9]/.test(x);\n\nconst TOKEN_TYPES = {\n  EN: 'en',\n  JA: 'ja',\n  EN_NUM: 'englishNumeral',\n  JA_NUM: 'japaneseNumeral',\n  EN_PUNC: 'englishPunctuation',\n  JA_PUNC: 'japanesePunctuation',\n  KANJI: 'kanji',\n  HIRAGANA: 'hiragana',\n  KATAKANA: 'katakana',\n  SPACE: 'space',\n  OTHER: 'other',\n};\n\n// prettier-ignore\nfunction getType(input, compact = false) {\n  const {\n    EN, JA, EN_NUM, JA_NUM, EN_PUNC, JA_PUNC, KANJI, HIRAGANA, KATAKANA, SPACE, OTHER,\n  } = TOKEN_TYPES;\n\n  if (compact) {\n    switch (true) {\n      case isCharJaNum(input): return OTHER;\n      case isCharEnNum(input): return OTHER;\n      case isCharEnSpace(input): return EN;\n      case isCharEnglishPunctuation(input): return OTHER;\n      case isCharJaSpace(input): return JA;\n      case isCharJapanesePunctuation(input): return OTHER;\n      case isCharJapanese(input): return JA;\n      case isCharRomaji(input): return EN;\n      default: return OTHER;\n    }\n  } else {\n    switch (true) {\n      case isCharJaSpace(input): return SPACE;\n      case isCharEnSpace(input): return SPACE;\n      case isCharJaNum(input): return JA_NUM;\n      case isCharEnNum(input): return EN_NUM;\n      case isCharEnglishPunctuation(input): return EN_PUNC;\n      case isCharJapanesePunctuation(input): return JA_PUNC;\n      case isCharKanji(input): return KANJI;\n      case isCharHiragana(input): return HIRAGANA;\n      case isCharKatakana(input): return KATAKANA;\n      case isCharJapanese(input): return JA;\n      case isCharRomaji(input): return EN;\n      default: return OTHER;\n    }\n  }\n}\n\n/**\n * Splits input into array of strings separated by opinionated token types\n * `'en', 'ja', 'englishNumeral', 'japaneseNumeral','englishPunctuation', 'japanesePunctuation','kanji', 'hiragana', 'katakana', 'space', 'other'`.\n * If `{ compact: true }` then many same-language tokens are combined (spaces + text, kanji + kana, numeral + punctuation).\n * If `{ detailed: true }` then return array will contain `{ type, value }` instead of `'value'`\n * @param  {String} input text\n * @param  {Object} [options={ compact: false, detailed: false}] options to modify output style\n * @return {String|Object[]} text split into tokens containing values, or detailed object\n * @example\n * tokenize('„Åµ„Åµ„Éï„Éï')\n * // ['„Åµ„Åµ', '„Éï„Éï']\n *\n * tokenize('ÊÑü„Åò')\n * // ['ÊÑü', '„Åò']\n *\n * tokenize('‰∫∫„ÄÖ')\n * // ['‰∫∫„ÄÖ']\n *\n * tokenize('truly ÁßÅ„ÅØÊÇ≤„Åó„ÅÑ')\n * // ['truly', ' ', 'ÁßÅ', '„ÅØ', 'ÊÇ≤', '„Åó„ÅÑ']\n *\n * tokenize('truly ÁßÅ„ÅØÊÇ≤„Åó„ÅÑ', { compact: true })\n * // ['truly ', 'ÁßÅ„ÅØÊÇ≤„Åó„ÅÑ']\n *\n * tokenize('5romaji here...!?‰∫∫„ÄÖÊº¢Â≠ó„Å≤„Çâ„Åå„Å™„Ç´„Çø„ÄÄ„Ç´„ÉäÔºî„ÄåÔº≥Ôº®Ôº©ÔºØ„Äç„ÄÇÔºÅ')\n * // [ '5', 'romaji', ' ', 'here', '...!?', '‰∫∫„ÄÖÊº¢Â≠ó', '„Å≤„Çâ„Åå„Å™', '„Ç´„Çø', '„ÄÄ', '„Ç´„Éä', 'Ôºî', '„Äå', 'Ôº≥Ôº®Ôº©ÔºØ', '„Äç„ÄÇÔºÅ']\n *\n * tokenize('5romaji here...!?‰∫∫„ÄÖÊº¢Â≠ó„Å≤„Çâ„Åå„Å™„Ç´„Çø„ÄÄ„Ç´„ÉäÔºî„ÄåÔº≥Ôº®Ôº©ÔºØ„Äç„ÄÇÔºÅ', { compact: true })\n * // [ '5', 'romaji here', '...!?', '‰∫∫„ÄÖÊº¢Â≠ó„Å≤„Çâ„Åå„Å™„Ç´„Çø„ÄÄ„Ç´„Éä', 'Ôºî„Äå', 'Ôº≥Ôº®Ôº©ÔºØ', '„Äç„ÄÇÔºÅ']\n *\n * tokenize('5romaji here...!?‰∫∫„ÄÖÊº¢Â≠ó„Å≤„Çâ„Åå„Å™„Ç´„Çø„ÄÄ„Ç´„ÉäÔºî„ÄåÔº≥Ôº®Ôº©ÔºØ„Äç„ÄÇÔºÅ ŸÑŸÜÿ∞Ÿáÿ®', { detailed: true })\n * // [\n *  { type: 'englishNumeral', value: '5' },\n *  { type: 'en', value: 'romaji' },\n *  { type: 'space', value: ' ' },\n *  { type: 'en', value: 'here' },\n *  { type: 'englishPunctuation', value: '...!?' },\n *  { type: 'kanji', value: '‰∫∫„ÄÖÊº¢Â≠ó' },\n *  { type: 'hiragana', value: '„Å≤„Çâ„Åå„Å™' },\n *  { type: 'katakana', value: '„Ç´„Çø' },\n *  { type: 'space', value: '„ÄÄ' },\n *  { type: 'katakana', value: '„Ç´„Éä' },\n *  { type: 'japaneseNumeral', value: 'Ôºî' },\n *  { type: 'japanesePunctuation', value: '„Äå' },\n *  { type: 'ja', value: 'Ôº≥Ôº®Ôº©ÔºØ' },\n *  { type: 'japanesePunctuation', value: '„Äç„ÄÇÔºÅ' },\n *  { type: 'space', value: ' ' },\n *  { type: 'other', value: 'ŸÑŸÜÿ∞Ÿáÿ®' },\n * ]\n *\n * tokenize('5romaji here...!?‰∫∫„ÄÖÊº¢Â≠ó„Å≤„Çâ„Åå„Å™„Ç´„Çø„ÄÄ„Ç´„ÉäÔºî„ÄåÔº≥Ôº®Ôº©ÔºØ„Äç„ÄÇÔºÅ ŸÑŸÜÿ∞Ÿáÿ®', { compact: true, detailed: true})\n * // [\n *  { type: 'other', value: '5' },\n *  { type: 'en', value: 'romaji here' },\n *  { type: 'other', value: '...!?' },\n *  { type: 'ja', value: '‰∫∫„ÄÖÊº¢Â≠ó„Å≤„Çâ„Åå„Å™„Ç´„Çø„ÄÄ„Ç´„Éä' },\n *  { type: 'other', value: 'Ôºî„Äå' },\n *  { type: 'ja', value: 'Ôº≥Ôº®Ôº©ÔºØ' },\n *  { type: 'other', value: '„Äç„ÄÇÔºÅ' },\n *  { type: 'en', value: ' ' },\n *  { type: 'other', value: 'ŸÑŸÜÿ∞Ÿáÿ®' },\n *]\n */\nfunction tokenize(input, { compact = false, detailed = false } = {}) {\n  if (input == null || isEmpty(input)) {\n    return [];\n  }\n  const chars = [...input];\n  let initial = chars.shift();\n  let prevType = getType(initial, compact);\n  initial = detailed ? { type: prevType, value: initial } : initial;\n\n  const result = chars.reduce(\n    (tokens, char) => {\n      const currType = getType(char, compact);\n      const sameType = currType === prevType;\n      prevType = currType;\n      let newValue = char;\n\n      if (sameType) {\n        newValue = (detailed ? tokens.pop().value : tokens.pop()) + newValue;\n      }\n\n      return detailed\n        ? tokens.concat({ type: currType, value: newValue })\n        : tokens.concat(newValue);\n    },\n    [initial]\n  );\n  return result;\n}\n\nconst isLeadingWithoutInitialKana = (input, leading) => leading && !isKana(input[0]);\nconst isTrailingWithoutFinalKana = (input, leading) => !leading && !isKana(input[input.length - 1]);\nconst isInvalidMatcher = (input, matchKanji) =>\n  (matchKanji && ![...matchKanji].some(isKanji)) || (!matchKanji && isKana(input));\n\n/**\n * Strips [Okurigana](https://en.wikipedia.org/wiki/Okurigana)\n * @param  {String} input text\n * @param  {Object} [options={ leading: false, matchKanji: '' }] optional config\n * @return {String} text with okurigana removed\n * @example\n * stripOkurigana('Ë∏è„ÅøËæº„ÇÄ')\n * // => 'Ë∏è„ÅøËæº'\n * stripOkurigana('„ÅäÁ•ù„ÅÑ')\n * // => '„ÅäÁ•ù'\n * stripOkurigana('„ÅäËÖπ', { leading: true });\n * // => 'ËÖπ'\n * stripOkurigana('„Åµ„Åø„Åì„ÇÄ', { matchKanji: 'Ë∏è„ÅøËæº„ÇÄ' });\n * // => '„Åµ„Åø„Åì'\n * stripOkurigana('„Åä„Åø„Åæ„ÅÑ', { matchKanji: '„ÅäÁ•ù„ÅÑ', leading: true });\n * // => '„Åø„Åæ„ÅÑ'\n */\nfunction stripOkurigana(input = '', { leading = false, matchKanji = '' } = {}) {\n  if (\n    !isJapanese(input) ||\n    isLeadingWithoutInitialKana(input, leading) ||\n    isTrailingWithoutFinalKana(input, leading) ||\n    isInvalidMatcher(input, matchKanji)\n  ) {\n    return input;\n  }\n\n  const chars = matchKanji || input;\n  const okuriganaRegex = new RegExp(\n    leading ? `^${tokenize(chars).shift()}` : `${tokenize(chars).pop()}$`\n  );\n  return input.replace(okuriganaRegex, '');\n}\n\nexport { ROMANIZATIONS, TO_KANA_METHODS, VERSION, bind, isHiragana, isJapanese, isKana, isKanji, isKatakana, isMixed, isRomaji, stripOkurigana, toHiragana, toKana, toKatakana, toRomaji, tokenize, unbind };\n//# sourceMappingURL=index.js.map\n","var arrayZip = zip;\n\n/*\n  zip([1, 2, 3]); // [[1], [2], [3]]\n  zip([1, 2, 3], ['a', 'b', 'c']); // [[1, 'a'], [2, 'b'], [3, 'c']]\n  zip([1, 2], ['a', 'b'], [true, false]); //[[1, 'a', true], [2, 'b', false]]\n\n  zip([1, 2, 3], ['a', 'b'], [true]);\n  // [[1, 'a', true], [2, 'b', undefined], [3, undefined, undefined]]\n\n  zip(undefined, {}, false, 1, 'foo'); // throws\n  zip([1, 2], ['a', 'b'], undefined, {}, false, 1, 'foo'); // throws\n*/\n\nfunction zip() {\n  var result = [];\n  var args = Array.prototype.slice.call(arguments);\n  var argsLen = args.length;\n  var maxLen = 0;\n  var i, j;\n\n  if (!argsLen) {\n    throw new Error('zip requires at least one argument');\n  }\n\n  for (i = 0; i < argsLen; i++) {\n    if (!Array.isArray(args[i])) {\n      throw new Error('all arguments must be arrays');\n    }\n    var arrLen = args[i].length;\n    if (arrLen > maxLen) {\n      maxLen = arrLen;\n    }\n  }\n\n  for (i = 0; i < maxLen; i++) {\n    var group = [];\n    for (j = 0; j < argsLen; j++) {\n      if (!Array.isArray(args[j])) {\n        throw new Error('all arguments must be arrays');\n      }\n      group[j] = args[j][i];\n    }\n    result[i] = group;\n  }\n\n  return result;\n}\n\nexport {arrayZip as default};\n","import { stripOkurigana, tokenize, isKanji, isKana, isHiragana, isKatakana } from 'wanakana';\nimport zip from 'just-zip-it';\n\n/**\n * Combines furigana with kanji into an array of string pairs.\n * @param  {String} word vocab kanji word\n * @param  {String} reading vocab kana reading\n * @param  {String|Object} furi furigana placement info\n * @return {Array} furigana/kanji pairs\n * @example\n * combineFuri('„Åä‰∏ñËæû', '„Åä„Åõ„Åò', '1:„Åõ;2:„Åò')\n * // => [['', '„Åä'], ['„Åõ', '‰∏ñ'], ['„Åò', 'Ëæû']]\n * combineFuri('Â§ß‰∫∫„Åó„ÅÑ', '„Åä„Å®„Å™„Åó„ÅÑ') // smart fallbacks\n * // => [['„Åä„Å®„Å™', 'Â§ß‰∫∫'], ['', '„Åó„ÅÑ']]\n * combineFuri('‰Ωø„ÅÑÊñπ', '„Å§„Åã„ÅÑ„Åã„Åü') // smart fallbacks\n * // => [['„Å§„Åã', '‰Ωø'], ['', '„ÅÑ'], ['„Åã„Åü', 'Êñπ']]\n *\n * // special compound readings (Áæ©Ë®ì/ÁÜüÂ≠óË®ì) are spread across relevant kanji\n * combineFuri('ËÉ°Â∫ß', '„ÅÇ„Åê„Çâ', '0:„ÅÇ„Åê„Çâ')\n * // => [['„ÅÇ„Åê„Çâ', 'ËÉ°Â∫ß']]\n */\nexport function combineFuri(word = '', reading = '', furi = '') {\n  const furiLocs = parseFuri(furi);\n  // Áæ©Ë®ì/ÁÜüÂ≠óË®ì words with a single furi loc: ‰ªäÊó• \"0:„Åç„Çá„ÅÜ\"\n  const isSpecialReading = furiLocs.length === 1 && [...word].every(isKanji);\n  const isKanaWord = [...word].every(isKana);\n  const isWanikaniMadness = [...reading].some(isHiragana) && [...reading].some(isKatakana);\n\n  if (word === reading || isKanaWord) {\n    return [['', word]];\n  }\n\n  if (!furi || isSpecialReading || isWanikaniMadness) {\n    return basicFuri(word, reading);\n  }\n\n  return generatePairs(word, furiLocs);\n}\n\n/**\n * Displays simple furigana by removing redundant kana\n * @param  {String} [word=''] '„ÅäË¶ãËàû„ÅÑ'\n * @param  {String} [reading=''] '„Åä„Åø„Åæ„ÅÑ'\n * @return {Array} [['', '„Åä'], ['Ë¶ãËàû', '„Åø„Åæ'], ['', '„ÅÑ']]\n */\nexport function basicFuri(word = '', reading = '') {\n  // early return + guard against words like ÔºëÊó• which are tokenized unfavourably\n  if ([...word].every((c) => !isKana(c))) {\n    return [[reading, word]];\n  }\n\n  const [bikago, okurigana] = [\n    reading.slice(0, word.length - stripOkurigana(word, { leading: true }).length),\n    reading.slice(stripOkurigana(reading, { matchKanji: word }).length),\n  ];\n\n  const innerWordTokens = tokenize(removeExtraneousKana(word, bikago, okurigana));\n  let innerReadingChars = removeExtraneousKana(reading, bikago, okurigana);\n\n  const kanjiOddKanaEvenRegex = RegExp(\n    innerWordTokens.map((char) => (isKanji(char) ? '(.*)' : `(${char})`)).join(''),\n  );\n\n  [, ...innerReadingChars] = innerReadingChars.match(kanjiOddKanaEvenRegex) || [];\n\n  const ret = zip(innerReadingChars, innerWordTokens).map(skipRedundantReadings);\n\n  if (bikago) {\n    ret.unshift(['', bikago]);\n  }\n\n  if (okurigana) {\n    ret.push(['', okurigana]);\n  }\n\n  return ret;\n}\n\nfunction removeExtraneousKana(str = '', leading = '', trailing = '') {\n  return str.replace(RegExp(`^${leading}`), '').replace(RegExp(`${trailing}$`), '');\n}\n\nfunction skipRedundantReadings([reading, word = '']) {\n  return !reading || reading === word ? ['', word] : [reading, word];\n}\n\nexport function parseFuri(data) {\n  return typeof data === 'string' ? parseFuriString(data) : parseFuriObject(data);\n}\n\n/**\n * Parses furigana placement object\n * @param  {Object} [locations={}] { 1:'„Åõ', 2:'„Åò' }\n * @return {Array} [ [[1, 2], '„Åõ'], [[2, 3], '„Åò'] ]\n */\nfunction parseFuriObject(locations = {}) {\n  return Object.entries(locations).map(([start, content]) => [\n    [Number(start), Number(start) + 1],\n    content,\n  ]);\n}\n\n/**\n * Parses furigana placement string\n * @param  {String} [locations=''] '1:„Åõ;2:„Åò'\n * @return {Array} [ [[1, 2], '„Åõ'], [[2, 3], '„Åò'] ]\n */\nfunction parseFuriString(locations = '') {\n  return locations.split(';').map((entry) => {\n    const [indexes, content] = entry.split(':');\n    const [start, end] = indexes.split('-').map(Number);\n    // NOTE: in the JMDict furistring data, the end index is either missing\n    // or it is listed as the *start* index of the final char ¬Ø\\_(„ÉÑ)_/¬Ø\n    // so we need to bump it either way to encompass that char\n    return [[start, end ? end + 1 : start + 1], content];\n  });\n}\n\n/**\n * Generates array pairs via furigana location data\n * @param  {String} word '„Åä‰∏ñËæû'\n * @param  {Array} furiLocs [[[1, 2], '„Åõ'], [[2, 3], '„Åò']]\n * @return {Array} [['', '„Åä'], ['„Åõ', '‰∏ñ'], ['„Åò', 'Ëæû']]\n */\nexport function generatePairs(word = '', furiLocs = []) {\n  let prevCharEnd = 0;\n\n  return furiLocs.reduce((pairs, [[start, end], furiText], index, source) => {\n    // if no furigana at this index, add intervening chars\n    if (start !== prevCharEnd) {\n      pairs.push(['', word.slice(prevCharEnd, start)]);\n    }\n\n    // add furigana and associated chars\n    pairs.push([furiText, word.slice(start, end)]);\n\n    // if no more furigana left, add any remaining chars/okurigana with blank furi\n    if (end < word.length && !source[index + 1]) {\n      pairs.push(['', word.slice(end)]);\n    }\n\n    prevCharEnd = end;\n    return pairs;\n  }, []);\n}\n","import React from 'react';\nimport { combineFuri } from './utils';\n\nexport function useFuriPairs(word, reading, furi) {\n  return React.useMemo(() => combineFuri(word, reading, furi), [word, reading, furi]);\n}\n","import React from 'react';\n\nimport { useFuriPairs } from './hooks';\n\nconst wrapperStyle = {\n  display: 'inline-flex',\n  flexFlow: 'row wrap',\n  fontFamily: `'„Éí„É©„ÇÆ„ÉéËßí„Ç¥ ProN', 'Hiragino Kaku Gothic ProN', 'TakaoP„Ç¥„Ç∑„ÉÉ„ÇØ', TakaoPGothic, 'Ê∏∏„Ç¥„Ç∑„ÉÉ„ÇØ', 'Ê∏∏„Ç¥„Ç∑„ÉÉ„ÇØ‰Ωì', YuGothic, 'Yu Gothic', '„É°„Ç§„É™„Ç™', Meiryo, 'Ôº≠Ôº≥ „Ç¥„Ç∑„ÉÉ„ÇØ', 'MS Gothic', HiraKakuProN-W3, 'MotoyaLCedar', 'Droid Sans Japanese', sans-serif`,\n};\n\nconst pairStyle = {\n  display: 'inline-flex',\n  fontSize: '24px',\n  lineHeight: '1',\n  flexFlow: 'column nowrap',\n  justifyContent: 'flex-end',\n  alignItems: 'center',\n  alignSelf: 'flex-end',\n};\n\nconst furiStyle = {\n  display: 'block',\n  fontSize: '0.5em',\n  letterSpacing: '-0.02em',\n  margin: '0 0.1em',\n  paddingTop: '0.2em',\n  paddingBottom: '0.1em',\n  // don't interfere with selection of the content text\n  userSelect: 'none',\n  opacity: '0.9',\n};\n\nconst textStyle = {\n  display: 'block',\n};\n\nexport function Wrapper({ style, ...props }) {\n  return <span lang=\"ja\" style={{ ...wrapperStyle, ...style }} {...props} />;\n}\n\nexport function Pair({ style, ...props }) {\n  return <span lang=\"ja\" style={{ ...pairStyle, ...style }} {...props} />;\n}\n\nexport function Furi({ style, ...props }) {\n  return <span lang=\"ja\" style={{ ...furiStyle, ...style }} {...props} />;\n}\n\nexport function Text({ style, ...props }) {\n  return <span lang=\"ja\" style={{ ...textStyle, ...style }} {...props} />;\n}\n\nexport function ReactFuri({ word, reading, furi, showFuri, render, ...props }) {\n  const pairs = useFuriPairs(word, reading, furi);\n\n  return typeof render === 'function' ? (\n    render({ pairs })\n  ) : (\n    <Wrapper {...props}>\n      {pairs.map(([furiText, text], index) => {\n        const uniquePairKey = text + index;\n\n        return (\n          <Pair key={uniquePairKey}>\n            {showFuri && <Furi>{furiText}</Furi>}\n            <Text>{text}</Text>\n          </Pair>\n        );\n      })}\n    </Wrapper>\n  );\n}\n\nReactFuri.defaultProps = {\n  word: '',\n  reading: '',\n  furi: '',\n  showFuri: true,\n};\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,MAAMA,CAACC,KAAK,EAAE;EACrB,IAAIA,KAAK,KAAK,IAAI,EAAE;IAClB,OAAO,MAAM;EACjB;EACE,IAAIA,KAAK,KAAKC,MAAM,CAACD,KAAK,CAAC,EAAE;IAC3B,OAAO,OAAOA,KAAK;EACvB;EACE,OAAO,EAAE,CAACE,QAAQ,CACfC,IAAI,CAACH,KAAK,CAAC,CACXI,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CACZC,WAAW,EAAE;AAClB;;AAEA;AACA;AACA;AACA;AACA;AACA,SAASC,OAAOA,CAACC,KAAK,EAAE;EACtB,IAAIR,MAAM,CAACQ,KAAK,CAAC,KAAK,QAAQ,EAAE;IAC9B,OAAO,IAAI;EACf;EACE,OAAO,CAACA,KAAK,CAACC,MAAM;AACtB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASC,aAAaA,CAACC,IAAI,GAAG,EAAE,EAAEC,KAAK,EAAEC,GAAG,EAAE;EAC5C,IAAIN,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,MAAMG,IAAI,GAAGH,IAAI,CAACI,UAAU,CAAC,CAAC,CAAC;EAC/B,OAAOH,KAAK,IAAIE,IAAI,IAAIA,IAAI,IAAID,GAAG;AACrC;AAsDA,MAAMG,uBAAuB,GAAG,MAAM;AACtC,MAAMC,qBAAqB,GAAG,MAAM;AACpC,MAAMC,uBAAuB,GAAG,MAAM;AACtC,MAAMC,qBAAqB,GAAG,MAAM;AACpC,MAAMC,cAAc,GAAG,MAAM;AAC7B,MAAMC,YAAY,GAAG,MAAM;AAC3B,MAAMC,cAAc,GAAG,MAAM;AAC7B,MAAMC,YAAY,GAAG,MAAM;AAC3B,MAAMC,WAAW,GAAG,MAAM;AAC1B,MAAMC,SAAS,GAAG,MAAM;AAExB,MAAMC,oBAAoB,GAAG,MAAM,CAAC;AACpC,MAAMC,oBAAoB,GAAG,MAAM,CAAC;;AAGpC,MAAMC,eAAe,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACxC,MAAMC,iBAAiB,GAAG,CAACX,uBAAuB,EAAEC,qBAAqB,CAAC;AAC1E,MAAMW,iBAAiB,GAAG,CAACd,uBAAuB,EAAEC,qBAAqB,CAAC;AAC1E,MAAMc,qBAAqB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAC9C,MAAMC,qBAAqB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAC9C,MAAMC,qBAAqB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAC9C,MAAMC,qBAAqB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAC9C,MAAMC,wBAAwB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAEjD,MAAMC,cAAc,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACvC,MAAMC,cAAc,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACvC,MAAMC,gBAAgB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACzC,MAAMC,oBAAoB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAC7C,MAAMC,gBAAgB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACzC,MAAMC,uBAAuB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAChD,MAAMC,UAAU,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACnC,MAAMC,QAAQ,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAEjC,MAAMC,WAAW,GAAG,CAClBR,cAAc,EACdC,cAAc,EACdG,gBAAgB,EAChBF,gBAAgB,CACjB;AAED,MAAMO,qBAAqB,GAAG,CAC5BJ,uBAAuB,EACvBD,gBAAgB,EAChBD,oBAAoB,EACpBR,qBAAqB,EACrBC,qBAAqB,EACrBC,qBAAqB,EACrBC,qBAAqB,EACrBC,wBAAwB,CACzB;;AAED;AACA;AACA,MAAMW,eAAe,GAAG,CACtB,GAAGF,WAAW,EACd,GAAGC,qBAAqB,EACxBhB,iBAAiB,EACjBC,iBAAiB,EACjBF,eAAe,EACfc,UAAU,EACVC,QAAQ,CACT;AAED,MAAMI,cAAc,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACvC,MAAMC,qBAAqB,GAAG,CAC5B,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA;AAChB,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA;AAChB,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA;AAChB,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA;AAChB,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA,CACjB;;AACD,MAAMC,kBAAkB,GAAG,CACzB,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA;AAChB,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA,CACjB;;AAED,MAAMC,aAAa,GAAG,CAACH,cAAc,EAAE,GAAGC,qBAAqB,CAAC;AAEhE,MAAMG,qBAAqB,GAAG,CAC5B,CAAC,IAAI,EAAE,IAAI,CAAC,EACZ,CAAC,IAAI,EAAE,IAAI,CAAC,EACZ,CAAC,IAAI,EAAE,IAAI,CAAC,EACZ,CAAC,IAAI,EAAE,IAAI,CAAC,EACZ,GAAGF,kBAAkB,CACtB;;AAED;AACA;AACA;AACA;AACA;AACA,SAASG,cAAcA,CAACzC,IAAI,GAAG,EAAE,EAAE;EACjC,OAAOmC,eAAe,CAACO,IAAI,CAAC,CAAC,CAACzC,KAAK,EAAEC,GAAG,CAAC,KAAKH,aAAa,CAACC,IAAI,EAAEC,KAAK,EAAEC,GAAG,CAAC,CAAC;AAChF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASyC,UAAUA,CAAC9C,KAAK,GAAG,EAAE,EAAE+C,OAAO,EAAE;EACvC,MAAMC,SAAS,GAAGxD,MAAM,CAACuD,OAAO,CAAC,KAAK,QAAQ;EAC9C,OAAOhD,OAAO,CAACC,KAAK,CAAC,GACjB,KAAK,GACL,CAAC,GAAGA,KAAK,CAAC,CAACiD,KAAK,CAAE9C,IAAI,IAAK;IAC3B,MAAM+C,IAAI,GAAGN,cAAc,CAACzC,IAAI,CAAC;IACjC,OAAO,CAAC6C,SAAS,GAAGE,IAAI,GAAGA,IAAI,IAAIH,OAAO,CAACI,IAAI,CAAChD,IAAI,CAAC;EAC3D,CAAK,CAAC;AACN;;AA6NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASiD,mBAAmBA,CAACC,SAAS,GAAG,EAAE,EAAE;EAC3C,MAAMC,UAAU,GAAG,EAAE;EAErB,IAAI9D,MAAM,CAAC6D,SAAS,CAAC,KAAK,QAAQ,EAAE;IAClC3D,MAAM,CAAC6D,OAAO,CAACF,SAAS,CAAC,CAACG,OAAO,CAAC,CAAC,CAACC,IAAI,EAAEC,IAAI,CAAC,KAAK;MAClD,IAAIC,OAAO,GAAGL,UAAU;MACxBG,IAAI,CAACG,KAAK,CAAC,EAAE,CAAC,CAACJ,OAAO,CAAErD,IAAI,IAAK;QAC/B,IAAIwD,OAAO,CAACxD,IAAI,CAAC,KAAK0D,SAAS,EAAE;UAC/BF,OAAO,CAACxD,IAAI,CAAC,GAAG,EAAE;QAC5B;QACQwD,OAAO,GAAGA,OAAO,CAACxD,IAAI,CAAC;MAC/B,CAAO,CAAC;MACFwD,OAAO,CAAC,EAAE,CAAC,GAAGD,IAAI;IACxB,CAAK,CAAC;EACN;EAEE,OAAO,SAASI,OAAOA,CAACC,GAAG,EAAE;IAC3B,MAAMC,OAAO,GAAGC,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,SAAS,CAACJ,GAAG,CAAC,CAAC;IAE/C,SAASK,YAAYA,CAACC,UAAU,EAAEC,aAAa,EAAE;MAC/C,IAAID,UAAU,KAAKR,SAAS,IAAIrE,MAAM,CAAC6E,UAAU,CAAC,KAAK,QAAQ,EAAE;QAC/D,OAAOC,aAAa;MAC5B;MACM,OAAO5E,MAAM,CAAC6D,OAAO,CAACe,aAAa,CAAC,CAACC,MAAM,CACzC,CAACC,UAAU,EAAE,CAACrE,IAAI,EAAEsE,OAAO,CAAC,KAAK;QACzC;QACUD,UAAU,CAACrE,IAAI,CAAC,GAAGiE,YAAY,CAACC,UAAU,CAAClE,IAAI,CAAC,EAAEsE,OAAO,CAAC;QAC1D,OAAOD,UAAU;MAC3B,CAAS,EACDH,UACR,CAAO;IACP;IAEI,OAAOD,YAAY,CAACJ,OAAO,EAAEV,UAAU,CAAC;EAC5C,CAAG;AACH;AAwEA,MAAMoB,SAAS,GAAG;EAAEC,EAAE,EAAE,GAAG;EAAEC,EAAE,EAAE,GAAG;EAAEC,EAAE,EAAE,GAAG;EAAEC,EAAE,EAAE,GAAG;EAAEC,EAAE,EAAE;AAAG,CAAE;AACjE,MAAMC,YAAY,GAAG;EAAEC,CAAC,EAAE,GAAG;EAAEC,CAAC,EAAE,GAAG;EAAEC,CAAC,EAAE,GAAG;EAAEC,CAAC,EAAE,GAAG;EAAEC,CAAC,EAAE;AAAG,CAAE;;AAoB/D;AACsB3F,MAAM,CAAC4F,MAAM,CACjC;EACEC,EAAE,EAAE,GAAG;EACPC,EAAE,EAAE,GAAG;EACPC,EAAE,EAAE,GAAG;EACPC,EAAE,EAAE;AACR,CAAG,EACDV,YAAY,EACZN,SACF;AAiJ8BtB,mBAAmB,CAAC;EAChDuC,EAAE,EAAE,GAAG;EACPC,EAAE,EAAE;AACN,CAAC;;AAoBD;AACA;AACA;AACA;AACA;AACA,SAASC,cAAcA,CAAC1F,IAAI,GAAG,EAAE,EAAE;EACjC,IAAIJ,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,OAAOA,IAAI,CAACI,UAAU,CAAC,CAAC,CAAC,KAAKY,oBAAoB;AACpD;;AAYA;AACA;AACA;AACA;AACA;AACA,SAAS2E,cAAcA,CAAC3F,IAAI,GAAG,EAAE,EAAE;EACjC,IAAIJ,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,IAAI0F,cAAc,CAAC1F,IAAI,CAAC,EAAE,OAAO,IAAI;EACrC,OAAOD,aAAa,CAACC,IAAI,EAAES,cAAc,EAAEC,YAAY,CAAC;AAC1D;;AAoZA;AACA;AACA;AACA;AACA;AACA,SAASkF,YAAYA,CAAC5F,IAAI,GAAG,EAAE,EAAE;EAC/B,IAAIJ,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,OAAOuC,aAAa,CAACG,IAAI,CAAC,CAAC,CAACzC,KAAK,EAAEC,GAAG,CAAC,KAAKH,aAAa,CAACC,IAAI,EAAEC,KAAK,EAAEC,GAAG,CAAC,CAAC;AAC9E;;AA+BA;AACA;AACA;AACA;AACA;AACA,SAAS2F,cAAcA,CAAC7F,IAAI,GAAG,EAAE,EAAE;EACjC,OAAOD,aAAa,CAACC,IAAI,EAAEW,cAAc,EAAEC,YAAY,CAAC;AAC1D;;AAEA;AACA;AACA;AACA;AACA;AACA,SAASkF,UAAUA,CAAC9F,IAAI,GAAG,EAAE,EAAE;EAC7B,IAAIJ,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,OAAO2F,cAAc,CAAC3F,IAAI,CAAC,IAAI6F,cAAc,CAAC7F,IAAI,CAAC;AACrD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS+F,MAAMA,CAAClG,KAAK,GAAG,EAAE,EAAE;EAC1B,IAAID,OAAO,CAACC,KAAK,CAAC,EAAE,OAAO,KAAK;EAChC,OAAO,CAAC,GAAGA,KAAK,CAAC,CAACiD,KAAK,CAACgD,UAAU,CAAC;AACrC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASE,UAAUA,CAACnG,KAAK,GAAG,EAAE,EAAE;EAC9B,IAAID,OAAO,CAACC,KAAK,CAAC,EAAE,OAAO,KAAK;EAChC,OAAO,CAAC,GAAGA,KAAK,CAAC,CAACiD,KAAK,CAAC6C,cAAc,CAAC;AACzC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASM,UAAUA,CAACpG,KAAK,GAAG,EAAE,EAAE;EAC9B,IAAID,OAAO,CAACC,KAAK,CAAC,EAAE,OAAO,KAAK;EAChC,OAAO,CAAC,GAAGA,KAAK,CAAC,CAACiD,KAAK,CAAC+C,cAAc,CAAC;AACzC;;AAEA;AACA;AACA;AACA;AACA;AACA,SAASK,mBAAmBA,CAAClG,IAAI,GAAG,EAAE,EAAE;EACtC,IAAIJ,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,OAAOA,IAAI,CAACI,UAAU,CAAC,CAAC,CAAC,KAAKW,oBAAoB;AACpD;;AAEA;AACA;AACA;AACA;AACA;AACA,SAASoF,WAAWA,CAACnG,IAAI,GAAG,EAAE,EAAE;EAC9B,OAAOD,aAAa,CAACC,IAAI,EAAEa,WAAW,EAAEC,SAAS,CAAC,IAAIoF,mBAAmB,CAAClG,IAAI,CAAC;AACjF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASoG,OAAOA,CAACvG,KAAK,GAAG,EAAE,EAAE;EAC3B,IAAID,OAAO,CAACC,KAAK,CAAC,EAAE,OAAO,KAAK;EAChC,OAAO,CAAC,GAAGA,KAAK,CAAC,CAACiD,KAAK,CAACqD,WAAW,CAAC;AACtC;;AAkXA;AACA;AACA;AACA;AACA;AACA,SAASE,wBAAwBA,CAACrG,IAAI,GAAG,EAAE,EAAE;EAC3C,IAAIJ,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,OAAOwC,qBAAqB,CAACE,IAAI,CAAC,CAAC,CAACzC,KAAK,EAAEC,GAAG,CAAC,KAAKH,aAAa,CAACC,IAAI,EAAEC,KAAK,EAAEC,GAAG,CAAC,CAAC;AACtF;;AAgEA;AACA;AACA;AACA;AACA;AACA,SAASoG,yBAAyBA,CAACtG,IAAI,GAAG,EAAE,EAAE;EAC5C,IAAIJ,OAAO,CAACI,IAAI,CAAC,IAAIkG,mBAAmB,CAAClG,IAAI,CAAC,EAAE,OAAO,KAAK;EAC5D,OAAOkC,qBAAqB,CAACQ,IAAI,CAAC,CAAC,CAACzC,KAAK,EAAEC,GAAG,CAAC,KAAKH,aAAa,CAACC,IAAI,EAAEC,KAAK,EAAEC,GAAG,CAAC,CAAC;AACtF;AAEA,MAAMqG,aAAa,GAAIC,CAAC,IAAKA,CAAC,KAAK,GAAG;AACtC,MAAMC,aAAa,GAAID,CAAC,IAAKA,CAAC,KAAK,GAAG;AACtC,MAAME,WAAW,GAAIF,CAAC,IAAK,OAAO,CAACxD,IAAI,CAACwD,CAAC,CAAC;AAC1C,MAAMG,WAAW,GAAIH,CAAC,IAAK,OAAO,CAACxD,IAAI,CAACwD,CAAC,CAAC;AAE1C,MAAMI,WAAW,GAAG;EAClBC,EAAE,EAAE,IAAI;EACRC,EAAE,EAAE,IAAI;EACRC,MAAM,EAAE,gBAAgB;EACxBC,MAAM,EAAE,iBAAiB;EACzBC,OAAO,EAAE,oBAAoB;EAC7BC,OAAO,EAAE,qBAAqB;EAC9BC,KAAK,EAAE,OAAO;EACdC,QAAQ,EAAE,UAAU;EACpBC,QAAQ,EAAE,UAAU;EACpBC,KAAK,EAAE,OAAO;EACdC,KAAK,EAAE;AACT,CAAC;;AAED;AACA,SAASC,OAAOA,CAAC3H,KAAK,EAAE4H,OAAO,GAAG,KAAK,EAAE;EACvC,MAAM;IACJZ,EAAE;IAAEC,EAAE;IAAEC,MAAM;IAAEC,MAAM;IAAEC,OAAO;IAAEC,OAAO;IAAEC,KAAK;IAAEC,QAAQ;IAAEC,QAAQ;IAAEC,KAAK;IAAEC;EAChF,CAAG,GAAGX,WAAW;EAEf,IAAIa,OAAO,EAAE;IACX,QAAQ,IAAI;MACV,KAAKf,WAAW,CAAC7G,KAAK,CAAC;QAAE,OAAO0H,KAAK;MACrC,KAAKZ,WAAW,CAAC9G,KAAK,CAAC;QAAE,OAAO0H,KAAK;MACrC,KAAKhB,aAAa,CAAC1G,KAAK,CAAC;QAAE,OAAOgH,EAAE;MACpC,KAAKR,wBAAwB,CAACxG,KAAK,CAAC;QAAE,OAAO0H,KAAK;MAClD,KAAKd,aAAa,CAAC5G,KAAK,CAAC;QAAE,OAAOiH,EAAE;MACpC,KAAKR,yBAAyB,CAACzG,KAAK,CAAC;QAAE,OAAO0H,KAAK;MACnD,KAAK9E,cAAc,CAAC5C,KAAK,CAAC;QAAE,OAAOiH,EAAE;MACrC,KAAKlB,YAAY,CAAC/F,KAAK,CAAC;QAAE,OAAOgH,EAAE;MACnC;QAAS,OAAOU,KAAK;IAC3B;EACA,CAAG,MAAM;IACL,QAAQ,IAAI;MACV,KAAKd,aAAa,CAAC5G,KAAK,CAAC;QAAE,OAAOyH,KAAK;MACvC,KAAKf,aAAa,CAAC1G,KAAK,CAAC;QAAE,OAAOyH,KAAK;MACvC,KAAKZ,WAAW,CAAC7G,KAAK,CAAC;QAAE,OAAOmH,MAAM;MACtC,KAAKL,WAAW,CAAC9G,KAAK,CAAC;QAAE,OAAOkH,MAAM;MACtC,KAAKV,wBAAwB,CAACxG,KAAK,CAAC;QAAE,OAAOoH,OAAO;MACpD,KAAKX,yBAAyB,CAACzG,KAAK,CAAC;QAAE,OAAOqH,OAAO;MACrD,KAAKf,WAAW,CAACtG,KAAK,CAAC;QAAE,OAAOsH,KAAK;MACrC,KAAKxB,cAAc,CAAC9F,KAAK,CAAC;QAAE,OAAOuH,QAAQ;MAC3C,KAAKvB,cAAc,CAAChG,KAAK,CAAC;QAAE,OAAOwH,QAAQ;MAC3C,KAAK5E,cAAc,CAAC5C,KAAK,CAAC;QAAE,OAAOiH,EAAE;MACrC,KAAKlB,YAAY,CAAC/F,KAAK,CAAC;QAAE,OAAOgH,EAAE;MACnC;QAAS,OAAOU,KAAK;IAC3B;EACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASG,QAAQA,CAAC7H,KAAK,EAAE;EAAE4H,OAAO,GAAG,KAAK;EAAEE,QAAQ,GAAG;AAAK,CAAE,GAAG,EAAE,EAAE;EACnE,IAAI9H,KAAK,IAAI,IAAI,IAAID,OAAO,CAACC,KAAK,CAAC,EAAE;IACnC,OAAO,EAAE;EACb;EACE,MAAM+H,KAAK,GAAG,CAAC,GAAG/H,KAAK,CAAC;EACxB,IAAIgI,OAAO,GAAGD,KAAK,CAACE,KAAK,EAAE;EAC3B,IAAIC,QAAQ,GAAGP,OAAO,CAACK,OAAO,EAAEJ,OAAO,CAAC;EACxCI,OAAO,GAAGF,QAAQ,GAAG;IAAEK,IAAI,EAAED,QAAQ;IAAEzI,KAAK,EAAEuI;EAAO,CAAE,GAAGA,OAAO;EAEjE,MAAMI,MAAM,GAAGL,KAAK,CAACxD,MAAM,CACzB,CAAC8D,MAAM,EAAElI,IAAI,KAAK;IAChB,MAAMmI,QAAQ,GAAGX,OAAO,CAACxH,IAAI,EAAEyH,OAAO,CAAC;IACvC,MAAMW,QAAQ,GAAGD,QAAQ,KAAKJ,QAAQ;IACtCA,QAAQ,GAAGI,QAAQ;IACnB,IAAIE,QAAQ,GAAGrI,IAAI;IAEnB,IAAIoI,QAAQ,EAAE;MACZC,QAAQ,GAAG,CAACV,QAAQ,GAAGO,MAAM,CAACI,GAAG,EAAE,CAAChJ,KAAK,GAAG4I,MAAM,CAACI,GAAG,EAAE,IAAID,QAAQ;IAC5E;IAEM,OAAOV,QAAQ,GACXO,MAAM,CAACK,MAAM,CAAC;MAAEP,IAAI,EAAEG,QAAQ;MAAE7I,KAAK,EAAE+I;IAAQ,CAAE,CAAC,GAClDH,MAAM,CAACK,MAAM,CAACF,QAAQ,CAAC;EACjC,CAAK,EACD,CAACR,OAAO,CACZ,CAAG;EACD,OAAOI,MAAM;AACf;AAEA,MAAMO,2BAA2B,GAAGA,CAAC3I,KAAK,EAAE4I,OAAO,KAAKA,OAAO,IAAI,CAAC1C,MAAM,CAAClG,KAAK,CAAC,CAAC,CAAC,CAAC;AACpF,MAAM6I,0BAA0B,GAAGA,CAAC7I,KAAK,EAAE4I,OAAO,KAAK,CAACA,OAAO,IAAI,CAAC1C,MAAM,CAAClG,KAAK,CAACA,KAAK,CAACC,MAAM,GAAG,CAAC,CAAC,CAAC;AACnG,MAAM6I,gBAAgB,GAAGA,CAAC9I,KAAK,EAAE+I,UAAU,KACxCA,UAAU,IAAI,CAAC,CAAC,GAAGA,UAAU,CAAC,CAAClG,IAAI,CAAC0D,OAAO,CAAC,IAAM,CAACwC,UAAU,IAAI7C,MAAM,CAAClG,KAAK,CAAE;;AAElF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASgJ,cAAcA,CAAChJ,KAAK,GAAG,EAAE,EAAE;EAAE4I,OAAO,GAAG,KAAK;EAAEG,UAAU,GAAG;AAAE,CAAE,GAAG,EAAE,EAAE;EAC7E,IACE,CAACjG,UAAU,CAAC9C,KAAK,CAAC,IAClB2I,2BAA2B,CAAC3I,KAAK,EAAE4I,OAAO,CAAC,IAC3CC,0BAA0B,CAAC7I,KAAK,EAAE4I,OAAO,CAAC,IAC1CE,gBAAgB,CAAC9I,KAAK,EAAE+I,UAAU,CAAC,EACnC;IACA,OAAO/I,KAAK;EAChB;EAEE,MAAM+H,KAAK,GAAGgB,UAAU,IAAI/I,KAAK;EACjC,MAAMiJ,cAAc,GAAG,IAAIC,MAAM,CAC/BN,OAAO,GAAI,IAAGf,QAAQ,CAACE,KAAK,CAAC,CAACE,KAAK,EAAG,EAAC,GAAI,GAAEJ,QAAQ,CAACE,KAAK,CAAC,CAACU,GAAG,EAAG,GACvE,CAAG;EACD,OAAOzI,KAAK,CAACmJ,OAAO,CAACF,cAAc,EAAE,EAAE,CAAC;AAC1C;ACz8DA,IAAIG,QAAQ,GAAGC,GAAG;;AAElB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAASA,GAAGA,CAAA,EAAG;EACb,IAAIjB,MAAM,GAAG,EAAE;EACf,IAAIkB,IAAI,GAAGC,KAAK,CAACC,SAAS,CAAC3J,KAAK,CAACD,IAAI,CAAC6J,SAAS,CAAC;EAChD,IAAIC,OAAO,GAAGJ,IAAI,CAACrJ,MAAM;EACzB,IAAI0J,MAAM,GAAG,CAAC;EACd,IAAIzE,CAAC,EAAE0E,CAAC;EAER,IAAI,CAACF,OAAO,EAAE;IACZ,MAAM,IAAIG,KAAK,CAAC,oCAAoC,CAAC;EACzD;EAEE,KAAK3E,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGwE,OAAO,EAAExE,CAAC,EAAE,EAAE;IAC5B,IAAI,CAACqE,KAAK,CAACO,OAAO,CAACR,IAAI,CAACpE,CAAC,CAAC,CAAC,EAAE;MAC3B,MAAM,IAAI2E,KAAK,CAAC,8BAA8B,CAAC;IACrD;IACI,IAAIE,MAAM,GAAGT,IAAI,CAACpE,CAAC,CAAC,CAACjF,MAAM;IAC3B,IAAI8J,MAAM,GAAGJ,MAAM,EAAE;MACnBA,MAAM,GAAGI,MAAM;IACrB;EACA;EAEE,KAAK7E,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGyE,MAAM,EAAEzE,CAAC,EAAE,EAAE;IAC3B,IAAI8E,KAAK,GAAG,EAAE;IACd,KAAKJ,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,OAAO,EAAEE,CAAC,EAAE,EAAE;MAC5B,IAAI,CAACL,KAAK,CAACO,OAAO,CAACR,IAAI,CAACM,CAAC,CAAC,CAAC,EAAE;QAC3B,MAAM,IAAIC,KAAK,CAAC,8BAA8B,CAAC;MACvD;MACMG,KAAK,CAACJ,CAAC,CAAC,GAAGN,IAAI,CAACM,CAAC,CAAC,CAAC1E,CAAC,CAAC;IAC3B;IACIkD,MAAM,CAAClD,CAAC,CAAC,GAAG8E,KAAK;EACrB;EAEE,OAAO5B,MAAM;AACf;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAAS6B,WAATA,CAAA,EAAyD;EAApC,IAAAC,IAAoC,GAAAT,SAAA,CAAAxJ,MAAA,QAAAwJ,SAAA,QAAA5F,SAAA,GAAA4F,SAAA,MAA7B,EAA6B;EAAzB,IAAAU,OAAyB,GAAAV,SAAA,CAAAxJ,MAAA,QAAAwJ,SAAA,QAAA5F,SAAA,GAAA4F,SAAA,MAAf,EAAe;EAAX,IAAAW,IAAW,GAAAX,SAAA,CAAAxJ,MAAA,QAAAwJ,SAAA,QAAA5F,SAAA,GAAA4F,SAAA,MAAJ,EAAI;EAC9D,IAAMY,QAAQ,GAAGC,SAAS,CAACF,IAAD,CAA1B,CAD8D;;EAG9D,IAAMG,gBAAgB,GAAGF,QAAQ,CAACpK,MAAT,KAAoB,CAApB,IAAyBuK,kBAAA,CAAIN,IAAJ,EAAUjH,KAAV,CAAgBsD,OAAhB,CAAlD;EACM,IAAAkE,UAAU,GAAGD,kBAAI,CAAAN,IAAJ,EAAUjH,KAAV,CAAgBiD,MAAhB,CAAnB;EACA,IAAMwE,iBAAiB,GAAGF,kBAAI,CAAAL,OAAJ,EAAatH,IAAb,CAAkBsD,UAAlB,KAAiCqE,kBAAA,CAAIL,OAAJ,EAAatH,IAAb,CAAkBuD,UAAlB,CAA3D;EAEA,IAAI8D,IAAI,KAAKC,OAAT,IAAoBM,UAAxB,EAAoC;IAClC,OAAO,CAAC,CAAC,EAAD,EAAKP,IAAL,CAAD,CAAP;EACD;EAED,IAAI,CAACE,IAAD,IAASG,gBAAT,IAA6BG,iBAAjC,EAAoD;IAClD,OAAOC,SAAS,CAACT,IAAD,EAAOC,OAAP,CAAhB;EACD;EAED,OAAOS,aAAa,CAACV,IAAD,EAAOG,QAAP,CAApB;AACD;AAED;AACA;AACA;AACA;AACA;AACA;;AACO,SAASM,SAATA,CAAA,EAA4C;EAAzB,IAAAT,IAAyB,GAAAT,SAAA,CAAAxJ,MAAA,QAAAwJ,SAAA,QAAA5F,SAAA,GAAA4F,SAAA,MAAlB,EAAkB;EAAd,IAAAU,OAAc,GAAAV,SAAA,CAAAxJ,MAAA,QAAAwJ,SAAA,QAAA5F,SAAA,GAAA4F,SAAA,MAAJ,EAAI;;EACjD;EACA,IAAIe,kBAAA,CAAIN,IAAJ,EAAUjH,KAAV,CAAgB,UAAC4H,CAAD;IAAA,OAAO,CAAC3E,MAAM,CAAC2E,CAAD,CAAd;EAAA,CAAhB,CAAJ,EAAwC;IACtC,OAAO,CAAC,CAACV,OAAD,EAAUD,IAAV,CAAD,CAAP;EACD;EAED,IAAAY,IAAA,GAA4B,CAC1BX,OAAO,CAACtK,KAAR,CAAc,CAAd,EAAiBqK,IAAI,CAACjK,MAAL,GAAc+I,cAAc,CAACkB,IAAD,EAAO;MAAEtB,OAAO,EAAE;IAAX,CAAP,CAAd,CAAwC3I,MAAvE,CAD0B,EAE1BkK,OAAO,CAACtK,KAAR,CAAcmJ,cAAc,CAACmB,OAAD,EAAU;MAAEpB,UAAU,EAAEmB;IAAd,CAAV,CAAd,CAA8CjK,MAA5D,CAF0B,CAA5B;IAAO8K,MAAP,GAAAD,IAAA;IAAeE,SAAf,GAAAF,IAAA;EAKA,IAAMG,eAAe,GAAGpD,QAAQ,CAACqD,oBAAoB,CAAChB,IAAD,EAAOa,MAAP,EAAeC,SAAf,CAArB,CAAhC;EACI,IAAAG,iBAAiB,GAAGD,oBAAoB,CAACf,OAAD,EAAUY,MAAV,EAAkBC,SAAlB,CAA5C;EAEM,IAAAI,qBAAqB,GAAGlC,MAAM,CAClC+B,eAAe,CAAClH,GAAhB,CAAoB,UAACsH,KAAD;IAAW,OAAA9E,OAAO,CAAC8E,KAAD,CAAP,GAAgB,MAAhB,OAAA3C,MAAA,CAA6B2C,KAA7B,EAAX;EAAA,CAApB,CAAsE,CAAAC,IAAtE,CAA2E,EAA3E,CADkC,CAApC;EAdiD,IAAAC,KAAA,GAkBtBJ,iBAAiB,CAACK,KAAlB,CAAwBJ,qBAAxB,KAAkD,EAlB5B;EAAA,IAAAK,KAAA,GAAAC,QAAA,CAAAH,KAAA;EAkB3CJ,iBAlB2C,GAAAM,KAAA,CAAA5L,KAAA;EAoBjD,IAAM8L,GAAG,GAAGvC,QAAG,CAAC+B,iBAAD,EAAoBF,eAApB,CAAH,CAAwClH,GAAxC,CAA4C6H,qBAA5C,CAAZ;EAEA,IAAIb,MAAJ,EAAY;IACVY,GAAG,CAACE,OAAJ,CAAY,CAAC,EAAD,EAAKd,MAAL,CAAZ;EACD;EAED,IAAIC,SAAJ,EAAe;IACbW,GAAG,CAACG,IAAJ,CAAS,CAAC,EAAD,EAAKd,SAAL,CAAT;EACD;EAED,OAAOW,GAAP;AACD;AAED,SAAST,oBAATA,CAAA,EAAqE;EAAvC,IAAAa,GAAuC,GAAAtC,SAAA,CAAAxJ,MAAA,QAAAwJ,SAAA,QAAA5F,SAAA,GAAA4F,SAAA,MAAjC,EAAiC;EAA7B,IAAAb,OAA6B,GAAAa,SAAA,CAAAxJ,MAAA,QAAAwJ,SAAA,QAAA5F,SAAA,GAAA4F,SAAA,MAAnB,EAAmB;EAAf,IAAAuC,QAAe,GAAAvC,SAAA,CAAAxJ,MAAA,QAAAwJ,SAAA,QAAA5F,SAAA,GAAA4F,SAAA,MAAJ,EAAI;EACnE,OAAOsC,GAAG,CAAC5C,OAAJ,CAAYD,MAAM,KAAAR,MAAA,CAAKE,OAAL,CAAlB,GAAmC,EAAnC,CAAuC,CAAAO,OAAvC,CAA+CD,MAAM,IAAAR,MAAA,CAAIsD,QAAJ,EAArD,OAAuE,EAAvE,CAAP;AACD;AAED,SAASJ,qBAATA,CAAqDK,KAAA;EAAA,IAAAC,KAAA,GAAAC,cAAA,CAAAF,KAAA;IAArB9B,OAAqB,GAAA+B,KAAA;IAAAE,MAAA,GAAAF,KAAA;IAAZhC,IAAY,GAAAkC,MAAA,cAAL,EAAK,GAAAA,MAAA;EACnD,OAAO,CAACjC,OAAD,IAAYA,OAAO,KAAKD,IAAxB,GAA+B,CAAC,EAAD,EAAKA,IAAL,CAA/B,GAA4C,CAACC,OAAD,EAAUD,IAAV,CAAnD;AACD;AAEM,SAASI,SAATA,CAAmB+B,IAAnB,EAAyB;EAC9B,OAAO,OAAOA,IAAP,KAAgB,QAAhB,GAA2BC,eAAe,CAACD,IAAD,CAA1C,GAAmDE,eAAe,CAACF,IAAD,CAAzE;AACD;AAED;AACA;AACA;AACA;AACA;;AACA,SAASE,eAATA,CAAA,EAAyC;EAAhB,IAAAC,SAAgB,GAAA/C,SAAA,CAAAxJ,MAAA,QAAAwJ,SAAA,QAAA5F,SAAA,GAAA4F,SAAA,MAAJ,EAAI;EACvC,OAAO/J,MAAM,CAAC6D,OAAP,CAAeiJ,SAAf,EAA0BzI,GAA1B,CAA8B,UAAA0I,KAAA;IAAA,IAAAC,KAAA,GAAAP,cAAA,CAAAM,KAAA;MAAErM,KAAF,GAAAsM,KAAA;MAASC,OAAT,GAAAD,KAAA;IAAA,OAAsB,CACzD,CAACE,MAAM,CAACxM,KAAD,CAAP,EAAgBwM,MAAM,CAACxM,KAAD,CAAN,GAAgB,CAAhC,CADyD,EAEzDuM,OAFyD,CAAtB;EAAA,CAA9B,CAAP;AAID;AAED;AACA;AACA;AACA;AACA;;AACA,SAASL,eAATA,CAAA,EAAyC;EAAhB,IAAAE,SAAgB,GAAA/C,SAAA,CAAAxJ,MAAA,QAAAwJ,SAAA,QAAA5F,SAAA,GAAA4F,SAAA,MAAJ,EAAI;EAChC,OAAA+C,SAAS,CAAC5I,KAAV,CAAgB,GAAhB,EAAqBG,GAArB,CAAyB,UAAC8I,KAAD,EAAW;IACzC,IAAAC,YAAA,GAA2BD,KAAK,CAACjJ,KAAN,CAAY,GAAZ,CAA3B;MAAAmJ,aAAA,GAAAZ,cAAA,CAAAW,YAAA;MAAOE,OAAP,GAAAD,aAAA;MAAgBJ,OAAhB,GAAAI,aAAA;IACqB,IAAAE,kBAAA,GAAAD,OAAO,CAACpJ,KAAR,CAAc,GAAd,CAAmB,CAAAG,GAAnB,CAAuB6I,MAAvB,CAArB;MAAAM,mBAAA,GAAAf,cAAA,CAAAc,kBAAA;MAAO7M,KAAP,GAAA8M,mBAAA;MAAc7M,GAAd,GAAA6M,mBAAA,IAFyC;IAIzC;IACA;;IACA,OAAO,CAAC,CAAC9M,KAAD,EAAQC,GAAG,GAAGA,GAAG,GAAG,CAAT,GAAaD,KAAK,GAAG,CAAhC,CAAD,EAAqCuM,OAArC,CAAP;EACD,CAPM,CAAP;AAQD;AAED;AACA;AACA;AACA;AACA;AACA;;AACO,SAAS/B,aAATA,CAAA,EAAiD;EAA1B,IAAAV,IAA0B,GAAAT,SAAA,CAAAxJ,MAAA,QAAAwJ,SAAA,QAAA5F,SAAA,GAAA4F,SAAA,MAAnB,EAAmB;EAAf,IAAAY,QAAe,GAAAZ,SAAA,CAAAxJ,MAAA,QAAAwJ,SAAA,QAAA5F,SAAA,GAAA4F,SAAA,MAAJ,EAAI;EAClD,IAAA0D,WAAW,GAAG,CAAlB;EAEO,OAAA9C,QAAQ,CAAC9F,MAAT,CAAgB,UAAC6I,KAAD,EAAkCC,KAAA,EAAAC,KAAlC,EAAyCC,MAAzC,EAAoD;IAAA,IAAAC,KAAA,GAAArB,cAAA,CAAAkB,KAAA;MAAAI,MAAA,GAAAtB,cAAA,CAAAqB,KAAA;MAA1CpN,KAA0C,GAAAqN,MAAA;MAAnCpN,GAAmC,GAAAoN,MAAA;MAA7BC,QAA6B,GAAAF,KAAA;;IACzE;IACI,IAAApN,KAAK,KAAK+M,WAAd,EAA2B;MACzBC,KAAK,CAACtB,IAAN,CAAW,CAAC,EAAD,EAAK5B,IAAI,CAACrK,KAAL,CAAWsN,WAAX,EAAwB/M,KAAxB,CAAL,CAAX;IACD,CAJwE;;IAOzEgN,KAAK,CAACtB,IAAN,CAAW,CAAC4B,QAAD,EAAWxD,IAAI,CAACrK,KAAL,CAAWO,KAAX,EAAkBC,GAAlB,CAAX,CAAX,EAPyE;;IAUzE,IAAIA,GAAG,GAAG6J,IAAI,CAACjK,MAAX,IAAqB,CAACsN,MAAM,CAACD,KAAK,GAAG,CAAT,CAAhC,EAA6C;MAC3CF,KAAK,CAACtB,IAAN,CAAW,CAAC,EAAD,EAAK5B,IAAI,CAACrK,KAAL,CAAWQ,GAAX,CAAL,CAAX;IACD;IAED8M,WAAW,GAAG9M,GAAd;IACA,OAAO+M,KAAP;EACD,CAhBM,EAgBJ,EAhBI,CAAP;AAiBD;AC7IM,SAASO,YAATA,CAAsBzD,IAAtB,EAA4BC,OAA5B,EAAqCC,IAArC,EAA2C;EACzC,OAAAwD,KAAK,CAACC,OAAN,CAAc;IAAA,OAAM5D,WAAW,CAACC,IAAD,EAAOC,OAAP,EAAgBC,IAAhB,CAAjB;EAAA,CAAd,EAAsD,CAACF,IAAD,EAAOC,OAAP,EAAgBC,IAAhB,CAAtD,CAAP;AACD;;;;;;ACDD,IAAM0D,YAAY,GAAG;EACnBC,OAAO,EAAE,aADU;EAEnBC,QAAQ,EAAE,UAFS;EAGnBC,UAAU;AAHS,CAArB;AAMA,IAAMC,SAAS,GAAG;EAChBH,OAAO,EAAE,aADO;EAEhBI,QAAQ,EAAE,MAFM;EAGhBC,UAAU,EAAE,GAHI;EAIhBJ,QAAQ,EAAE,eAJM;EAKhBK,cAAc,EAAE,UALA;EAMhBC,UAAU,EAAE,QANI;EAOhBC,SAAS,EAAE;AAPK,CAAlB;AAUA,IAAMC,SAAS,GAAG;EAChBT,OAAO,EAAE,OADO;EAEhBI,QAAQ,EAAE,OAFM;EAGhBM,aAAa,EAAE,SAHC;EAIhBC,MAAM,EAAE,SAJQ;EAKhBC,UAAU,EAAE,OALI;EAMhBC,aAAa,EAAE,OANC;EAOhB;EACAC,UAAU,EAAE,MARI;EAShBC,OAAO,EAAE;AATO,CAAlB;AAYA,IAAMC,SAAS,GAAG;EAChBhB,OAAO,EAAE;AADO,CAAlB;AAIO,SAASiB,OAATA,CAAsClE,IAAA;EAAnB,IAAAmE,KAAmB,GAAAnE,IAAA,CAAnBmE,KAAmB;IAATC,KAAS,GAAAC,wBAAA,CAAArE,IAAA,EAAAsE,SAAA;EACpC,oBAAAxB,KAAA,CAAAyB,aAAA,SAAAC,QAAA;IAAMC,IAAI,EAAC,IAAX;IAAgBN,KAAK,EAAAO,cAAA,CAAAA,cAAA,KAAO1B,YAAP,GAAwBmB,KAAxB;EAArB,GAA0DC,KAA1D,CAAP;AACD;AAEM,SAASO,IAATA,CAAmClE,KAAA;EAAnB,IAAA0D,KAAmB,GAAA1D,KAAA,CAAnB0D,KAAmB;IAATC,KAAS,GAAAC,wBAAA,CAAA5D,KAAA,EAAAmE,UAAA;EACjC,oBAAA9B,KAAA,CAAAyB,aAAA,SAAAC,QAAA;IAAMC,IAAI,EAAC,IAAX;IAAgBN,KAAK,EAAAO,cAAA,CAAAA,cAAA,KAAOtB,SAAP,GAAqBe,KAArB;EAArB,GAAuDC,KAAvD,CAAP;AACD;AAEM,SAASS,IAATA,CAAmClE,KAAA;EAAnB,IAAAwD,KAAmB,GAAAxD,KAAA,CAAnBwD,KAAmB;IAATC,KAAS,GAAAC,wBAAA,CAAA1D,KAAA,EAAAmE,UAAA;EACjC,oBAAAhC,KAAA,CAAAyB,aAAA,SAAAC,QAAA;IAAMC,IAAI,EAAC,IAAX;IAAgBN,KAAK,EAAAO,cAAA,CAAAA,cAAA,KAAOhB,SAAP,GAAqBS,KAArB;EAArB,GAAuDC,KAAvD,CAAP;AACD;AAEM,SAASW,IAATA,CAAmC5D,KAAA;EAAnB,IAAAgD,KAAmB,GAAAhD,KAAA,CAAnBgD,KAAmB;IAATC,KAAS,GAAAC,wBAAA,CAAAlD,KAAA,EAAA6D,UAAA;EACjC,oBAAAlC,KAAA,CAAAyB,aAAA,SAAAC,QAAA;IAAMC,IAAI,EAAC,IAAX;IAAgBN,KAAK,EAAAO,cAAA,CAAAA,cAAA,KAAOT,SAAP,GAAqBE,KAArB;EAArB,GAAuDC,KAAvD,CAAP;AACD;AAEM,SAASa,SAATA,CAAwE7D,KAAA;EAAnD,IAAAhC,IAAmD,GAAAgC,KAAA,CAAnDhC,IAAmD;IAA7CC,OAA6C,GAAA+B,KAAA,CAA7C/B,OAA6C;IAApCC,IAAoC,GAAA8B,KAAA,CAApC9B,IAAoC;IAA9B4F,QAA8B,GAAA9D,KAAA,CAA9B8D,QAA8B;IAApBC,MAAoB,GAAA/D,KAAA,CAApB+D,MAAoB;IAATf,KAAS,GAAAC,wBAAA,CAAAjD,KAAA,EAAAgE,UAAA;EACvE,IAAA9C,KAAK,GAAGO,YAAY,CAACzD,IAAD,EAAOC,OAAP,EAAgBC,IAAhB,CAA1B;EAEA,OAAO,OAAO6F,MAAP,KAAkB,UAAlB,GACLA,MAAM,CAAC;IAAE7C,KAAK,EAALA;EAAF,CAAD,CADD,gBAGLQ,KAAC,CAAAyB,aAAA,CAAAL,OAAD,EAAaE,KAAb,EACG9B,KAAK,CAACrJ,GAAN,CAAU,UAAA0I,KAAA,EAAmBa,KAAnB,EAA6B;IAAA,IAAAZ,KAAA,GAAAP,cAAA,CAAAM,KAAA;MAA3BiB,QAA2B,GAAAhB,KAAA;MAAjByD,IAAiB,GAAAzD,KAAA;IACtC,IAAM0D,aAAa,GAAGD,IAAI,GAAG7C,KAA7B;IAEA,oBACEM,KAAA,CAAAyB,aAAA,CAACI,IAAD;MAAMY,GAAG,EAAED;IAAX,GACGJ,QAAQ,iBAAIpC,KAAC,CAAAyB,aAAA,CAAAM,IAAD,EAAO,MAAAjC,QAAP,CADf,eAEEE,KAAC,CAAAyB,aAAA,CAAAQ,IAAD,EAAO,MAAAM,IAAP,CAFF,CADF;EAMD,CATA,CADH,CAHF;AAgBD;AAEDJ,SAAS,CAACO,YAAV,GAAyB;EACvBpG,IAAI,EAAE,EADiB;EAEvBC,OAAO,EAAE,EAFc;EAGvBC,IAAI,EAAE,EAHiB;EAIvB4F,QAAQ,EAAE;AAJa,CAAzB"},"metadata":{},"sourceType":"module"}