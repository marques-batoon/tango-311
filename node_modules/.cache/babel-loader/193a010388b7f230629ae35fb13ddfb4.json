{"ast":null,"code":"import React from 'react';\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n    enumerableOnly && (symbols = symbols.filter(function (sym) {\n      return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n    })), keys.push.apply(keys, symbols);\n  }\n  return keys;\n}\nfunction _objectSpread2(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = null != arguments[i] ? arguments[i] : {};\n    i % 2 ? ownKeys(Object(source), !0).forEach(function (key) {\n      _defineProperty(target, key, source[key]);\n    }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) {\n      Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n    });\n  }\n  return target;\n}\nfunction _defineProperty(obj, key, value) {\n  if (key in obj) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n  } else {\n    obj[key] = value;\n  }\n  return obj;\n}\nfunction _extends() {\n  _extends = Object.assign || function (target) {\n    for (var i = 1; i < arguments.length; i++) {\n      var source = arguments[i];\n      for (var key in source) {\n        if (Object.prototype.hasOwnProperty.call(source, key)) {\n          target[key] = source[key];\n        }\n      }\n    }\n    return target;\n  };\n  return _extends.apply(this, arguments);\n}\nfunction _objectWithoutPropertiesLoose(source, excluded) {\n  if (source == null) return {};\n  var target = {};\n  var sourceKeys = Object.keys(source);\n  var key, i;\n  for (i = 0; i < sourceKeys.length; i++) {\n    key = sourceKeys[i];\n    if (excluded.indexOf(key) >= 0) continue;\n    target[key] = source[key];\n  }\n  return target;\n}\nfunction _objectWithoutProperties(source, excluded) {\n  if (source == null) return {};\n  var target = _objectWithoutPropertiesLoose(source, excluded);\n  var key, i;\n  if (Object.getOwnPropertySymbols) {\n    var sourceSymbolKeys = Object.getOwnPropertySymbols(source);\n    for (i = 0; i < sourceSymbolKeys.length; i++) {\n      key = sourceSymbolKeys[i];\n      if (excluded.indexOf(key) >= 0) continue;\n      if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue;\n      target[key] = source[key];\n    }\n  }\n  return target;\n}\nfunction _slicedToArray(arr, i) {\n  return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest();\n}\nfunction _toArray(arr) {\n  return _arrayWithHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableRest();\n}\nfunction _toConsumableArray(arr) {\n  return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread();\n}\nfunction _arrayWithoutHoles(arr) {\n  if (Array.isArray(arr)) return _arrayLikeToArray(arr);\n}\nfunction _arrayWithHoles(arr) {\n  if (Array.isArray(arr)) return arr;\n}\nfunction _iterableToArray(iter) {\n  if (typeof Symbol !== \"undefined\" && iter[Symbol.iterator] != null || iter[\"@@iterator\"] != null) return Array.from(iter);\n}\nfunction _iterableToArrayLimit(arr, i) {\n  var _i = arr == null ? null : typeof Symbol !== \"undefined\" && arr[Symbol.iterator] || arr[\"@@iterator\"];\n  if (_i == null) return;\n  var _arr = [];\n  var _n = true;\n  var _d = false;\n  var _s, _e;\n  try {\n    for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) {\n      _arr.push(_s.value);\n      if (i && _arr.length === i) break;\n    }\n  } catch (err) {\n    _d = true;\n    _e = err;\n  } finally {\n    try {\n      if (!_n && _i[\"return\"] != null) _i[\"return\"]();\n    } finally {\n      if (_d) throw _e;\n    }\n  }\n  return _arr;\n}\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return _arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen);\n}\nfunction _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n  for (var i = 0, arr2 = new Array(len); i < len; i++) arr2[i] = arr[i];\n  return arr2;\n}\nfunction _nonIterableSpread() {\n  throw new TypeError(\"Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\nfunction _nonIterableRest() {\n  throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\n\n/**\n * Returns detailed type as string (instead of just 'object' for arrays etc)\n * @private\n * @param {any} value js value\n * @returns {String} type of value\n * @example\n * typeOf({}); // 'object'\n * typeOf([]); // 'array'\n * typeOf(function() {}); // 'function'\n * typeOf(/a/); // 'regexp'\n * typeOf(new Date()); // 'date'\n * typeOf(null); // 'null'\n * typeOf(undefined); // 'undefined'\n * typeOf('a'); // 'string'\n * typeOf(1); // 'number'\n * typeOf(true); // 'boolean'\n * typeOf(new Map()); // 'map'\n * typeOf(new Set()); // 'map'\n */\nfunction typeOf(value) {\n  if (value === null) {\n    return 'null';\n  }\n  if (value !== Object(value)) {\n    return typeof value;\n  }\n  return {}.toString.call(value).slice(8, -1).toLowerCase();\n}\n\n/**\n * Checks if input string is empty\n * @param  {String} input text input\n * @return {Boolean} true if no input\n */\nfunction isEmpty(input) {\n  if (typeOf(input) !== 'string') {\n    return true;\n  }\n  return !input.length;\n}\n\n/**\n * Takes a character and a unicode range. Returns true if the char is in the range.\n * @param  {String}  char  unicode character\n * @param  {Number}  start unicode start range\n * @param  {Number}  end   unicode end range\n * @return {Boolean}\n */\nfunction isCharInRange() {\n  let char = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  let start = arguments.length > 1 ? arguments[1] : undefined;\n  let end = arguments.length > 2 ? arguments[2] : undefined;\n  if (isEmpty(char)) return false;\n  const code = char.charCodeAt(0);\n  return start <= code && code <= end;\n}\nconst LOWERCASE_ZENKAKU_START = 0xff41;\nconst LOWERCASE_ZENKAKU_END = 0xff5a;\nconst UPPERCASE_ZENKAKU_START = 0xff21;\nconst UPPERCASE_ZENKAKU_END = 0xff3a;\nconst HIRAGANA_START = 0x3041;\nconst HIRAGANA_END = 0x3096;\nconst KATAKANA_START = 0x30a1;\nconst KATAKANA_END = 0x30fc;\nconst KANJI_START = 0x4e00;\nconst KANJI_END = 0x9faf;\nconst KANJI_ITERATION_MARK = 0x3005; // ã€…\nconst PROLONGED_SOUND_MARK = 0x30fc; // ãƒ¼\n\nconst ZENKAKU_NUMBERS = [0xff10, 0xff19];\nconst ZENKAKU_UPPERCASE = [UPPERCASE_ZENKAKU_START, UPPERCASE_ZENKAKU_END];\nconst ZENKAKU_LOWERCASE = [LOWERCASE_ZENKAKU_START, LOWERCASE_ZENKAKU_END];\nconst ZENKAKU_PUNCTUATION_1 = [0xff01, 0xff0f];\nconst ZENKAKU_PUNCTUATION_2 = [0xff1a, 0xff1f];\nconst ZENKAKU_PUNCTUATION_3 = [0xff3b, 0xff3f];\nconst ZENKAKU_PUNCTUATION_4 = [0xff5b, 0xff60];\nconst ZENKAKU_SYMBOLS_CURRENCY = [0xffe0, 0xffee];\nconst HIRAGANA_CHARS = [0x3040, 0x309f];\nconst KATAKANA_CHARS = [0x30a0, 0x30ff];\nconst HANKAKU_KATAKANA = [0xff66, 0xff9f];\nconst KATAKANA_PUNCTUATION = [0x30fb, 0x30fc];\nconst KANA_PUNCTUATION = [0xff61, 0xff65];\nconst CJK_SYMBOLS_PUNCTUATION = [0x3000, 0x303f];\nconst COMMON_CJK = [0x4e00, 0x9fff];\nconst RARE_CJK = [0x3400, 0x4dbf];\nconst KANA_RANGES = [HIRAGANA_CHARS, KATAKANA_CHARS, KANA_PUNCTUATION, HANKAKU_KATAKANA];\nconst JA_PUNCTUATION_RANGES = [CJK_SYMBOLS_PUNCTUATION, KANA_PUNCTUATION, KATAKANA_PUNCTUATION, ZENKAKU_PUNCTUATION_1, ZENKAKU_PUNCTUATION_2, ZENKAKU_PUNCTUATION_3, ZENKAKU_PUNCTUATION_4, ZENKAKU_SYMBOLS_CURRENCY];\n\n// All Japanese unicode start and end ranges\n// Includes kanji, kana, zenkaku latin chars, punctuation, and number ranges.\nconst JAPANESE_RANGES = [...KANA_RANGES, ...JA_PUNCTUATION_RANGES, ZENKAKU_UPPERCASE, ZENKAKU_LOWERCASE, ZENKAKU_NUMBERS, COMMON_CJK, RARE_CJK];\nconst MODERN_ENGLISH = [0x0000, 0x007f];\nconst HEPBURN_MACRON_RANGES = [[0x0100, 0x0101],\n// Ä€ Ä\n[0x0112, 0x0113],\n// Ä’ Ä“\n[0x012a, 0x012b],\n// Äª Ä«\n[0x014c, 0x014d],\n// ÅŒ Å\n[0x016a, 0x016b] // Åª Å«\n];\n\nconst SMART_QUOTE_RANGES = [[0x2018, 0x2019],\n// â€˜ â€™\n[0x201c, 0x201d] // â€œ â€\n];\n\nconst ROMAJI_RANGES = [MODERN_ENGLISH, ...HEPBURN_MACRON_RANGES];\nconst EN_PUNCTUATION_RANGES = [[0x20, 0x2f], [0x3a, 0x3f], [0x5b, 0x60], [0x7b, 0x7e], ...SMART_QUOTE_RANGES];\n\n/**\n * Tests a character. Returns true if the character is [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharJapanese() {\n  let char = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  return JAPANESE_RANGES.some(_ref10 => {\n    let [start, end] = _ref10;\n    return isCharInRange(char, start, end);\n  });\n}\n\n/**\n * Test if `input` only includes [Kanji](https://en.wikipedia.org/wiki/Kanji), [Kana](https://en.wikipedia.org/wiki/Kana), zenkaku numbers, and JA punctuation/symbols.â€\n * @param  {String} [input=''] text\n * @param  {Regexp} [allowed] additional test allowed to pass for each char\n * @return {Boolean} true if passes checks\n * @example\n * isJapanese('æ³£ãè™«')\n * // => true\n * isJapanese('ã‚ã‚¢')\n * // => true\n * isJapanese('ï¼’æœˆ') // Zenkaku numbers allowed\n * // => true\n * isJapanese('æ³£ãè™«ã€‚ï¼ã€œï¼„') // Zenkaku/JA punctuation\n * // => true\n * isJapanese('æ³£ãè™«.!~$') // Latin punctuation fails\n * // => false\n * isJapanese('Aæ³£ãè™«')\n * // => false\n * isJapanese('â‰ªå½æ‹¬å¼§â‰«', /[â‰ªâ‰«]/);\n * // => true\n */\nfunction isJapanese() {\n  let input = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  let allowed = arguments.length > 1 ? arguments[1] : undefined;\n  const augmented = typeOf(allowed) === 'regexp';\n  return isEmpty(input) ? false : [...input].every(char => {\n    const isJa = isCharJapanese(char);\n    return !augmented ? isJa : isJa || allowed.test(char);\n  });\n}\n\n/**\n * Creates a custom mapping tree, returns a function that accepts a defaultMap which the newly created customMapping will be merged with and returned\n * (customMap) => (defaultMap) => mergedMap\n * @param  {Object} customMap { 'ka' : 'ãª' }\n * @return {Function} (defaultMap) => defaultMergedWithCustomMap\n * @example\n * const sillyMap = createCustomMapping({ 'ã¡ã‚ƒ': 'time', 'èŒŽ': 'cookie'ã€€});\n * // sillyMap is passed defaultMapping to merge with when called in toRomaji()\n * toRomaji(\"It's èŒŽ ã¡ã‚ƒ ã‚ˆ\", { customRomajiMapping: sillyMap });\n * // => 'It's cookie time yo';\n */\nfunction createCustomMapping() {\n  let customMap = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  const customTree = {};\n  if (typeOf(customMap) === 'object') {\n    Object.entries(customMap).forEach(_ref11 => {\n      let [roma, kana] = _ref11;\n      let subTree = customTree;\n      roma.split('').forEach(char => {\n        if (subTree[char] === undefined) {\n          subTree[char] = {};\n        }\n        subTree = subTree[char];\n      });\n      subTree[''] = kana;\n    });\n  }\n  return function makeMap(map) {\n    const mapCopy = JSON.parse(JSON.stringify(map));\n    function transformMap(mapSubtree, customSubtree) {\n      if (mapSubtree === undefined || typeOf(mapSubtree) === 'string') {\n        return customSubtree;\n      }\n      return Object.entries(customSubtree).reduce((newSubtree, _ref12) => {\n        let [char, subtree] = _ref12;\n        // eslint-disable-next-line no-param-reassign\n        newSubtree[char] = transformMap(mapSubtree[char], subtree);\n        return newSubtree;\n      }, mapSubtree);\n    }\n    return transformMap(mapCopy, customTree);\n  };\n}\nconst SMALL_Y$1 = {\n  ya: 'ã‚ƒ',\n  yi: 'ãƒ',\n  yu: 'ã‚…',\n  ye: 'ã‡',\n  yo: 'ã‚‡'\n};\nconst SMALL_VOWELS = {\n  a: 'ã',\n  i: 'ãƒ',\n  u: 'ã…',\n  e: 'ã‡',\n  o: 'ã‰'\n};\n\n// xtu -> ã£\nObject.assign({\n  tu: 'ã£',\n  wa: 'ã‚Ž',\n  ka: 'ãƒµ',\n  ke: 'ãƒ¶'\n}, SMALL_VOWELS, SMALL_Y$1);\ncreateCustomMapping({\n  wi: 'ã‚',\n  we: 'ã‚‘'\n});\n\n/**\n * Returns true if char is 'ãƒ¼'\n * @param  {String} char to test\n * @return {Boolean}\n */\nfunction isCharLongDash() {\n  let char = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  if (isEmpty(char)) return false;\n  return char.charCodeAt(0) === PROLONGED_SOUND_MARK;\n}\n\n/**\n * Tests a character. Returns true if the character is [Hiragana](https://en.wikipedia.org/wiki/Hiragana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharHiragana() {\n  let char = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  if (isEmpty(char)) return false;\n  if (isCharLongDash(char)) return true;\n  return isCharInRange(char, HIRAGANA_START, HIRAGANA_END);\n}\n\n/**\n * Tests a character. Returns true if the character is [Romaji](https://en.wikipedia.org/wiki/Romaji) (allowing [Hepburn romanisation](https://en.wikipedia.org/wiki/Hepburn_romanization))\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharRomaji() {\n  let char = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  if (isEmpty(char)) return false;\n  return ROMAJI_RANGES.some(_ref13 => {\n    let [start, end] = _ref13;\n    return isCharInRange(char, start, end);\n  });\n}\n\n/**\n * Tests a character. Returns true if the character is [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharKatakana() {\n  let char = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  return isCharInRange(char, KATAKANA_START, KATAKANA_END);\n}\n\n/**\n * Tests a character. Returns true if the character is [Hiragana](https://en.wikipedia.org/wiki/Hiragana) or [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharKana() {\n  let char = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  if (isEmpty(char)) return false;\n  return isCharHiragana(char) || isCharKatakana(char);\n}\n\n/**\n * Test if `input` is [Kana](https://en.wikipedia.org/wiki/Kana) ([Katakana](https://en.wikipedia.org/wiki/Katakana) and/or [Hiragana](https://en.wikipedia.org/wiki/Hiragana))\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Kana](https://en.wikipedia.org/wiki/Kana)\n * @example\n * isKana('ã‚')\n * // => true\n * isKana('ã‚¢')\n * // => true\n * isKana('ã‚ãƒ¼ã‚¢')\n * // => true\n * isKana('A')\n * // => false\n * isKana('ã‚Aã‚¢')\n * // => false\n */\nfunction isKana() {\n  let input = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharKana);\n}\n\n/**\n * Test if `input` is [Hiragana](https://en.wikipedia.org/wiki/Hiragana)\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Hiragana](https://en.wikipedia.org/wiki/Hiragana)\n * @example\n * isHiragana('ã’ãƒ¼ã‚€')\n * // => true\n * isHiragana('A')\n * // => false\n * isHiragana('ã‚ã‚¢')\n * // => false\n */\nfunction isHiragana() {\n  let input = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharHiragana);\n}\n\n/**\n * Test if `input` is [Katakana](https://en.wikipedia.org/wiki/Katakana)\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Katakana](https://en.wikipedia.org/wiki/Katakana)\n * @example\n * isKatakana('ã‚²ãƒ¼ãƒ ')\n * // => true\n * isKatakana('ã‚')\n * // => false\n * isKatakana('A')\n * // => false\n * isKatakana('ã‚ã‚¢')\n * // => false\n */\nfunction isKatakana() {\n  let input = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharKatakana);\n}\n\n/**\n * Returns true if char is 'ã€…'\n * @param  {String} char to test\n * @return {Boolean}\n */\nfunction isCharIterationMark() {\n  let char = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  if (isEmpty(char)) return false;\n  return char.charCodeAt(0) === KANJI_ITERATION_MARK;\n}\n\n/**\n * Tests a character. Returns true if the character is a CJK ideograph (kanji).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharKanji() {\n  let char = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  return isCharInRange(char, KANJI_START, KANJI_END) || isCharIterationMark(char);\n}\n\n/**\n * Tests if `input` is [Kanji](https://en.wikipedia.org/wiki/Kanji) ([Japanese CJK ideographs](https://en.wikipedia.org/wiki/CJK_Unified_Ideographs))\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Kanji](https://en.wikipedia.org/wiki/Kanji)\n * @example\n * isKanji('åˆ€')\n * // => true\n * isKanji('åˆ‡è…¹')\n * // => true\n * isKanji('å‹¢ã„')\n * // => false\n * isKanji('ã‚Aã‚¢')\n * // => false\n * isKanji('ðŸ¸')\n * // => false\n */\nfunction isKanji() {\n  let input = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharKanji);\n}\n\n/**\n * Tests a character. Returns true if the character is considered English punctuation.\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharEnglishPunctuation() {\n  let char = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  if (isEmpty(char)) return false;\n  return EN_PUNCTUATION_RANGES.some(_ref14 => {\n    let [start, end] = _ref14;\n    return isCharInRange(char, start, end);\n  });\n}\n\n/**\n * Tests a character. Returns true if the character is considered Japanese punctuation.\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharJapanesePunctuation() {\n  let char = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  if (isEmpty(char) || isCharIterationMark(char)) return false;\n  return JA_PUNCTUATION_RANGES.some(_ref15 => {\n    let [start, end] = _ref15;\n    return isCharInRange(char, start, end);\n  });\n}\nconst isCharEnSpace = x => x === ' ';\nconst isCharJaSpace = x => x === 'ã€€';\nconst isCharJaNum = x => /[ï¼-ï¼™]/.test(x);\nconst isCharEnNum = x => /[0-9]/.test(x);\nconst TOKEN_TYPES = {\n  EN: 'en',\n  JA: 'ja',\n  EN_NUM: 'englishNumeral',\n  JA_NUM: 'japaneseNumeral',\n  EN_PUNC: 'englishPunctuation',\n  JA_PUNC: 'japanesePunctuation',\n  KANJI: 'kanji',\n  HIRAGANA: 'hiragana',\n  KATAKANA: 'katakana',\n  SPACE: 'space',\n  OTHER: 'other'\n};\n\n// prettier-ignore\nfunction getType(input) {\n  let compact = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n  const {\n    EN,\n    JA,\n    EN_NUM,\n    JA_NUM,\n    EN_PUNC,\n    JA_PUNC,\n    KANJI,\n    HIRAGANA,\n    KATAKANA,\n    SPACE,\n    OTHER\n  } = TOKEN_TYPES;\n  if (compact) {\n    switch (true) {\n      case isCharJaNum(input):\n        return OTHER;\n      case isCharEnNum(input):\n        return OTHER;\n      case isCharEnSpace(input):\n        return EN;\n      case isCharEnglishPunctuation(input):\n        return OTHER;\n      case isCharJaSpace(input):\n        return JA;\n      case isCharJapanesePunctuation(input):\n        return OTHER;\n      case isCharJapanese(input):\n        return JA;\n      case isCharRomaji(input):\n        return EN;\n      default:\n        return OTHER;\n    }\n  } else {\n    switch (true) {\n      case isCharJaSpace(input):\n        return SPACE;\n      case isCharEnSpace(input):\n        return SPACE;\n      case isCharJaNum(input):\n        return JA_NUM;\n      case isCharEnNum(input):\n        return EN_NUM;\n      case isCharEnglishPunctuation(input):\n        return EN_PUNC;\n      case isCharJapanesePunctuation(input):\n        return JA_PUNC;\n      case isCharKanji(input):\n        return KANJI;\n      case isCharHiragana(input):\n        return HIRAGANA;\n      case isCharKatakana(input):\n        return KATAKANA;\n      case isCharJapanese(input):\n        return JA;\n      case isCharRomaji(input):\n        return EN;\n      default:\n        return OTHER;\n    }\n  }\n}\n\n/**\n * Splits input into array of strings separated by opinionated token types\n * `'en', 'ja', 'englishNumeral', 'japaneseNumeral','englishPunctuation', 'japanesePunctuation','kanji', 'hiragana', 'katakana', 'space', 'other'`.\n * If `{ compact: true }` then many same-language tokens are combined (spaces + text, kanji + kana, numeral + punctuation).\n * If `{ detailed: true }` then return array will contain `{ type, value }` instead of `'value'`\n * @param  {String} input text\n * @param  {Object} [options={ compact: false, detailed: false}] options to modify output style\n * @return {String|Object[]} text split into tokens containing values, or detailed object\n * @example\n * tokenize('ãµãµãƒ•ãƒ•')\n * // ['ãµãµ', 'ãƒ•ãƒ•']\n *\n * tokenize('æ„Ÿã˜')\n * // ['æ„Ÿ', 'ã˜']\n *\n * tokenize('äººã€…')\n * // ['äººã€…']\n *\n * tokenize('truly ç§ã¯æ‚²ã—ã„')\n * // ['truly', ' ', 'ç§', 'ã¯', 'æ‚²', 'ã—ã„']\n *\n * tokenize('truly ç§ã¯æ‚²ã—ã„', { compact: true })\n * // ['truly ', 'ç§ã¯æ‚²ã—ã„']\n *\n * tokenize('5romaji here...!?äººã€…æ¼¢å­—ã²ã‚‰ãŒãªã‚«ã‚¿ã€€ã‚«ãƒŠï¼”ã€Œï¼³ï¼¨ï¼©ï¼¯ã€ã€‚ï¼')\n * // [ '5', 'romaji', ' ', 'here', '...!?', 'äººã€…æ¼¢å­—', 'ã²ã‚‰ãŒãª', 'ã‚«ã‚¿', 'ã€€', 'ã‚«ãƒŠ', 'ï¼”', 'ã€Œ', 'ï¼³ï¼¨ï¼©ï¼¯', 'ã€ã€‚ï¼']\n *\n * tokenize('5romaji here...!?äººã€…æ¼¢å­—ã²ã‚‰ãŒãªã‚«ã‚¿ã€€ã‚«ãƒŠï¼”ã€Œï¼³ï¼¨ï¼©ï¼¯ã€ã€‚ï¼', { compact: true })\n * // [ '5', 'romaji here', '...!?', 'äººã€…æ¼¢å­—ã²ã‚‰ãŒãªã‚«ã‚¿ã€€ã‚«ãƒŠ', 'ï¼”ã€Œ', 'ï¼³ï¼¨ï¼©ï¼¯', 'ã€ã€‚ï¼']\n *\n * tokenize('5romaji here...!?äººã€…æ¼¢å­—ã²ã‚‰ãŒãªã‚«ã‚¿ã€€ã‚«ãƒŠï¼”ã€Œï¼³ï¼¨ï¼©ï¼¯ã€ã€‚ï¼ Ù„Ù†Ø°Ù‡Ø¨', { detailed: true })\n * // [\n *  { type: 'englishNumeral', value: '5' },\n *  { type: 'en', value: 'romaji' },\n *  { type: 'space', value: ' ' },\n *  { type: 'en', value: 'here' },\n *  { type: 'englishPunctuation', value: '...!?' },\n *  { type: 'kanji', value: 'äººã€…æ¼¢å­—' },\n *  { type: 'hiragana', value: 'ã²ã‚‰ãŒãª' },\n *  { type: 'katakana', value: 'ã‚«ã‚¿' },\n *  { type: 'space', value: 'ã€€' },\n *  { type: 'katakana', value: 'ã‚«ãƒŠ' },\n *  { type: 'japaneseNumeral', value: 'ï¼”' },\n *  { type: 'japanesePunctuation', value: 'ã€Œ' },\n *  { type: 'ja', value: 'ï¼³ï¼¨ï¼©ï¼¯' },\n *  { type: 'japanesePunctuation', value: 'ã€ã€‚ï¼' },\n *  { type: 'space', value: ' ' },\n *  { type: 'other', value: 'Ù„Ù†Ø°Ù‡Ø¨' },\n * ]\n *\n * tokenize('5romaji here...!?äººã€…æ¼¢å­—ã²ã‚‰ãŒãªã‚«ã‚¿ã€€ã‚«ãƒŠï¼”ã€Œï¼³ï¼¨ï¼©ï¼¯ã€ã€‚ï¼ Ù„Ù†Ø°Ù‡Ø¨', { compact: true, detailed: true})\n * // [\n *  { type: 'other', value: '5' },\n *  { type: 'en', value: 'romaji here' },\n *  { type: 'other', value: '...!?' },\n *  { type: 'ja', value: 'äººã€…æ¼¢å­—ã²ã‚‰ãŒãªã‚«ã‚¿ã€€ã‚«ãƒŠ' },\n *  { type: 'other', value: 'ï¼”ã€Œ' },\n *  { type: 'ja', value: 'ï¼³ï¼¨ï¼©ï¼¯' },\n *  { type: 'other', value: 'ã€ã€‚ï¼' },\n *  { type: 'en', value: ' ' },\n *  { type: 'other', value: 'Ù„Ù†Ø°Ù‡Ø¨' },\n *]\n */\nfunction tokenize(input) {\n  let {\n    compact = false,\n    detailed = false\n  } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  if (input == null || isEmpty(input)) {\n    return [];\n  }\n  const chars = [...input];\n  let initial = chars.shift();\n  let prevType = getType(initial, compact);\n  initial = detailed ? {\n    type: prevType,\n    value: initial\n  } : initial;\n  const result = chars.reduce((tokens, char) => {\n    const currType = getType(char, compact);\n    const sameType = currType === prevType;\n    prevType = currType;\n    let newValue = char;\n    if (sameType) {\n      newValue = (detailed ? tokens.pop().value : tokens.pop()) + newValue;\n    }\n    return detailed ? tokens.concat({\n      type: currType,\n      value: newValue\n    }) : tokens.concat(newValue);\n  }, [initial]);\n  return result;\n}\nconst isLeadingWithoutInitialKana = (input, leading) => leading && !isKana(input[0]);\nconst isTrailingWithoutFinalKana = (input, leading) => !leading && !isKana(input[input.length - 1]);\nconst isInvalidMatcher = (input, matchKanji) => matchKanji && ![...matchKanji].some(isKanji) || !matchKanji && isKana(input);\n\n/**\n * Strips [Okurigana](https://en.wikipedia.org/wiki/Okurigana)\n * @param  {String} input text\n * @param  {Object} [options={ leading: false, matchKanji: '' }] optional config\n * @return {String} text with okurigana removed\n * @example\n * stripOkurigana('è¸ã¿è¾¼ã‚€')\n * // => 'è¸ã¿è¾¼'\n * stripOkurigana('ãŠç¥ã„')\n * // => 'ãŠç¥'\n * stripOkurigana('ãŠè…¹', { leading: true });\n * // => 'è…¹'\n * stripOkurigana('ãµã¿ã“ã‚€', { matchKanji: 'è¸ã¿è¾¼ã‚€' });\n * // => 'ãµã¿ã“'\n * stripOkurigana('ãŠã¿ã¾ã„', { matchKanji: 'ãŠç¥ã„', leading: true });\n * // => 'ã¿ã¾ã„'\n */\nfunction stripOkurigana() {\n  let input = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  let {\n    leading = false,\n    matchKanji = ''\n  } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  if (!isJapanese(input) || isLeadingWithoutInitialKana(input, leading) || isTrailingWithoutFinalKana(input, leading) || isInvalidMatcher(input, matchKanji)) {\n    return input;\n  }\n  const chars = matchKanji || input;\n  const okuriganaRegex = new RegExp(leading ? \"^\".concat(tokenize(chars).shift()) : \"\".concat(tokenize(chars).pop(), \"$\"));\n  return input.replace(okuriganaRegex, '');\n}\nvar arrayZip = zip;\n\n/*\n  zip([1, 2, 3]); // [[1], [2], [3]]\n  zip([1, 2, 3], ['a', 'b', 'c']); // [[1, 'a'], [2, 'b'], [3, 'c']]\n  zip([1, 2], ['a', 'b'], [true, false]); //[[1, 'a', true], [2, 'b', false]]\n\n  zip([1, 2, 3], ['a', 'b'], [true]);\n  // [[1, 'a', true], [2, 'b', undefined], [3, undefined, undefined]]\n\n  zip(undefined, {}, false, 1, 'foo'); // throws\n  zip([1, 2], ['a', 'b'], undefined, {}, false, 1, 'foo'); // throws\n*/\n\nfunction zip() {\n  var result = [];\n  var args = Array.prototype.slice.call(arguments);\n  var argsLen = args.length;\n  var maxLen = 0;\n  var i, j;\n  if (!argsLen) {\n    throw new Error('zip requires at least one argument');\n  }\n  for (i = 0; i < argsLen; i++) {\n    if (!Array.isArray(args[i])) {\n      throw new Error('all arguments must be arrays');\n    }\n    var arrLen = args[i].length;\n    if (arrLen > maxLen) {\n      maxLen = arrLen;\n    }\n  }\n  for (i = 0; i < maxLen; i++) {\n    var group = [];\n    for (j = 0; j < argsLen; j++) {\n      if (!Array.isArray(args[j])) {\n        throw new Error('all arguments must be arrays');\n      }\n      group[j] = args[j][i];\n    }\n    result[i] = group;\n  }\n  return result;\n}\n\n/**\n * Combines furigana with kanji into an array of string pairs.\n * @param  {String} word vocab kanji word\n * @param  {String} reading vocab kana reading\n * @param  {String|Object} furi furigana placement info\n * @return {Array} furigana/kanji pairs\n * @example\n * combineFuri('ãŠä¸–è¾ž', 'ãŠã›ã˜', '1:ã›;2:ã˜')\n * // => [['', 'ãŠ'], ['ã›', 'ä¸–'], ['ã˜', 'è¾ž']]\n * combineFuri('å¤§äººã—ã„', 'ãŠã¨ãªã—ã„') // smart fallbacks\n * // => [['ãŠã¨ãª', 'å¤§äºº'], ['', 'ã—ã„']]\n * combineFuri('ä½¿ã„æ–¹', 'ã¤ã‹ã„ã‹ãŸ') // smart fallbacks\n * // => [['ã¤ã‹', 'ä½¿'], ['', 'ã„'], ['ã‹ãŸ', 'æ–¹']]\n *\n * // special compound readings (ç¾©è¨“/ç†Ÿå­—è¨“) are spread across relevant kanji\n * combineFuri('èƒ¡åº§', 'ã‚ãã‚‰', '0:ã‚ãã‚‰')\n * // => [['ã‚ãã‚‰', 'èƒ¡åº§']]\n */\n\nfunction combineFuri() {\n  var word = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  var reading = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n  var furi = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : '';\n  var furiLocs = parseFuri(furi); // ç¾©è¨“/ç†Ÿå­—è¨“ words with a single furi loc: ä»Šæ—¥ \"0:ãã‚‡ã†\"\n\n  var isSpecialReading = furiLocs.length === 1 && _toConsumableArray(word).every(isKanji);\n  var isKanaWord = _toConsumableArray(word).every(isKana);\n  var isWanikaniMadness = _toConsumableArray(reading).some(isHiragana) && _toConsumableArray(reading).some(isKatakana);\n  if (word === reading || isKanaWord) {\n    return [['', word]];\n  }\n  if (!furi || isSpecialReading || isWanikaniMadness) {\n    return basicFuri(word, reading);\n  }\n  return generatePairs(word, furiLocs);\n}\n/**\n * Displays simple furigana by removing redundant kana\n * @param  {String} [word=''] 'ãŠè¦‹èˆžã„'\n * @param  {String} [reading=''] 'ãŠã¿ã¾ã„'\n * @return {Array} [['', 'ãŠ'], ['è¦‹èˆž', 'ã¿ã¾'], ['', 'ã„']]\n */\n\nfunction basicFuri() {\n  var word = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  var reading = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n\n  // early return + guard against words like ï¼‘æ—¥ which are tokenized unfavourably\n  if (_toConsumableArray(word).every(function (c) {\n    return !isKana(c);\n  })) {\n    return [[reading, word]];\n  }\n  var _ref = [reading.slice(0, word.length - stripOkurigana(word, {\n      leading: true\n    }).length), reading.slice(stripOkurigana(reading, {\n      matchKanji: word\n    }).length)],\n    bikago = _ref[0],\n    okurigana = _ref[1];\n  var innerWordTokens = tokenize(removeExtraneousKana(word, bikago, okurigana));\n  var innerReadingChars = removeExtraneousKana(reading, bikago, okurigana);\n  var kanjiOddKanaEvenRegex = RegExp(innerWordTokens.map(function (_char) {\n    return isKanji(_char) ? '(.*)' : \"(\".concat(_char, \")\");\n  }).join(''));\n  var _ref2 = innerReadingChars.match(kanjiOddKanaEvenRegex) || [];\n  var _ref3 = _toArray(_ref2);\n  innerReadingChars = _ref3.slice(1);\n  var ret = arrayZip(innerReadingChars, innerWordTokens).map(skipRedundantReadings);\n  if (bikago) {\n    ret.unshift(['', bikago]);\n  }\n  if (okurigana) {\n    ret.push(['', okurigana]);\n  }\n  return ret;\n}\nfunction removeExtraneousKana() {\n  var str = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  var leading = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n  var trailing = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : '';\n  return str.replace(RegExp(\"^\".concat(leading)), '').replace(RegExp(\"\".concat(trailing, \"$\")), '');\n}\nfunction skipRedundantReadings(_ref4) {\n  var _ref5 = _slicedToArray(_ref4, 2),\n    reading = _ref5[0],\n    _ref5$ = _ref5[1],\n    word = _ref5$ === void 0 ? '' : _ref5$;\n  return !reading || reading === word ? ['', word] : [reading, word];\n}\nfunction parseFuri(data) {\n  return typeof data === 'string' ? parseFuriString(data) : parseFuriObject(data);\n}\n/**\n * Parses furigana placement object\n * @param  {Object} [locations={}] { 1:'ã›', 2:'ã˜' }\n * @return {Array} [ [[1, 2], 'ã›'], [[2, 3], 'ã˜'] ]\n */\n\nfunction parseFuriObject() {\n  var locations = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  return Object.entries(locations).map(function (_ref6) {\n    var _ref7 = _slicedToArray(_ref6, 2),\n      start = _ref7[0],\n      content = _ref7[1];\n    return [[Number(start), Number(start) + 1], content];\n  });\n}\n/**\n * Parses furigana placement string\n * @param  {String} [locations=''] '1:ã›;2:ã˜'\n * @return {Array} [ [[1, 2], 'ã›'], [[2, 3], 'ã˜'] ]\n */\n\nfunction parseFuriString() {\n  var locations = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  return locations.split(';').map(function (entry) {\n    var _entry$split = entry.split(':'),\n      _entry$split2 = _slicedToArray(_entry$split, 2),\n      indexes = _entry$split2[0],\n      content = _entry$split2[1];\n    var _indexes$split$map = indexes.split('-').map(Number),\n      _indexes$split$map2 = _slicedToArray(_indexes$split$map, 2),\n      start = _indexes$split$map2[0],\n      end = _indexes$split$map2[1]; // NOTE: in the JMDict furistring data, the end index is either missing\n    // or it is listed as the *start* index of the final char Â¯\\_(ãƒ„)_/Â¯\n    // so we need to bump it either way to encompass that char\n\n    return [[start, end ? end + 1 : start + 1], content];\n  });\n}\n/**\n * Generates array pairs via furigana location data\n * @param  {String} word 'ãŠä¸–è¾ž'\n * @param  {Array} furiLocs [[[1, 2], 'ã›'], [[2, 3], 'ã˜']]\n * @return {Array} [['', 'ãŠ'], ['ã›', 'ä¸–'], ['ã˜', 'è¾ž']]\n */\n\nfunction generatePairs() {\n  var word = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  var furiLocs = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n  var prevCharEnd = 0;\n  return furiLocs.reduce(function (pairs, _ref8, index, source) {\n    var _ref9 = _slicedToArray(_ref8, 2),\n      _ref9$ = _slicedToArray(_ref9[0], 2),\n      start = _ref9$[0],\n      end = _ref9$[1],\n      furiText = _ref9[1];\n\n    // if no furigana at this index, add intervening chars\n    if (start !== prevCharEnd) {\n      pairs.push(['', word.slice(prevCharEnd, start)]);\n    } // add furigana and associated chars\n\n    pairs.push([furiText, word.slice(start, end)]); // if no more furigana left, add any remaining chars/okurigana with blank furi\n\n    if (end < word.length && !source[index + 1]) {\n      pairs.push(['', word.slice(end)]);\n    }\n    prevCharEnd = end;\n    return pairs;\n  }, []);\n}\nfunction useFuriPairs(word, reading, furi) {\n  return React.useMemo(function () {\n    return combineFuri(word, reading, furi);\n  }, [word, reading, furi]);\n}\nvar _excluded = [\"style\"],\n  _excluded2 = [\"style\"],\n  _excluded3 = [\"style\"],\n  _excluded4 = [\"style\"],\n  _excluded5 = [\"word\", \"reading\", \"furi\", \"showFuri\", \"render\"];\nvar wrapperStyle = {\n  display: 'inline-flex',\n  flexFlow: 'row wrap',\n  fontFamily: \"'\\u30D2\\u30E9\\u30AE\\u30CE\\u89D2\\u30B4 ProN', 'Hiragino Kaku Gothic ProN', 'TakaoP\\u30B4\\u30B7\\u30C3\\u30AF', TakaoPGothic, '\\u6E38\\u30B4\\u30B7\\u30C3\\u30AF', '\\u6E38\\u30B4\\u30B7\\u30C3\\u30AF\\u4F53', YuGothic, 'Yu Gothic', '\\u30E1\\u30A4\\u30EA\\u30AA', Meiryo, '\\uFF2D\\uFF33 \\u30B4\\u30B7\\u30C3\\u30AF', 'MS Gothic', HiraKakuProN-W3, 'MotoyaLCedar', 'Droid Sans Japanese', sans-serif\"\n};\nvar pairStyle = {\n  display: 'inline-flex',\n  fontSize: '24px',\n  lineHeight: '1',\n  flexFlow: 'column nowrap',\n  justifyContent: 'flex-end',\n  alignItems: 'center',\n  alignSelf: 'flex-end'\n};\nvar furiStyle = {\n  display: 'block',\n  fontSize: '0.5em',\n  letterSpacing: '-0.02em',\n  margin: '0 0.1em',\n  paddingTop: '0.2em',\n  paddingBottom: '0.1em',\n  // don't interfere with selection of the content text\n  userSelect: 'none',\n  opacity: '0.9'\n};\nvar textStyle = {\n  display: 'block'\n};\nfunction Wrapper(_ref) {\n  var style = _ref.style,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return /*#__PURE__*/React.createElement(\"span\", _extends({\n    lang: \"ja\",\n    style: _objectSpread2(_objectSpread2({}, wrapperStyle), style)\n  }, props));\n}\nfunction Pair(_ref2) {\n  var style = _ref2.style,\n    props = _objectWithoutProperties(_ref2, _excluded2);\n  return /*#__PURE__*/React.createElement(\"span\", _extends({\n    lang: \"ja\",\n    style: _objectSpread2(_objectSpread2({}, pairStyle), style)\n  }, props));\n}\nfunction Furi(_ref3) {\n  var style = _ref3.style,\n    props = _objectWithoutProperties(_ref3, _excluded3);\n  return /*#__PURE__*/React.createElement(\"span\", _extends({\n    lang: \"ja\",\n    style: _objectSpread2(_objectSpread2({}, furiStyle), style)\n  }, props));\n}\nfunction Text(_ref4) {\n  var style = _ref4.style,\n    props = _objectWithoutProperties(_ref4, _excluded4);\n  return /*#__PURE__*/React.createElement(\"span\", _extends({\n    lang: \"ja\",\n    style: _objectSpread2(_objectSpread2({}, textStyle), style)\n  }, props));\n}\nfunction ReactFuri(_ref5) {\n  var word = _ref5.word,\n    reading = _ref5.reading,\n    furi = _ref5.furi,\n    showFuri = _ref5.showFuri,\n    render = _ref5.render,\n    props = _objectWithoutProperties(_ref5, _excluded5);\n  var pairs = useFuriPairs(word, reading, furi);\n  return typeof render === 'function' ? render({\n    pairs: pairs\n  }) : /*#__PURE__*/React.createElement(Wrapper, props, pairs.map(function (_ref6, index) {\n    var _ref7 = _slicedToArray(_ref6, 2),\n      furiText = _ref7[0],\n      text = _ref7[1];\n    var uniquePairKey = text + index;\n    return /*#__PURE__*/React.createElement(Pair, {\n      key: uniquePairKey\n    }, showFuri && /*#__PURE__*/React.createElement(Furi, null, furiText), /*#__PURE__*/React.createElement(Text, null, text));\n  }));\n}\nReactFuri.defaultProps = {\n  word: '',\n  reading: '',\n  furi: '',\n  showFuri: true\n};\nexport { Furi, Pair, ReactFuri, Text, Wrapper, combineFuri, useFuriPairs };","map":{"version":3,"names":["typeOf","value","Object","toString","call","slice","toLowerCase","isEmpty","input","length","isCharInRange","char","arguments","undefined","start","end","code","charCodeAt","LOWERCASE_ZENKAKU_START","LOWERCASE_ZENKAKU_END","UPPERCASE_ZENKAKU_START","UPPERCASE_ZENKAKU_END","HIRAGANA_START","HIRAGANA_END","KATAKANA_START","KATAKANA_END","KANJI_START","KANJI_END","KANJI_ITERATION_MARK","PROLONGED_SOUND_MARK","ZENKAKU_NUMBERS","ZENKAKU_UPPERCASE","ZENKAKU_LOWERCASE","ZENKAKU_PUNCTUATION_1","ZENKAKU_PUNCTUATION_2","ZENKAKU_PUNCTUATION_3","ZENKAKU_PUNCTUATION_4","ZENKAKU_SYMBOLS_CURRENCY","HIRAGANA_CHARS","KATAKANA_CHARS","HANKAKU_KATAKANA","KATAKANA_PUNCTUATION","KANA_PUNCTUATION","CJK_SYMBOLS_PUNCTUATION","COMMON_CJK","RARE_CJK","KANA_RANGES","JA_PUNCTUATION_RANGES","JAPANESE_RANGES","MODERN_ENGLISH","HEPBURN_MACRON_RANGES","SMART_QUOTE_RANGES","ROMAJI_RANGES","EN_PUNCTUATION_RANGES","isCharJapanese","some","_ref10","isJapanese","allowed","augmented","every","isJa","test","createCustomMapping","customMap","customTree","entries","forEach","_ref11","roma","kana","subTree","split","makeMap","map","mapCopy","JSON","parse","stringify","transformMap","mapSubtree","customSubtree","reduce","newSubtree","_ref12","subtree","SMALL_Y$1","ya","yi","yu","ye","yo","SMALL_VOWELS","a","i","u","e","o","assign","tu","wa","ka","ke","wi","we","isCharLongDash","isCharHiragana","isCharRomaji","_ref13","isCharKatakana","isCharKana","isKana","isHiragana","isKatakana","isCharIterationMark","isCharKanji","isKanji","isCharEnglishPunctuation","_ref14","isCharJapanesePunctuation","_ref15","isCharEnSpace","x","isCharJaSpace","isCharJaNum","isCharEnNum","TOKEN_TYPES","EN","JA","EN_NUM","JA_NUM","EN_PUNC","JA_PUNC","KANJI","HIRAGANA","KATAKANA","SPACE","OTHER","getType","compact","tokenize","detailed","chars","initial","shift","prevType","type","result","tokens","currType","sameType","newValue","pop","concat","isLeadingWithoutInitialKana","leading","isTrailingWithoutFinalKana","isInvalidMatcher","matchKanji","stripOkurigana","okuriganaRegex","RegExp","replace","arrayZip","zip","args","Array","prototype","argsLen","maxLen","j","Error","isArray","arrLen","group","combineFuri","word","reading","furi","furiLocs","parseFuri","isSpecialReading","_toConsumableArray","isKanaWord","isWanikaniMadness","basicFuri","generatePairs","c","_ref","bikago","okurigana","innerWordTokens","removeExtraneousKana","innerReadingChars","kanjiOddKanaEvenRegex","_char","join","_ref2","match","_ref3","_toArray","ret","skipRedundantReadings","unshift","push","str","trailing","_ref4","_ref5","_slicedToArray","_ref5$","data","parseFuriString","parseFuriObject","locations","_ref6","_ref7","content","Number","entry","_entry$split","_entry$split2","indexes","_indexes$split$map","_indexes$split$map2","prevCharEnd","pairs","_ref8","index","source","_ref9","_ref9$","furiText","useFuriPairs","React","useMemo","wrapperStyle","display","flexFlow","fontFamily","pairStyle","fontSize","lineHeight","justifyContent","alignItems","alignSelf","furiStyle","letterSpacing","margin","paddingTop","paddingBottom","userSelect","opacity","textStyle","Wrapper","style","props","_objectWithoutProperties","_excluded","createElement","_extends","lang","_objectSpread2","Pair","_excluded2","Furi","_excluded3","Text","_excluded4","ReactFuri","showFuri","render","_excluded5","text","uniquePairKey","key","defaultProps"],"sources":["../node_modules/wanakana/esm/index.js","../node_modules/just-zip-it/index.mjs","../src/utils.js","../src/hooks.js","../src/components.js"],"sourcesContent":["/**\n * Returns detailed type as string (instead of just 'object' for arrays etc)\n * @private\n * @param {any} value js value\n * @returns {String} type of value\n * @example\n * typeOf({}); // 'object'\n * typeOf([]); // 'array'\n * typeOf(function() {}); // 'function'\n * typeOf(/a/); // 'regexp'\n * typeOf(new Date()); // 'date'\n * typeOf(null); // 'null'\n * typeOf(undefined); // 'undefined'\n * typeOf('a'); // 'string'\n * typeOf(1); // 'number'\n * typeOf(true); // 'boolean'\n * typeOf(new Map()); // 'map'\n * typeOf(new Set()); // 'map'\n */\nfunction typeOf(value) {\n  if (value === null) {\n    return 'null';\n  }\n  if (value !== Object(value)) {\n    return typeof value;\n  }\n  return {}.toString\n    .call(value)\n    .slice(8, -1)\n    .toLowerCase();\n}\n\n/**\n * Checks if input string is empty\n * @param  {String} input text input\n * @return {Boolean} true if no input\n */\nfunction isEmpty(input) {\n  if (typeOf(input) !== 'string') {\n    return true;\n  }\n  return !input.length;\n}\n\n/**\n * Takes a character and a unicode range. Returns true if the char is in the range.\n * @param  {String}  char  unicode character\n * @param  {Number}  start unicode start range\n * @param  {Number}  end   unicode end range\n * @return {Boolean}\n */\nfunction isCharInRange(char = '', start, end) {\n  if (isEmpty(char)) return false;\n  const code = char.charCodeAt(0);\n  return start <= code && code <= end;\n}\n\nconst VERSION = '5.2.0';\n\nconst TO_KANA_METHODS = {\n  HIRAGANA: 'toHiragana',\n  KATAKANA: 'toKatakana',\n};\n\nconst ROMANIZATIONS = {\n  HEPBURN: 'hepburn',\n};\n\n/**\n * Default config for WanaKana, user passed options will be merged with these\n * @type {DefaultOptions}\n * @name defaultOptions\n * @property {Boolean} [useObsoleteKana=false] - Set to true to use obsolete characters, such as ã‚ and ã‚‘.\n * @example\n * toHiragana('we', { useObsoleteKana: true })\n * // => 'ã‚‘'\n * @property {Boolean} [passRomaji=false] - Set to true to pass romaji when using mixed syllabaries with toKatakana() or toHiragana()\n * @example\n * toHiragana('only convert the katakana: ãƒ’ãƒ©ã‚¬ãƒŠ', { passRomaji: true })\n * // => \"only convert the katakana: ã²ã‚‰ãŒãª\"\n * @property {Object} [convertLongVowelMark=true] - Set to false to prevent conversions of 'ãƒ¼' to extended vowels with toHiragana()\n * @example\n * toHiragana('ãƒ©ãƒ¼ãƒ¡ãƒ³', { convertLongVowelMark: false });\n * // => 'ã‚‰ãƒ¼ã‚ã‚“\n * @property {Boolean} [upcaseKatakana=false] - Set to true to convert katakana to uppercase using toRomaji()\n * @example\n * toRomaji('ã²ã‚‰ãŒãª ã‚«ã‚¿ã‚«ãƒŠ', { upcaseKatakana: true })\n * // => \"hiragana KATAKANA\"\n * @property {Boolean|String} [IMEMode=false] - Set to true, 'toHiragana', or 'toKatakana' to handle conversion while it is being typed.\n * @property {String} [romanization='hepburn'] - choose toRomaji() romanization map (currently only 'hepburn')\n * @property {Object} [customKanaMapping] - custom map will be merged with default conversion\n * @example\n * toKana('wanakana', { customKanaMapping: { na: 'ã«', ka: 'Bana' }) };\n * // => 'ã‚ã«Banaã«'\n * @property {Object} [customRomajiMapping] - custom map will be merged with default conversion\n * @example\n * toRomaji('ã¤ã˜ãŽã‚Š', { customRomajiMapping: { ã˜: 'zi', ã¤: 'tu', ã‚Š: 'li' }) };\n * // => 'tuzigili'\n */\nconst DEFAULT_OPTIONS = {\n  useObsoleteKana: false,\n  passRomaji: false,\n  upcaseKatakana: false,\n  IMEMode: false,\n  convertLongVowelMark: true,\n  romanization: ROMANIZATIONS.HEPBURN,\n};\nconst LATIN_UPPERCASE_START = 0x41;\nconst LATIN_UPPERCASE_END = 0x5a;\nconst LOWERCASE_ZENKAKU_START = 0xff41;\nconst LOWERCASE_ZENKAKU_END = 0xff5a;\nconst UPPERCASE_ZENKAKU_START = 0xff21;\nconst UPPERCASE_ZENKAKU_END = 0xff3a;\nconst HIRAGANA_START = 0x3041;\nconst HIRAGANA_END = 0x3096;\nconst KATAKANA_START = 0x30a1;\nconst KATAKANA_END = 0x30fc;\nconst KANJI_START = 0x4e00;\nconst KANJI_END = 0x9faf;\n\nconst KANJI_ITERATION_MARK = 0x3005; // ã€…\nconst PROLONGED_SOUND_MARK = 0x30fc; // ãƒ¼\nconst KANA_SLASH_DOT = 0x30fb; // ãƒ»\n\nconst ZENKAKU_NUMBERS = [0xff10, 0xff19];\nconst ZENKAKU_UPPERCASE = [UPPERCASE_ZENKAKU_START, UPPERCASE_ZENKAKU_END];\nconst ZENKAKU_LOWERCASE = [LOWERCASE_ZENKAKU_START, LOWERCASE_ZENKAKU_END];\nconst ZENKAKU_PUNCTUATION_1 = [0xff01, 0xff0f];\nconst ZENKAKU_PUNCTUATION_2 = [0xff1a, 0xff1f];\nconst ZENKAKU_PUNCTUATION_3 = [0xff3b, 0xff3f];\nconst ZENKAKU_PUNCTUATION_4 = [0xff5b, 0xff60];\nconst ZENKAKU_SYMBOLS_CURRENCY = [0xffe0, 0xffee];\n\nconst HIRAGANA_CHARS = [0x3040, 0x309f];\nconst KATAKANA_CHARS = [0x30a0, 0x30ff];\nconst HANKAKU_KATAKANA = [0xff66, 0xff9f];\nconst KATAKANA_PUNCTUATION = [0x30fb, 0x30fc];\nconst KANA_PUNCTUATION = [0xff61, 0xff65];\nconst CJK_SYMBOLS_PUNCTUATION = [0x3000, 0x303f];\nconst COMMON_CJK = [0x4e00, 0x9fff];\nconst RARE_CJK = [0x3400, 0x4dbf];\n\nconst KANA_RANGES = [\n  HIRAGANA_CHARS,\n  KATAKANA_CHARS,\n  KANA_PUNCTUATION,\n  HANKAKU_KATAKANA,\n];\n\nconst JA_PUNCTUATION_RANGES = [\n  CJK_SYMBOLS_PUNCTUATION,\n  KANA_PUNCTUATION,\n  KATAKANA_PUNCTUATION,\n  ZENKAKU_PUNCTUATION_1,\n  ZENKAKU_PUNCTUATION_2,\n  ZENKAKU_PUNCTUATION_3,\n  ZENKAKU_PUNCTUATION_4,\n  ZENKAKU_SYMBOLS_CURRENCY,\n];\n\n// All Japanese unicode start and end ranges\n// Includes kanji, kana, zenkaku latin chars, punctuation, and number ranges.\nconst JAPANESE_RANGES = [\n  ...KANA_RANGES,\n  ...JA_PUNCTUATION_RANGES,\n  ZENKAKU_UPPERCASE,\n  ZENKAKU_LOWERCASE,\n  ZENKAKU_NUMBERS,\n  COMMON_CJK,\n  RARE_CJK,\n];\n\nconst MODERN_ENGLISH = [0x0000, 0x007f];\nconst HEPBURN_MACRON_RANGES = [\n  [0x0100, 0x0101], // Ä€ Ä\n  [0x0112, 0x0113], // Ä’ Ä“\n  [0x012a, 0x012b], // Äª Ä«\n  [0x014c, 0x014d], // ÅŒ Å\n  [0x016a, 0x016b], // Åª Å«\n];\nconst SMART_QUOTE_RANGES = [\n  [0x2018, 0x2019], // â€˜ â€™\n  [0x201c, 0x201d], // â€œ â€\n];\n\nconst ROMAJI_RANGES = [MODERN_ENGLISH, ...HEPBURN_MACRON_RANGES];\n\nconst EN_PUNCTUATION_RANGES = [\n  [0x20, 0x2f],\n  [0x3a, 0x3f],\n  [0x5b, 0x60],\n  [0x7b, 0x7e],\n  ...SMART_QUOTE_RANGES,\n];\n\n/**\n * Tests a character. Returns true if the character is [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharJapanese(char = '') {\n  return JAPANESE_RANGES.some(([start, end]) => isCharInRange(char, start, end));\n}\n\n/**\n * Test if `input` only includes [Kanji](https://en.wikipedia.org/wiki/Kanji), [Kana](https://en.wikipedia.org/wiki/Kana), zenkaku numbers, and JA punctuation/symbols.â€\n * @param  {String} [input=''] text\n * @param  {Regexp} [allowed] additional test allowed to pass for each char\n * @return {Boolean} true if passes checks\n * @example\n * isJapanese('æ³£ãè™«')\n * // => true\n * isJapanese('ã‚ã‚¢')\n * // => true\n * isJapanese('ï¼’æœˆ') // Zenkaku numbers allowed\n * // => true\n * isJapanese('æ³£ãè™«ã€‚ï¼ã€œï¼„') // Zenkaku/JA punctuation\n * // => true\n * isJapanese('æ³£ãè™«.!~$') // Latin punctuation fails\n * // => false\n * isJapanese('Aæ³£ãè™«')\n * // => false\n * isJapanese('â‰ªå½æ‹¬å¼§â‰«', /[â‰ªâ‰«]/);\n * // => true\n */\nfunction isJapanese(input = '', allowed) {\n  const augmented = typeOf(allowed) === 'regexp';\n  return isEmpty(input)\n    ? false\n    : [...input].every((char) => {\n      const isJa = isCharJapanese(char);\n      return !augmented ? isJa : isJa || allowed.test(char);\n    });\n}\n\nvar safeIsNaN = Number.isNaN ||\n    function ponyfill(value) {\n        return typeof value === 'number' && value !== value;\n    };\nfunction isEqual(first, second) {\n    if (first === second) {\n        return true;\n    }\n    if (safeIsNaN(first) && safeIsNaN(second)) {\n        return true;\n    }\n    return false;\n}\nfunction areInputsEqual(newInputs, lastInputs) {\n    if (newInputs.length !== lastInputs.length) {\n        return false;\n    }\n    for (var i = 0; i < newInputs.length; i++) {\n        if (!isEqual(newInputs[i], lastInputs[i])) {\n            return false;\n        }\n    }\n    return true;\n}\n\nfunction memoizeOne(resultFn, isEqual) {\n    if (isEqual === void 0) { isEqual = areInputsEqual; }\n    var cache = null;\n    function memoized() {\n        var newArgs = [];\n        for (var _i = 0; _i < arguments.length; _i++) {\n            newArgs[_i] = arguments[_i];\n        }\n        if (cache && cache.lastThis === this && isEqual(newArgs, cache.lastArgs)) {\n            return cache.lastResult;\n        }\n        var lastResult = resultFn.apply(this, newArgs);\n        cache = {\n            lastResult: lastResult,\n            lastArgs: newArgs,\n            lastThis: this,\n        };\n        return lastResult;\n    }\n    memoized.clear = function clear() {\n        cache = null;\n    };\n    return memoized;\n}\n\nvar has = Object.prototype.hasOwnProperty;\n\nfunction find(iter, tar, key) {\n\tfor (key of iter.keys()) {\n\t\tif (dequal(key, tar)) return key;\n\t}\n}\n\nfunction dequal(foo, bar) {\n\tvar ctor, len, tmp;\n\tif (foo === bar) return true;\n\n\tif (foo && bar && (ctor=foo.constructor) === bar.constructor) {\n\t\tif (ctor === Date) return foo.getTime() === bar.getTime();\n\t\tif (ctor === RegExp) return foo.toString() === bar.toString();\n\n\t\tif (ctor === Array) {\n\t\t\tif ((len=foo.length) === bar.length) {\n\t\t\t\twhile (len-- && dequal(foo[len], bar[len]));\n\t\t\t}\n\t\t\treturn len === -1;\n\t\t}\n\n\t\tif (ctor === Set) {\n\t\t\tif (foo.size !== bar.size) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tfor (len of foo) {\n\t\t\t\ttmp = len;\n\t\t\t\tif (tmp && typeof tmp === 'object') {\n\t\t\t\t\ttmp = find(bar, tmp);\n\t\t\t\t\tif (!tmp) return false;\n\t\t\t\t}\n\t\t\t\tif (!bar.has(tmp)) return false;\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\n\t\tif (ctor === Map) {\n\t\t\tif (foo.size !== bar.size) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tfor (len of foo) {\n\t\t\t\ttmp = len[0];\n\t\t\t\tif (tmp && typeof tmp === 'object') {\n\t\t\t\t\ttmp = find(bar, tmp);\n\t\t\t\t\tif (!tmp) return false;\n\t\t\t\t}\n\t\t\t\tif (!dequal(len[1], bar.get(tmp))) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\n\t\tif (ctor === ArrayBuffer) {\n\t\t\tfoo = new Uint8Array(foo);\n\t\t\tbar = new Uint8Array(bar);\n\t\t} else if (ctor === DataView) {\n\t\t\tif ((len=foo.byteLength) === bar.byteLength) {\n\t\t\t\twhile (len-- && foo.getInt8(len) === bar.getInt8(len));\n\t\t\t}\n\t\t\treturn len === -1;\n\t\t}\n\n\t\tif (ArrayBuffer.isView(foo)) {\n\t\t\tif ((len=foo.byteLength) === bar.byteLength) {\n\t\t\t\twhile (len-- && foo[len] === bar[len]);\n\t\t\t}\n\t\t\treturn len === -1;\n\t\t}\n\n\t\tif (!ctor || typeof foo === 'object') {\n\t\t\tlen = 0;\n\t\t\tfor (ctor in foo) {\n\t\t\t\tif (has.call(foo, ctor) && ++len && !has.call(bar, ctor)) return false;\n\t\t\t\tif (!(ctor in bar) || !dequal(foo[ctor], bar[ctor])) return false;\n\t\t\t}\n\t\t\treturn Object.keys(bar).length === len;\n\t\t}\n\t}\n\n\treturn foo !== foo && bar !== bar;\n}\n\n/**\n * Easy re-use of merging with default options\n * @param {Object} opts user options\n * @returns user options merged over default options\n */\nconst mergeWithDefaultOptions = (opts = {}) => Object.assign({}, DEFAULT_OPTIONS, opts);\n\nfunction applyMapping(string, mapping, convertEnding) {\n  const root = mapping;\n\n  function nextSubtree(tree, nextChar) {\n    const subtree = tree[nextChar];\n    if (subtree === undefined) {\n      return undefined;\n    }\n    // if the next child node does not have a node value, set its node value to the input\n    return Object.assign({ '': tree[''] + nextChar }, tree[nextChar]);\n  }\n\n  function newChunk(remaining, currentCursor) {\n    // start parsing a new chunk\n    const firstChar = remaining.charAt(0);\n\n    return parse(\n      Object.assign({ '': firstChar }, root[firstChar]),\n      remaining.slice(1),\n      currentCursor,\n      currentCursor + 1\n    );\n  }\n\n  function parse(tree, remaining, lastCursor, currentCursor) {\n    if (!remaining) {\n      if (convertEnding || Object.keys(tree).length === 1) {\n        // nothing more to consume, just commit the last chunk and return it\n        // so as to not have an empty element at the end of the result\n        return tree[''] ? [[lastCursor, currentCursor, tree['']]] : [];\n      }\n      // if we don't want to convert the ending, because there are still possible continuations\n      // return null as the final node value\n      return [[lastCursor, currentCursor, null]];\n    }\n\n    if (Object.keys(tree).length === 1) {\n      return [[lastCursor, currentCursor, tree['']]].concat(\n        newChunk(remaining, currentCursor)\n      );\n    }\n\n    const subtree = nextSubtree(tree, remaining.charAt(0));\n\n    if (subtree === undefined) {\n      return [[lastCursor, currentCursor, tree['']]].concat(\n        newChunk(remaining, currentCursor)\n      );\n    }\n    // continue current branch\n    return parse(subtree, remaining.slice(1), lastCursor, currentCursor + 1);\n  }\n\n  return newChunk(string, 0);\n}\n\n// transform the tree, so that for example hepburnTree['ã‚”']['ã'][''] === 'va'\n// or kanaTree['k']['y']['a'][''] === 'ãã‚ƒ'\nfunction transform(tree) {\n  return Object.entries(tree).reduce((map, [char, subtree]) => {\n    const endOfBranch = typeOf(subtree) === 'string';\n    // eslint-disable-next-line no-param-reassign\n    map[char] = endOfBranch ? { '': subtree } : transform(subtree);\n    return map;\n  }, {});\n}\n\nfunction getSubTreeOf(tree, string) {\n  return string.split('').reduce((correctSubTree, char) => {\n    if (correctSubTree[char] === undefined) {\n      // eslint-disable-next-line no-param-reassign\n      correctSubTree[char] = {};\n    }\n    return correctSubTree[char];\n  }, tree);\n}\n\n/**\n * Creates a custom mapping tree, returns a function that accepts a defaultMap which the newly created customMapping will be merged with and returned\n * (customMap) => (defaultMap) => mergedMap\n * @param  {Object} customMap { 'ka' : 'ãª' }\n * @return {Function} (defaultMap) => defaultMergedWithCustomMap\n * @example\n * const sillyMap = createCustomMapping({ 'ã¡ã‚ƒ': 'time', 'èŒŽ': 'cookie'ã€€});\n * // sillyMap is passed defaultMapping to merge with when called in toRomaji()\n * toRomaji(\"It's èŒŽ ã¡ã‚ƒ ã‚ˆ\", { customRomajiMapping: sillyMap });\n * // => 'It's cookie time yo';\n */\nfunction createCustomMapping(customMap = {}) {\n  const customTree = {};\n\n  if (typeOf(customMap) === 'object') {\n    Object.entries(customMap).forEach(([roma, kana]) => {\n      let subTree = customTree;\n      roma.split('').forEach((char) => {\n        if (subTree[char] === undefined) {\n          subTree[char] = {};\n        }\n        subTree = subTree[char];\n      });\n      subTree[''] = kana;\n    });\n  }\n\n  return function makeMap(map) {\n    const mapCopy = JSON.parse(JSON.stringify(map));\n\n    function transformMap(mapSubtree, customSubtree) {\n      if (mapSubtree === undefined || typeOf(mapSubtree) === 'string') {\n        return customSubtree;\n      }\n      return Object.entries(customSubtree).reduce(\n        (newSubtree, [char, subtree]) => {\n          // eslint-disable-next-line no-param-reassign\n          newSubtree[char] = transformMap(mapSubtree[char], subtree);\n          return newSubtree;\n        },\n        mapSubtree\n      );\n    }\n\n    return transformMap(mapCopy, customTree);\n  };\n}\n\n// allow consumer to pass either function or object as customMapping\nfunction mergeCustomMapping(map, customMapping) {\n  if (!customMapping) {\n    return map;\n  }\n  return typeOf(customMapping) === 'function'\n    ? customMapping(map)\n    : createCustomMapping(customMapping)(map);\n}\n\n// NOTE: not exactly kunrei shiki, for example ã¢ã‚ƒ -> dya instead of zya, to avoid name clashing\n/* eslint-disable */\n// prettier-ignore\nconst BASIC_KUNREI = {\n  a: 'ã‚', i: 'ã„', u: 'ã†', e: 'ãˆ', o: 'ãŠ',\n  k: { a: 'ã‹', i: 'ã', u: 'ã', e: 'ã‘', o: 'ã“', },\n  s: { a: 'ã•', i: 'ã—', u: 'ã™', e: 'ã›', o: 'ã', },\n  t: { a: 'ãŸ', i: 'ã¡', u: 'ã¤', e: 'ã¦', o: 'ã¨', },\n  n: { a: 'ãª', i: 'ã«', u: 'ã¬', e: 'ã­', o: 'ã®', },\n  h: { a: 'ã¯', i: 'ã²', u: 'ãµ', e: 'ã¸', o: 'ã»', },\n  m: { a: 'ã¾', i: 'ã¿', u: 'ã‚€', e: 'ã‚', o: 'ã‚‚', },\n  y: { a: 'ã‚„', u: 'ã‚†', o: 'ã‚ˆ' },\n  r: { a: 'ã‚‰', i: 'ã‚Š', u: 'ã‚‹', e: 'ã‚Œ', o: 'ã‚', },\n  w: { a: 'ã‚', i: 'ã‚', e: 'ã‚‘', o: 'ã‚’', },\n  g: { a: 'ãŒ', i: 'ãŽ', u: 'ã', e: 'ã’', o: 'ã”', },\n  z: { a: 'ã–', i: 'ã˜', u: 'ãš', e: 'ãœ', o: 'ãž', },\n  d: { a: 'ã ', i: 'ã¢', u: 'ã¥', e: 'ã§', o: 'ã©', },\n  b: { a: 'ã°', i: 'ã³', u: 'ã¶', e: 'ã¹', o: 'ã¼', },\n  p: { a: 'ã±', i: 'ã´', u: 'ã·', e: 'ãº', o: 'ã½', },\n  v: { a: 'ã‚”ã', i: 'ã‚”ãƒ', u: 'ã‚”', e: 'ã‚”ã‡', o: 'ã‚”ã‰', },\n};\n\nconst SPECIAL_SYMBOLS$1 = {\n  '.': 'ã€‚',\n  ',': 'ã€',\n  ':': 'ï¼š',\n  '/': 'ãƒ»',\n  '!': 'ï¼',\n  '?': 'ï¼Ÿ',\n  '~': 'ã€œ',\n  '-': 'ãƒ¼',\n  'â€˜': 'ã€Œ',\n  'â€™': 'ã€',\n  'â€œ': 'ã€Ž',\n  'â€': 'ã€',\n  '[': 'ï¼»',\n  ']': 'ï¼½',\n  '(': 'ï¼ˆ',\n  ')': 'ï¼‰',\n  '{': 'ï½›',\n  '}': 'ï½',\n};\n\nconst CONSONANTS = {\n  k: 'ã',\n  s: 'ã—',\n  t: 'ã¡',\n  n: 'ã«',\n  h: 'ã²',\n  m: 'ã¿',\n  r: 'ã‚Š',\n  g: 'ãŽ',\n  z: 'ã˜',\n  d: 'ã¢',\n  b: 'ã³',\n  p: 'ã´',\n  v: 'ã‚”',\n  q: 'ã',\n  f: 'ãµ',\n};\nconst SMALL_Y$1 = { ya: 'ã‚ƒ', yi: 'ãƒ', yu: 'ã‚…', ye: 'ã‡', yo: 'ã‚‡' };\nconst SMALL_VOWELS = { a: 'ã', i: 'ãƒ', u: 'ã…', e: 'ã‡', o: 'ã‰' };\n\n// typing one should be the same as having typed the other instead\nconst ALIASES = {\n  sh: 'sy', // sha -> sya\n  ch: 'ty', // cho -> tyo\n  cy: 'ty', // cyo -> tyo\n  chy: 'ty', // chyu -> tyu\n  shy: 'sy', // shya -> sya\n  j: 'zy', // ja -> zya\n  jy: 'zy', // jye -> zye\n\n  // exceptions to above rules\n  shi: 'si',\n  chi: 'ti',\n  tsu: 'tu',\n  ji: 'zi',\n  fu: 'hu',\n};\n\n// xtu -> ã£\nconst SMALL_LETTERS = Object.assign(\n  {\n    tu: 'ã£',\n    wa: 'ã‚Ž',\n    ka: 'ãƒµ',\n    ke: 'ãƒ¶',\n  },\n  SMALL_VOWELS,\n  SMALL_Y$1\n);\n\n// don't follow any notable patterns\nconst SPECIAL_CASES = {\n  yi: 'ã„',\n  wu: 'ã†',\n  ye: 'ã„ã‡',\n  wi: 'ã†ãƒ',\n  we: 'ã†ã‡',\n  kwa: 'ãã',\n  whu: 'ã†',\n  // because it's not thya for ã¦ã‚ƒ but tha\n  // and tha is not ã¦ã, but ã¦ã‚ƒ\n  tha: 'ã¦ã‚ƒ',\n  thu: 'ã¦ã‚…',\n  tho: 'ã¦ã‚‡',\n  dha: 'ã§ã‚ƒ',\n  dhu: 'ã§ã‚…',\n  dho: 'ã§ã‚‡',\n};\n\nconst AIUEO_CONSTRUCTIONS = {\n  wh: 'ã†',\n  kw: 'ã',\n  qw: 'ã',\n  q: 'ã',\n  gw: 'ã',\n  sw: 'ã™',\n  ts: 'ã¤',\n  th: 'ã¦',\n  tw: 'ã¨',\n  dh: 'ã§',\n  dw: 'ã©',\n  fw: 'ãµ',\n  f: 'ãµ',\n};\n\n/* eslint-enable */\nfunction createRomajiToKanaMap$1() {\n  const kanaTree = transform(BASIC_KUNREI);\n  // pseudo partial application\n  const subtreeOf = (string) => getSubTreeOf(kanaTree, string);\n\n  // add tya, sya, etc.\n  Object.entries(CONSONANTS).forEach(([consonant, yKana]) => {\n    Object.entries(SMALL_Y$1).forEach(([roma, kana]) => {\n      // for example kyo -> ã + ã‚‡\n      subtreeOf(consonant + roma)[''] = yKana + kana;\n    });\n  });\n\n  Object.entries(SPECIAL_SYMBOLS$1).forEach(([symbol, jsymbol]) => {\n    subtreeOf(symbol)[''] = jsymbol;\n  });\n\n  // things like ã†ãƒ, ããƒ, etc.\n  Object.entries(AIUEO_CONSTRUCTIONS).forEach(([consonant, aiueoKana]) => {\n    Object.entries(SMALL_VOWELS).forEach(([vowel, kana]) => {\n      const subtree = subtreeOf(consonant + vowel);\n      subtree[''] = aiueoKana + kana;\n    });\n  });\n\n  // different ways to write ã‚“\n  ['n', \"n'\", 'xn'].forEach((nChar) => {\n    subtreeOf(nChar)[''] = 'ã‚“';\n  });\n\n  // c is equivalent to k, but not for chi, cha, etc. that's why we have to make a copy of k\n  kanaTree.c = JSON.parse(JSON.stringify(kanaTree.k));\n\n  Object.entries(ALIASES).forEach(([string, alternative]) => {\n    const allExceptLast = string.slice(0, string.length - 1);\n    const last = string.charAt(string.length - 1);\n    const parentTree = subtreeOf(allExceptLast);\n    // copy to avoid recursive containment\n    parentTree[last] = JSON.parse(JSON.stringify(subtreeOf(alternative)));\n  });\n\n  function getAlternatives(string) {\n    return [...Object.entries(ALIASES), ...[['c', 'k']]].reduce(\n      (list, [alt, roma]) => (string.startsWith(roma) ? list.concat(string.replace(roma, alt)) : list),\n      []\n    );\n  }\n\n  Object.entries(SMALL_LETTERS).forEach(([kunreiRoma, kana]) => {\n    const last = (char) => char.charAt(char.length - 1);\n    const allExceptLast = (chars) => chars.slice(0, chars.length - 1);\n    const xRoma = `x${kunreiRoma}`;\n    const xSubtree = subtreeOf(xRoma);\n    xSubtree[''] = kana;\n\n    // ltu -> xtu -> ã£\n    const parentTree = subtreeOf(`l${allExceptLast(kunreiRoma)}`);\n    parentTree[last(kunreiRoma)] = xSubtree;\n\n    // ltsu -> ltu -> ã£\n    getAlternatives(kunreiRoma).forEach((altRoma) => {\n      ['l', 'x'].forEach((prefix) => {\n        const altParentTree = subtreeOf(prefix + allExceptLast(altRoma));\n        altParentTree[last(altRoma)] = subtreeOf(prefix + kunreiRoma);\n      });\n    });\n  });\n\n  Object.entries(SPECIAL_CASES).forEach(([string, kana]) => {\n    subtreeOf(string)[''] = kana;\n  });\n\n  // add kka, tta, etc.\n  function addTsu(tree) {\n    return Object.entries(tree).reduce((tsuTree, [key, value]) => {\n      if (!key) {\n        // we have reached the bottom of this branch\n        // eslint-disable-next-line no-param-reassign\n        tsuTree[key] = `ã£${value}`;\n      } else {\n        // more subtrees\n        // eslint-disable-next-line no-param-reassign\n        tsuTree[key] = addTsu(value);\n      }\n      return tsuTree;\n    }, {});\n  }\n  // have to explicitly name c here, because we made it a copy of k, not a reference\n  [...Object.keys(CONSONANTS), 'c', 'y', 'w', 'j'].forEach((consonant) => {\n    const subtree = kanaTree[consonant];\n    subtree[consonant] = addTsu(subtree);\n  });\n  // nn should not be ã£ã‚“\n  delete kanaTree.n.n;\n  // solidify the results, so that there there is referential transparency within the tree\n  return Object.freeze(JSON.parse(JSON.stringify(kanaTree)));\n}\n\nlet romajiToKanaMap = null;\n\nfunction getRomajiToKanaTree() {\n  if (romajiToKanaMap == null) {\n    romajiToKanaMap = createRomajiToKanaMap$1();\n  }\n  return romajiToKanaMap;\n}\n\nconst USE_OBSOLETE_KANA_MAP = createCustomMapping({\n  wi: 'ã‚',\n  we: 'ã‚‘',\n});\n\nfunction IME_MODE_MAP(map) {\n  // in IME mode, we do not want to convert single ns\n  const mapCopy = JSON.parse(JSON.stringify(map));\n  mapCopy.n.n = { '': 'ã‚“' };\n  mapCopy.n[' '] = { '': 'ã‚“' };\n  return mapCopy;\n}\n\n/**\n * Tests if char is in English unicode uppercase range\n * @param  {String} char\n * @return {Boolean}\n */\nfunction isCharUpperCase(char = '') {\n  if (isEmpty(char)) return false;\n  return isCharInRange(char, LATIN_UPPERCASE_START, LATIN_UPPERCASE_END);\n}\n\n/**\n * Returns true if char is 'ãƒ¼'\n * @param  {String} char to test\n * @return {Boolean}\n */\nfunction isCharLongDash(char = '') {\n  if (isEmpty(char)) return false;\n  return char.charCodeAt(0) === PROLONGED_SOUND_MARK;\n}\n\n/**\n * Tests if char is 'ãƒ»'\n * @param  {String} char\n * @return {Boolean} true if 'ãƒ»'\n */\nfunction isCharSlashDot(char = '') {\n  if (isEmpty(char)) return false;\n  return char.charCodeAt(0) === KANA_SLASH_DOT;\n}\n\n/**\n * Tests a character. Returns true if the character is [Hiragana](https://en.wikipedia.org/wiki/Hiragana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharHiragana(char = '') {\n  if (isEmpty(char)) return false;\n  if (isCharLongDash(char)) return true;\n  return isCharInRange(char, HIRAGANA_START, HIRAGANA_END);\n}\n\n/**\n * Convert [Hiragana](https://en.wikipedia.org/wiki/Hiragana) to [Katakana](https://en.wikipedia.org/wiki/Katakana)\n * Passes through any non-hiragana chars\n * @private\n * @param  {String} [input=''] text input\n * @return {String} converted text\n * @example\n * hiraganaToKatakana('ã²ã‚‰ãŒãª')\n * // => \"ãƒ’ãƒ©ã‚¬ãƒŠ\"\n * hiraganaToKatakana('ã²ã‚‰ãŒãª is a type of kana')\n * // => \"ãƒ’ãƒ©ã‚¬ãƒŠ is a type of kana\"\n */\nfunction hiraganaToKatakana(input = '') {\n  const kata = [];\n  input.split('').forEach((char) => {\n    // Short circuit to avoid incorrect codeshift for 'ãƒ¼' and 'ãƒ»'\n    if (isCharLongDash(char) || isCharSlashDot(char)) {\n      kata.push(char);\n    } else if (isCharHiragana(char)) {\n      // Shift charcode.\n      const code = char.charCodeAt(0) + (KATAKANA_START - HIRAGANA_START);\n      const kataChar = String.fromCharCode(code);\n      kata.push(kataChar);\n    } else {\n      // Pass non-hiragana chars through\n      kata.push(char);\n    }\n  });\n  return kata.join('');\n}\n\n// memoize and deeply compare args so we only recreate when necessary\nconst createRomajiToKanaMap = memoizeOne(\n  (IMEMode, useObsoleteKana, customKanaMapping) => {\n    let map = getRomajiToKanaTree();\n\n    map = IMEMode ? IME_MODE_MAP(map) : map;\n    map = useObsoleteKana ? USE_OBSOLETE_KANA_MAP(map) : map;\n\n    if (customKanaMapping) {\n      map = mergeCustomMapping(map, customKanaMapping);\n    }\n\n    return map;\n  },\n  dequal\n);\n\n/**\n * Convert [Romaji](https://en.wikipedia.org/wiki/Romaji) to [Kana](https://en.wikipedia.org/wiki/Kana), lowercase text will result in [Hiragana](https://en.wikipedia.org/wiki/Hiragana) and uppercase text will result in [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} [input=''] text\n * @param  {DefaultOptions} [options=defaultOptions]\n * @return {String} converted text\n * @example\n * toKana('onaji BUTTSUUJI')\n * // => 'ãŠãªã˜ ãƒ–ãƒƒãƒ„ã‚¦ã‚¸'\n * toKana('ONAJI buttsuuji')\n * // => 'ã‚ªãƒŠã‚¸ ã¶ã£ã¤ã†ã˜'\n * toKana('åº§ç¦…â€˜zazenâ€™ã‚¹ã‚¿ã‚¤ãƒ«')\n * // => 'åº§ç¦…ã€Œã–ãœã‚“ã€ã‚¹ã‚¿ã‚¤ãƒ«'\n * toKana('batsuge-mu')\n * // => 'ã°ã¤ã’ãƒ¼ã‚€'\n * toKana('!?.:/,~-â€˜â€™â€œâ€[](){}') // Punctuation conversion\n * // => 'ï¼ï¼Ÿã€‚ï¼šãƒ»ã€ã€œãƒ¼ã€Œã€ã€Žã€ï¼»ï¼½ï¼ˆï¼‰ï½›ï½'\n * toKana('we', { useObsoleteKana: true })\n * // => 'ã‚‘'\n * toKana('wanakana', { customKanaMapping: { na: 'ã«', ka: 'bana' } });\n * // => 'ã‚ã«banaã«'\n */\nfunction toKana(input = '', options = {}, map) {\n  let config;\n  if (!map) {\n    config = mergeWithDefaultOptions(options);\n    map = createRomajiToKanaMap(\n      config.IMEMode,\n      config.useObsoleteKana,\n      config.customKanaMapping\n    );\n  } else {\n    config = options;\n  }\n\n  // throw away the substring index information and just concatenate all the kana\n  return splitIntoConvertedKana(input, config, map)\n    .map((kanaToken) => {\n      const [start, end, kana] = kanaToken;\n      if (kana === null) {\n        // haven't converted the end of the string, since we are in IME mode\n        return input.slice(start);\n      }\n      const enforceHiragana = config.IMEMode === TO_KANA_METHODS.HIRAGANA;\n      const enforceKatakana = config.IMEMode === TO_KANA_METHODS.KATAKANA\n        || [...input.slice(start, end)].every(isCharUpperCase);\n\n      return enforceHiragana || !enforceKatakana\n        ? kana\n        : hiraganaToKatakana(kana);\n    })\n    .join('');\n}\n\n/**\n *\n * @private\n * @param {String} [input=''] input text\n * @param {DefaultOptions} [options=defaultOptions] toKana options\n * @param {Object} [map] custom mapping\n * @returns {Array[]} [[start, end, token]]\n * @example\n * splitIntoConvertedKana('buttsuuji')\n * // => [[0, 2, 'ã¶'], [2, 6, 'ã£ã¤'], [6, 7, 'ã†'], [7, 9, 'ã˜']]\n */\nfunction splitIntoConvertedKana(input = '', options = {}, map) {\n  const { IMEMode, useObsoleteKana, customKanaMapping } = options;\n\n  if (!map) {\n    map = createRomajiToKanaMap(IMEMode, useObsoleteKana, customKanaMapping);\n  }\n\n  return applyMapping(input.toLowerCase(), map, !IMEMode);\n}\n\nlet LISTENERS = [];\n/**\n * Automagically replaces input values with converted text to kana\n * @param  {defaultOptions} [options] user config overrides, default conversion is toKana()\n * @return {Function} event handler with bound options\n * @private\n */\nfunction makeOnInput(options) {\n  let prevInput;\n\n  // Enforce IMEMode if not already specified\n  const mergedConfig = Object.assign({}, mergeWithDefaultOptions(options), {\n    IMEMode: options.IMEMode || true,\n  });\n\n  const preConfiguredMap = createRomajiToKanaMap(\n    mergedConfig.IMEMode,\n    mergedConfig.useObsoleteKana,\n    mergedConfig.customKanaMapping\n  );\n\n  const triggers = [\n    ...Object.keys(preConfiguredMap),\n    ...Object.keys(preConfiguredMap).map((char) => char.toUpperCase()),\n  ];\n\n  return function onInput({ target }) {\n    if (\n      target.value !== prevInput\n      && target.dataset.ignoreComposition !== 'true'\n    ) {\n      convertInput(target, mergedConfig, preConfiguredMap, triggers);\n    }\n  };\n}\n\nfunction convertInput(target, options, map, triggers, prevInput) {\n  const [head, textToConvert, tail] = splitInput(\n    target.value,\n    target.selectionEnd,\n    triggers\n  );\n  const convertedText = toKana(textToConvert, options, map);\n  const changed = textToConvert !== convertedText;\n\n  if (changed) {\n    const newCursor = head.length + convertedText.length;\n    const newValue = head + convertedText + tail;\n    // eslint-disable-next-line no-param-reassign\n    target.value = newValue;\n\n    if (tail.length) {\n      // push later on event loop (otherwise mid-text insertion can be 1 char too far to the right)\n      setTimeout(() => target.setSelectionRange(newCursor, newCursor), 1);\n    } else {\n      target.setSelectionRange(newCursor, newCursor);\n    }\n  }\n}\n\nfunction onComposition({ type, target, data }) {\n  // navigator.platform is not 100% reliable for singling out all OS,\n  // but for determining desktop \"Mac OS\" it is effective enough.\n  const isMacOS = /Mac/.test(window.navigator && window.navigator.platform);\n  // We don't want to ignore on Android:\n  // https://github.com/WaniKani/WanaKana/issues/82\n  // But MacOS IME auto-closes if we don't ignore:\n  // https://github.com/WaniKani/WanaKana/issues/71\n  // Other platform Japanese IMEs pass through happily\n  if (isMacOS) {\n    if (type === 'compositionupdate' && isJapanese(data)) {\n      // eslint-disable-next-line no-param-reassign\n      target.dataset.ignoreComposition = 'true';\n    }\n\n    if (type === 'compositionend') {\n      // eslint-disable-next-line no-param-reassign\n      target.dataset.ignoreComposition = 'false';\n    }\n  }\n}\n\nfunction trackListeners(id, inputHandler, compositionHandler) {\n  LISTENERS = LISTENERS.concat({\n    id,\n    inputHandler,\n    compositionHandler,\n  });\n}\n\nfunction untrackListeners({ id: targetId }) {\n  LISTENERS = LISTENERS.filter(({ id }) => id !== targetId);\n}\n\nfunction findListeners(el) {\n  return (\n    el && LISTENERS.find(({ id }) => id === el.getAttribute('data-wanakana-id'))\n  );\n}\n\n// Handle non-terminal inserted input conversion:\n// | -> ã‚| -> ã‚ã³| -> ã‚|ã³ -> ã‚s|ã³ -> ã‚sh|ã³ -> ã‚shi|ã³ -> ã‚ã—|ã³\n// or multiple ambiguous positioning (to select which \"s\" to work from)\n// ã“sã“s|ã“sã“ -> ã“sã“so|ã“sã“ -> ã“sã“ã|ã“sã“\nfunction splitInput(text = '', cursor = 0, triggers = []) {\n  let head;\n  let toConvert;\n  let tail;\n\n  if (cursor === 0 && triggers.includes(text[0])) {\n    [head, toConvert, tail] = workFromStart(text, triggers);\n  } else if (cursor > 0) {\n    [head, toConvert, tail] = workBackwards(text, cursor);\n  } else {\n    [head, toConvert] = takeWhileAndSlice(\n      text,\n      (char) => !triggers.includes(char)\n    );\n    [toConvert, tail] = takeWhileAndSlice(\n      toConvert,\n      (char) => !isJapanese(char)\n    );\n  }\n\n  return [head, toConvert, tail];\n}\n\nfunction workFromStart(text, catalystChars) {\n  return [\n    '',\n    ...takeWhileAndSlice(\n      text,\n      (char) => catalystChars.includes(char) || !isJapanese(char, /[0-9]/)\n    ),\n  ];\n}\n\nfunction workBackwards(text = '', startIndex = 0) {\n  const [toConvert, head] = takeWhileAndSlice(\n    [...text.slice(0, startIndex)].reverse(),\n    (char) => !isJapanese(char)\n  );\n  return [\n    head.reverse().join(''),\n    toConvert\n      .split('')\n      .reverse()\n      .join(''),\n    text.slice(startIndex),\n  ];\n}\n\nfunction takeWhileAndSlice(source = {}, predicate = (x) => !!x) {\n  const result = [];\n  const { length } = source;\n  let i = 0;\n  while (i < length && predicate(source[i], i)) {\n    result.push(source[i]);\n    i += 1;\n  }\n  return [result.join(''), source.slice(i)];\n}\n\n/* eslint-disable no-console */\nconst onInput = ({ target: { value, selectionStart, selectionEnd } }) => console.log('input:', { value, selectionStart, selectionEnd });\nconst onCompositionStart = () => console.log('compositionstart');\nconst onCompositionUpdate = ({\n  target: { value, selectionStart, selectionEnd },\n  data,\n}) => console.log('compositionupdate', {\n  data,\n  value,\n  selectionStart,\n  selectionEnd,\n});\nconst onCompositionEnd = () => console.log('compositionend');\n\nconst events = {\n  input: onInput,\n  compositionstart: onCompositionStart,\n  compositionupdate: onCompositionUpdate,\n  compositionend: onCompositionEnd,\n};\n\nconst addDebugListeners = (input) => {\n  Object.entries(events).forEach(([event, handler]) => input.addEventListener(event, handler)\n  );\n};\n\nconst removeDebugListeners = (input) => {\n  Object.entries(events).forEach(([event, handler]) => input.removeEventListener(event, handler)\n  );\n};\n\nconst ELEMENTS = ['TEXTAREA', 'INPUT'];\n\nlet idCounter = 0;\nconst newId = () => {\n  idCounter += 1;\n  return `${Date.now()}${idCounter}`;\n};\n\n/**\n * Binds eventListener for 'input' events to an input field to automagically replace values with kana\n * Can pass `{ IMEMode: 'toHiragana' || 'toKatakana' }` to enforce kana conversion type\n * @param  {HTMLElement} element textarea, input[type=\"text\"] etc\n * @param  {DefaultOptions} [options=defaultOptions] defaults to { IMEMode: true } using `toKana`\n * @example\n * bind(document.querySelector('#myInput'));\n */\nfunction bind(element = {}, options = {}, debug = false) {\n  if (!ELEMENTS.includes(element.nodeName)) {\n    throw new Error(\n      `Element provided to Wanakana bind() was not a valid input or textarea element.\\n Received: (${JSON.stringify(\n        element\n      )})`\n    );\n  }\n  if (element.hasAttribute('data-wanakana-id')) {\n    return;\n  }\n  const onInput = makeOnInput(options);\n  const id = newId();\n  const attributes = [\n    { name: 'data-wanakana-id', value: id },\n    { name: 'lang', value: 'ja' },\n    { name: 'autoCapitalize', value: 'none' },\n    { name: 'autoCorrect', value: 'off' },\n    { name: 'autoComplete', value: 'off' },\n    { name: 'spellCheck', value: 'false' },\n  ];\n  const previousAttributes = {};\n  attributes.forEach((attribute) => {\n    previousAttributes[attribute.name] = element.getAttribute(attribute.name);\n    element.setAttribute(attribute.name, attribute.value);\n  });\n  element.dataset.previousAttributes = JSON.stringify(previousAttributes);\n  element.addEventListener('input', onInput);\n  element.addEventListener('compositionupdate', onComposition);\n  element.addEventListener('compositionend', onComposition);\n  trackListeners(id, onInput, onComposition);\n  if (debug === true) {\n    addDebugListeners(element);\n  }\n}\n\n/**\n * Unbinds eventListener from input field\n * @param  {HTMLElement} element textarea, input\n */\nfunction unbind(element, debug = false) {\n  const listeners = findListeners(element);\n  if (listeners == null) {\n    throw new Error(\n      `Element provided to Wanakana unbind() had no listener registered.\\n Received: ${JSON.stringify(\n        element\n      )}`\n    );\n  }\n  const { inputHandler, compositionHandler } = listeners;\n  const attributes = JSON.parse(element.dataset.previousAttributes);\n  Object.keys(attributes).forEach((key) => {\n    if (attributes[key]) {\n      element.setAttribute(key, attributes[key]);\n    } else {\n      element.removeAttribute(key);\n    }\n  });\n  element.removeAttribute('data-previous-attributes');\n  element.removeAttribute('data-ignore-composition');\n  element.removeEventListener('input', inputHandler);\n  element.removeEventListener('compositionstart', compositionHandler);\n  element.removeEventListener('compositionupdate', compositionHandler);\n  element.removeEventListener('compositionend', compositionHandler);\n  untrackListeners(listeners);\n  if (debug === true) {\n    removeDebugListeners(element);\n  }\n}\n\n/**\n * Tests a character. Returns true if the character is [Romaji](https://en.wikipedia.org/wiki/Romaji) (allowing [Hepburn romanisation](https://en.wikipedia.org/wiki/Hepburn_romanization))\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharRomaji(char = '') {\n  if (isEmpty(char)) return false;\n  return ROMAJI_RANGES.some(([start, end]) => isCharInRange(char, start, end));\n}\n\n/**\n * Test if `input` is [Romaji](https://en.wikipedia.org/wiki/Romaji) (allowing [Hepburn romanisation](https://en.wikipedia.org/wiki/Hepburn_romanization))\n * @param  {String} [input=''] text\n * @param  {Regexp} [allowed] additional test allowed to pass for each char\n * @return {Boolean} true if [Romaji](https://en.wikipedia.org/wiki/Romaji)\n * @example\n * isRomaji('TÅkyÅ and ÅŒsaka')\n * // => true\n * isRomaji('12a*b&c-d')\n * // => true\n * isRomaji('ã‚ã‚¢A')\n * // => false\n * isRomaji('ãŠé¡˜ã„')\n * // => false\n * isRomaji('aï¼b&cãƒ¼d') // Zenkaku punctuation fails\n * // => false\n * isRomaji('aï¼b&cãƒ¼d', /[ï¼ãƒ¼]/)\n * // => true\n */\nfunction isRomaji(input = '', allowed) {\n  const augmented = typeOf(allowed) === 'regexp';\n  return isEmpty(input)\n    ? false\n    : [...input].every((char) => {\n      const isRoma = isCharRomaji(char);\n      return !augmented ? isRoma : isRoma || allowed.test(char);\n    });\n}\n\n/**\n * Tests a character. Returns true if the character is [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharKatakana(char = '') {\n  return isCharInRange(char, KATAKANA_START, KATAKANA_END);\n}\n\n/**\n * Tests a character. Returns true if the character is [Hiragana](https://en.wikipedia.org/wiki/Hiragana) or [Katakana](https://en.wikipedia.org/wiki/Katakana).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharKana(char = '') {\n  if (isEmpty(char)) return false;\n  return isCharHiragana(char) || isCharKatakana(char);\n}\n\n/**\n * Test if `input` is [Kana](https://en.wikipedia.org/wiki/Kana) ([Katakana](https://en.wikipedia.org/wiki/Katakana) and/or [Hiragana](https://en.wikipedia.org/wiki/Hiragana))\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Kana](https://en.wikipedia.org/wiki/Kana)\n * @example\n * isKana('ã‚')\n * // => true\n * isKana('ã‚¢')\n * // => true\n * isKana('ã‚ãƒ¼ã‚¢')\n * // => true\n * isKana('A')\n * // => false\n * isKana('ã‚Aã‚¢')\n * // => false\n */\nfunction isKana(input = '') {\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharKana);\n}\n\n/**\n * Test if `input` is [Hiragana](https://en.wikipedia.org/wiki/Hiragana)\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Hiragana](https://en.wikipedia.org/wiki/Hiragana)\n * @example\n * isHiragana('ã’ãƒ¼ã‚€')\n * // => true\n * isHiragana('A')\n * // => false\n * isHiragana('ã‚ã‚¢')\n * // => false\n */\nfunction isHiragana(input = '') {\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharHiragana);\n}\n\n/**\n * Test if `input` is [Katakana](https://en.wikipedia.org/wiki/Katakana)\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Katakana](https://en.wikipedia.org/wiki/Katakana)\n * @example\n * isKatakana('ã‚²ãƒ¼ãƒ ')\n * // => true\n * isKatakana('ã‚')\n * // => false\n * isKatakana('A')\n * // => false\n * isKatakana('ã‚ã‚¢')\n * // => false\n */\nfunction isKatakana(input = '') {\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharKatakana);\n}\n\n/**\n * Returns true if char is 'ã€…'\n * @param  {String} char to test\n * @return {Boolean}\n */\nfunction isCharIterationMark(char = '') {\n  if (isEmpty(char)) return false;\n  return char.charCodeAt(0) === KANJI_ITERATION_MARK;\n}\n\n/**\n * Tests a character. Returns true if the character is a CJK ideograph (kanji).\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharKanji(char = '') {\n  return isCharInRange(char, KANJI_START, KANJI_END) || isCharIterationMark(char);\n}\n\n/**\n * Tests if `input` is [Kanji](https://en.wikipedia.org/wiki/Kanji) ([Japanese CJK ideographs](https://en.wikipedia.org/wiki/CJK_Unified_Ideographs))\n * @param  {String} [input=''] text\n * @return {Boolean} true if all [Kanji](https://en.wikipedia.org/wiki/Kanji)\n * @example\n * isKanji('åˆ€')\n * // => true\n * isKanji('åˆ‡è…¹')\n * // => true\n * isKanji('å‹¢ã„')\n * // => false\n * isKanji('ã‚Aã‚¢')\n * // => false\n * isKanji('ðŸ¸')\n * // => false\n */\nfunction isKanji(input = '') {\n  if (isEmpty(input)) return false;\n  return [...input].every(isCharKanji);\n}\n\n/**\n * Test if `input` contains a mix of [Romaji](https://en.wikipedia.org/wiki/Romaji) *and* [Kana](https://en.wikipedia.org/wiki/Kana), defaults to pass through [Kanji](https://en.wikipedia.org/wiki/Kanji)\n * @param  {String} input text\n * @param  {Object} [options={ passKanji: true }] optional config to pass through kanji\n * @return {Boolean} true if mixed\n * @example\n * isMixed('Abã‚ã‚¢'))\n * // => true\n * isMixed('ãŠè…¹A')) // ignores kanji by default\n * // => true\n * isMixed('ãŠè…¹A', { passKanji: false }))\n * // => false\n * isMixed('ab'))\n * // => false\n * isMixed('ã‚ã‚¢'))\n * // => false\n */\nfunction isMixed(input = '', options = { passKanji: true }) {\n  const chars = [...input];\n  let hasKanji = false;\n  if (!options.passKanji) {\n    hasKanji = chars.some(isKanji);\n  }\n  return (chars.some(isHiragana) || chars.some(isKatakana)) && chars.some(isRomaji) && !hasKanji;\n}\n\nconst isCharInitialLongDash = (char, index) => isCharLongDash(char) && index < 1;\nconst isCharInnerLongDash = (char, index) => isCharLongDash(char) && index > 0;\nconst isKanaAsSymbol = (char) => ['ãƒ¶', 'ãƒµ'].includes(char);\nconst LONG_VOWELS = {\n  a: 'ã‚',\n  i: 'ã„',\n  u: 'ã†',\n  e: 'ãˆ',\n  o: 'ã†',\n};\n\n// inject toRomaji to avoid circular dependency between toRomaji <-> katakanaToHiragana\nfunction katakanaToHiragana(\n  input = '',\n  toRomaji,\n  { isDestinationRomaji, convertLongVowelMark } = {}\n) {\n  let previousKana = '';\n\n  return input\n    .split('')\n    .reduce((hira, char, index) => {\n      // Short circuit to avoid incorrect codeshift for 'ãƒ¼' and 'ãƒ»'\n      if (\n        isCharSlashDot(char)\n        || isCharInitialLongDash(char, index)\n        || isKanaAsSymbol(char)\n      ) {\n        return hira.concat(char);\n      }\n\n      // Transform long vowels: 'ã‚ªãƒ¼' to 'ãŠã†'\n      if (\n        convertLongVowelMark\n        && previousKana\n        && isCharInnerLongDash(char, index)\n      ) {\n        // Transform previousKana back to romaji, and slice off the vowel\n        const romaji = toRomaji(previousKana).slice(-1);\n        // However, ensure 'ã‚ªãƒ¼' => 'ãŠãŠ' => 'oo' if this is a transform on the way to romaji\n        if (\n          isCharKatakana(input[index - 1])\n          && romaji === 'o'\n          && isDestinationRomaji\n        ) {\n          return hira.concat('ãŠ');\n        }\n        return hira.concat(LONG_VOWELS[romaji]);\n        // Transform all other chars\n      }\n\n      if (!isCharLongDash(char) && isCharKatakana(char)) {\n        const code = char.charCodeAt(0) + (HIRAGANA_START - KATAKANA_START);\n        const hiraChar = String.fromCharCode(code);\n        previousKana = hiraChar;\n        return hira.concat(hiraChar);\n      }\n\n      // Pass non katakana chars through\n      previousKana = '';\n      return hira.concat(char);\n    }, [])\n    .join('');\n}\n\nlet kanaToHepburnMap = null;\n\n/* eslint-disable */\n// prettier-ignore\nconst BASIC_ROMAJI = {\n  ã‚:'a',    ã„:'i',   ã†:'u',   ãˆ:'e',    ãŠ:'o',\n  ã‹:'ka',   ã:'ki',  ã:'ku',  ã‘:'ke',   ã“:'ko',\n  ã•:'sa',   ã—:'shi', ã™:'su',  ã›:'se',   ã:'so',\n  ãŸ:'ta',   ã¡:'chi', ã¤:'tsu', ã¦:'te',   ã¨:'to',\n  ãª:'na',   ã«:'ni',  ã¬:'nu',  ã­:'ne',   ã®:'no',\n  ã¯:'ha',   ã²:'hi',  ãµ:'fu',  ã¸:'he',   ã»:'ho',\n  ã¾:'ma',   ã¿:'mi',  ã‚€:'mu',  ã‚:'me',   ã‚‚:'mo',\n  ã‚‰:'ra',   ã‚Š:'ri',  ã‚‹:'ru',  ã‚Œ:'re',   ã‚:'ro',\n  ã‚„:'ya',   ã‚†:'yu',  ã‚ˆ:'yo',\n  ã‚:'wa',   ã‚:'wi',  ã‚‘:'we',  ã‚’:'wo',\n  ã‚“: 'n',\n  ãŒ:'ga',   ãŽ:'gi',  ã:'gu',  ã’:'ge',   ã”:'go',\n  ã–:'za',   ã˜:'ji',  ãš:'zu',  ãœ:'ze',   ãž:'zo',\n  ã :'da',   ã¢:'ji',  ã¥:'zu',  ã§:'de',   ã©:'do',\n  ã°:'ba',   ã³:'bi',  ã¶:'bu',  ã¹:'be',   ã¼:'bo',\n  ã±:'pa',   ã´:'pi',  ã·:'pu',  ãº:'pe',   ã½:'po',\n  ã‚”ã:'va', ã‚”ãƒ:'vi', ã‚”:'vu',  ã‚”ã‡:'ve', ã‚”ã‰:'vo',\n};\n/* eslint-enable  */\n\nconst SPECIAL_SYMBOLS = {\n  'ã€‚': '.',\n  'ã€': ',',\n  'ï¼š': ':',\n  'ãƒ»': '/',\n  'ï¼': '!',\n  'ï¼Ÿ': '?',\n  'ã€œ': '~',\n  'ãƒ¼': '-',\n  'ã€Œ': 'â€˜',\n  'ã€': 'â€™',\n  'ã€Ž': 'â€œ',\n  'ã€': 'â€',\n  'ï¼»': '[',\n  'ï¼½': ']',\n  'ï¼ˆ': '(',\n  'ï¼‰': ')',\n  'ï½›': '{',\n  'ï½': '}',\n  'ã€€': ' ',\n};\n\n// ã‚“ã„ -> n'i\nconst AMBIGUOUS_VOWELS = ['ã‚', 'ã„', 'ã†', 'ãˆ', 'ãŠ', 'ã‚„', 'ã‚†', 'ã‚ˆ'];\nconst SMALL_Y = { ã‚ƒ: 'ya', ã‚…: 'yu', ã‚‡: 'yo' };\nconst SMALL_Y_EXTRA = { ãƒ: 'yi', ã‡: 'ye' };\nconst SMALL_AIUEO = {\n  ã: 'a',\n  ãƒ: 'i',\n  ã…: 'u',\n  ã‡: 'e',\n  ã‰: 'o',\n};\nconst YOON_KANA = [\n  'ã',\n  'ã«',\n  'ã²',\n  'ã¿',\n  'ã‚Š',\n  'ãŽ',\n  'ã³',\n  'ã´',\n  'ã‚”',\n  'ã',\n  'ãµ',\n];\nconst YOON_EXCEPTIONS = {\n  ã—: 'sh',\n  ã¡: 'ch',\n  ã˜: 'j',\n  ã¢: 'j',\n};\nconst SMALL_KANA = {\n  ã£: '',\n  ã‚ƒ: 'ya',\n  ã‚…: 'yu',\n  ã‚‡: 'yo',\n  ã: 'a',\n  ãƒ: 'i',\n  ã…: 'u',\n  ã‡: 'e',\n  ã‰: 'o',\n};\n\n// going with the intuitive (yet incorrect) solution where ã£ã‚„ -> yya and ã£ãƒ -> ii\n// in other words, just assume the sokuon could have been applied to anything\nconst SOKUON_WHITELIST = {\n  b: 'b',\n  c: 't',\n  d: 'd',\n  f: 'f',\n  g: 'g',\n  h: 'h',\n  j: 'j',\n  k: 'k',\n  m: 'm',\n  p: 'p',\n  q: 'q',\n  r: 'r',\n  s: 's',\n  t: 't',\n  v: 'v',\n  w: 'w',\n  x: 'x',\n  z: 'z',\n};\n\nfunction getKanaToHepburnTree() {\n  if (kanaToHepburnMap == null) {\n    kanaToHepburnMap = createKanaToHepburnMap();\n  }\n  return kanaToHepburnMap;\n}\n\nfunction getKanaToRomajiTree(romanization) {\n  switch (romanization) {\n    case ROMANIZATIONS.HEPBURN:\n      return getKanaToHepburnTree();\n    default:\n      return {};\n  }\n}\n\nfunction createKanaToHepburnMap() {\n  const romajiTree = transform(BASIC_ROMAJI);\n\n  const subtreeOf = (string) => getSubTreeOf(romajiTree, string);\n  const setTrans = (string, transliteration) => {\n    subtreeOf(string)[''] = transliteration;\n  };\n\n  Object.entries(SPECIAL_SYMBOLS).forEach(([jsymbol, symbol]) => {\n    subtreeOf(jsymbol)[''] = symbol;\n  });\n\n  [...Object.entries(SMALL_Y), ...Object.entries(SMALL_AIUEO)].forEach(\n    ([roma, kana]) => {\n      setTrans(roma, kana);\n    }\n  );\n\n  // ãã‚ƒ -> kya\n  YOON_KANA.forEach((kana) => {\n    const firstRomajiChar = subtreeOf(kana)[''][0];\n    Object.entries(SMALL_Y).forEach(([yKana, yRoma]) => {\n      setTrans(kana + yKana, firstRomajiChar + yRoma);\n    });\n    // ããƒ -> kyi\n    Object.entries(SMALL_Y_EXTRA).forEach(([yKana, yRoma]) => {\n      setTrans(kana + yKana, firstRomajiChar + yRoma);\n    });\n  });\n\n  Object.entries(YOON_EXCEPTIONS).forEach(([kana, roma]) => {\n    // ã˜ã‚ƒ -> ja\n    Object.entries(SMALL_Y).forEach(([yKana, yRoma]) => {\n      setTrans(kana + yKana, roma + yRoma[1]);\n    });\n    // ã˜ãƒ -> jyi, ã˜ã‡ -> je\n    setTrans(`${kana}ãƒ`, `${roma}yi`);\n    setTrans(`${kana}ã‡`, `${roma}e`);\n  });\n\n  romajiTree['ã£'] = resolveTsu(romajiTree);\n\n  Object.entries(SMALL_KANA).forEach(([kana, roma]) => {\n    setTrans(kana, roma);\n  });\n\n  AMBIGUOUS_VOWELS.forEach((kana) => {\n    setTrans(`ã‚“${kana}`, `n'${subtreeOf(kana)['']}`);\n  });\n\n  // NOTE: could be re-enabled with an option?\n  // // ã‚“ã° -> mbo\n  // const LABIAL = [\n  //   'ã°', 'ã³', 'ã¶', 'ã¹', 'ã¼',\n  //   'ã±', 'ã´', 'ã·', 'ãº', 'ã½',\n  //   'ã¾', 'ã¿', 'ã‚€', 'ã‚', 'ã‚‚',\n  // ];\n  // LABIAL.forEach((kana) => {\n  //   setTrans(`ã‚“${kana}`, `m${subtreeOf(kana)['']}`);\n  // });\n\n  return Object.freeze(JSON.parse(JSON.stringify(romajiTree)));\n}\n\nfunction resolveTsu(tree) {\n  return Object.entries(tree).reduce((tsuTree, [key, value]) => {\n    if (!key) {\n      // we have reached the bottom of this branch\n      const consonant = value.charAt(0);\n      // eslint-disable-next-line no-param-reassign\n      tsuTree[key] = Object.keys(SOKUON_WHITELIST).includes(consonant)\n        ? SOKUON_WHITELIST[consonant] + value\n        : value;\n    } else {\n      // more subtrees\n      // eslint-disable-next-line no-param-reassign\n      tsuTree[key] = resolveTsu(value);\n    }\n    return tsuTree;\n  }, {});\n}\n\n// memoize and deeply compare args so we only recreate when necessary\nconst createKanaToRomajiMap = memoizeOne(\n  (romanization, customRomajiMapping) => {\n    let map = getKanaToRomajiTree(romanization);\n\n    if (customRomajiMapping) {\n      map = mergeCustomMapping(map, customRomajiMapping);\n    }\n\n    return map;\n  },\n  dequal\n);\n\n/**\n * Convert kana to romaji\n * @param  {String} kana text input\n * @param  {DefaultOptions} [options=defaultOptions]\n * @param  {Object} map custom mapping\n * @return {String} converted text\n * @example\n * toRomaji('ã²ã‚‰ãŒãªã€€ã‚«ã‚¿ã‚«ãƒŠ')\n * // => 'hiragana katakana'\n * toRomaji('ã’ãƒ¼ã‚€ã€€ã‚²ãƒ¼ãƒ ')\n * // => 'ge-mu geemu'\n * toRomaji('ã²ã‚‰ãŒãªã€€ã‚«ã‚¿ã‚«ãƒŠ', { upcaseKatakana: true })\n * // => 'hiragana KATAKANA'\n * toRomaji('ã¤ã˜ãŽã‚Š', { customRomajiMapping: { ã˜: 'zi', ã¤: 'tu', ã‚Š: 'li' } });\n * // => 'tuzigili'\n */\nfunction toRomaji(input = '', options = {}, map) {\n  const config = mergeWithDefaultOptions(options);\n\n  if (!map) {\n    map = createKanaToRomajiMap(\n      config.romanization,\n      config.customRomajiMapping\n    );\n  }\n\n  // just throw away the substring index information and simply concatenate all the kana\n  return splitIntoRomaji(input, config, map)\n    .map((romajiToken) => {\n      const [start, end, romaji] = romajiToken;\n      const makeUpperCase = config.upcaseKatakana && isKatakana(input.slice(start, end));\n      return makeUpperCase ? romaji.toUpperCase() : romaji;\n    })\n    .join('');\n}\n\nfunction splitIntoRomaji(input, options, map) {\n  if (!map) {\n    map = createKanaToRomajiMap(\n      options.romanization,\n      options.customRomajiMapping\n    );\n  }\n\n  const config = Object.assign({}, { isDestinationRomaji: true }, options);\n\n  return applyMapping(\n    katakanaToHiragana(input, toRomaji, config),\n    map,\n    !options.IMEMode\n  );\n}\n\n/**\n * Tests a character. Returns true if the character is considered English punctuation.\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharEnglishPunctuation(char = '') {\n  if (isEmpty(char)) return false;\n  return EN_PUNCTUATION_RANGES.some(([start, end]) => isCharInRange(char, start, end));\n}\n\n/**\n * Convert input to [Hiragana](https://en.wikipedia.org/wiki/Hiragana)\n * @param  {String} [input=''] text\n * @param  {DefaultOptions} [options=defaultOptions]\n * @return {String} converted text\n * @example\n * toHiragana('toukyou, ã‚ªã‚ªã‚µã‚«')\n * // => 'ã¨ã†ãã‚‡ã†ã€ã€€ãŠãŠã•ã‹'\n * toHiragana('only ã‚«ãƒŠ', { passRomaji: true })\n * // => 'only ã‹ãª'\n * toHiragana('wi')\n * // => 'ã†ãƒ'\n * toHiragana('wi', { useObsoleteKana: true })\n * // => 'ã‚'\n */\nfunction toHiragana(input = '', options = {}) {\n  const config = mergeWithDefaultOptions(options);\n  if (config.passRomaji) {\n    return katakanaToHiragana(input, toRomaji, config);\n  }\n\n  if (isMixed(input, { passKanji: true })) {\n    const convertedKatakana = katakanaToHiragana(input, toRomaji, config);\n    return toKana(convertedKatakana.toLowerCase(), config);\n  }\n\n  if (isRomaji(input) || isCharEnglishPunctuation(input)) {\n    return toKana(input.toLowerCase(), config);\n  }\n\n  return katakanaToHiragana(input, toRomaji, config);\n}\n\n/**\n * Convert input to [Katakana](https://en.wikipedia.org/wiki/Katakana)\n * @param  {String} [input=''] text\n * @param  {DefaultOptions} [options=defaultOptions]\n * @return {String} converted text\n * @example\n * toKatakana('toukyou, ãŠãŠã•ã‹')\n * // => 'ãƒˆã‚¦ã‚­ãƒ§ã‚¦ã€ã€€ã‚ªã‚ªã‚µã‚«'\n * toKatakana('only ã‹ãª', { passRomaji: true })\n * // => 'only ã‚«ãƒŠ'\n * toKatakana('wi')\n * // => 'ã‚¦ã‚£'\n * toKatakana('wi', { useObsoleteKana: true })\n * // => 'ãƒ°'\n */\nfunction toKatakana(input = '', options = {}) {\n  const mergedOptions = mergeWithDefaultOptions(options);\n  if (mergedOptions.passRomaji) {\n    return hiraganaToKatakana(input);\n  }\n\n  if (isMixed(input) || isRomaji(input) || isCharEnglishPunctuation(input)) {\n    const hiragana = toKana(input.toLowerCase(), mergedOptions);\n    return hiraganaToKatakana(hiragana);\n  }\n\n  return hiraganaToKatakana(input);\n}\n\n/**\n * Tests a character. Returns true if the character is considered Japanese punctuation.\n * @param  {String} char character string to test\n * @return {Boolean}\n */\nfunction isCharJapanesePunctuation(char = '') {\n  if (isEmpty(char) || isCharIterationMark(char)) return false;\n  return JA_PUNCTUATION_RANGES.some(([start, end]) => isCharInRange(char, start, end));\n}\n\nconst isCharEnSpace = (x) => x === ' ';\nconst isCharJaSpace = (x) => x === 'ã€€';\nconst isCharJaNum = (x) => /[ï¼-ï¼™]/.test(x);\nconst isCharEnNum = (x) => /[0-9]/.test(x);\n\nconst TOKEN_TYPES = {\n  EN: 'en',\n  JA: 'ja',\n  EN_NUM: 'englishNumeral',\n  JA_NUM: 'japaneseNumeral',\n  EN_PUNC: 'englishPunctuation',\n  JA_PUNC: 'japanesePunctuation',\n  KANJI: 'kanji',\n  HIRAGANA: 'hiragana',\n  KATAKANA: 'katakana',\n  SPACE: 'space',\n  OTHER: 'other',\n};\n\n// prettier-ignore\nfunction getType(input, compact = false) {\n  const {\n    EN, JA, EN_NUM, JA_NUM, EN_PUNC, JA_PUNC, KANJI, HIRAGANA, KATAKANA, SPACE, OTHER,\n  } = TOKEN_TYPES;\n\n  if (compact) {\n    switch (true) {\n      case isCharJaNum(input): return OTHER;\n      case isCharEnNum(input): return OTHER;\n      case isCharEnSpace(input): return EN;\n      case isCharEnglishPunctuation(input): return OTHER;\n      case isCharJaSpace(input): return JA;\n      case isCharJapanesePunctuation(input): return OTHER;\n      case isCharJapanese(input): return JA;\n      case isCharRomaji(input): return EN;\n      default: return OTHER;\n    }\n  } else {\n    switch (true) {\n      case isCharJaSpace(input): return SPACE;\n      case isCharEnSpace(input): return SPACE;\n      case isCharJaNum(input): return JA_NUM;\n      case isCharEnNum(input): return EN_NUM;\n      case isCharEnglishPunctuation(input): return EN_PUNC;\n      case isCharJapanesePunctuation(input): return JA_PUNC;\n      case isCharKanji(input): return KANJI;\n      case isCharHiragana(input): return HIRAGANA;\n      case isCharKatakana(input): return KATAKANA;\n      case isCharJapanese(input): return JA;\n      case isCharRomaji(input): return EN;\n      default: return OTHER;\n    }\n  }\n}\n\n/**\n * Splits input into array of strings separated by opinionated token types\n * `'en', 'ja', 'englishNumeral', 'japaneseNumeral','englishPunctuation', 'japanesePunctuation','kanji', 'hiragana', 'katakana', 'space', 'other'`.\n * If `{ compact: true }` then many same-language tokens are combined (spaces + text, kanji + kana, numeral + punctuation).\n * If `{ detailed: true }` then return array will contain `{ type, value }` instead of `'value'`\n * @param  {String} input text\n * @param  {Object} [options={ compact: false, detailed: false}] options to modify output style\n * @return {String|Object[]} text split into tokens containing values, or detailed object\n * @example\n * tokenize('ãµãµãƒ•ãƒ•')\n * // ['ãµãµ', 'ãƒ•ãƒ•']\n *\n * tokenize('æ„Ÿã˜')\n * // ['æ„Ÿ', 'ã˜']\n *\n * tokenize('äººã€…')\n * // ['äººã€…']\n *\n * tokenize('truly ç§ã¯æ‚²ã—ã„')\n * // ['truly', ' ', 'ç§', 'ã¯', 'æ‚²', 'ã—ã„']\n *\n * tokenize('truly ç§ã¯æ‚²ã—ã„', { compact: true })\n * // ['truly ', 'ç§ã¯æ‚²ã—ã„']\n *\n * tokenize('5romaji here...!?äººã€…æ¼¢å­—ã²ã‚‰ãŒãªã‚«ã‚¿ã€€ã‚«ãƒŠï¼”ã€Œï¼³ï¼¨ï¼©ï¼¯ã€ã€‚ï¼')\n * // [ '5', 'romaji', ' ', 'here', '...!?', 'äººã€…æ¼¢å­—', 'ã²ã‚‰ãŒãª', 'ã‚«ã‚¿', 'ã€€', 'ã‚«ãƒŠ', 'ï¼”', 'ã€Œ', 'ï¼³ï¼¨ï¼©ï¼¯', 'ã€ã€‚ï¼']\n *\n * tokenize('5romaji here...!?äººã€…æ¼¢å­—ã²ã‚‰ãŒãªã‚«ã‚¿ã€€ã‚«ãƒŠï¼”ã€Œï¼³ï¼¨ï¼©ï¼¯ã€ã€‚ï¼', { compact: true })\n * // [ '5', 'romaji here', '...!?', 'äººã€…æ¼¢å­—ã²ã‚‰ãŒãªã‚«ã‚¿ã€€ã‚«ãƒŠ', 'ï¼”ã€Œ', 'ï¼³ï¼¨ï¼©ï¼¯', 'ã€ã€‚ï¼']\n *\n * tokenize('5romaji here...!?äººã€…æ¼¢å­—ã²ã‚‰ãŒãªã‚«ã‚¿ã€€ã‚«ãƒŠï¼”ã€Œï¼³ï¼¨ï¼©ï¼¯ã€ã€‚ï¼ Ù„Ù†Ø°Ù‡Ø¨', { detailed: true })\n * // [\n *  { type: 'englishNumeral', value: '5' },\n *  { type: 'en', value: 'romaji' },\n *  { type: 'space', value: ' ' },\n *  { type: 'en', value: 'here' },\n *  { type: 'englishPunctuation', value: '...!?' },\n *  { type: 'kanji', value: 'äººã€…æ¼¢å­—' },\n *  { type: 'hiragana', value: 'ã²ã‚‰ãŒãª' },\n *  { type: 'katakana', value: 'ã‚«ã‚¿' },\n *  { type: 'space', value: 'ã€€' },\n *  { type: 'katakana', value: 'ã‚«ãƒŠ' },\n *  { type: 'japaneseNumeral', value: 'ï¼”' },\n *  { type: 'japanesePunctuation', value: 'ã€Œ' },\n *  { type: 'ja', value: 'ï¼³ï¼¨ï¼©ï¼¯' },\n *  { type: 'japanesePunctuation', value: 'ã€ã€‚ï¼' },\n *  { type: 'space', value: ' ' },\n *  { type: 'other', value: 'Ù„Ù†Ø°Ù‡Ø¨' },\n * ]\n *\n * tokenize('5romaji here...!?äººã€…æ¼¢å­—ã²ã‚‰ãŒãªã‚«ã‚¿ã€€ã‚«ãƒŠï¼”ã€Œï¼³ï¼¨ï¼©ï¼¯ã€ã€‚ï¼ Ù„Ù†Ø°Ù‡Ø¨', { compact: true, detailed: true})\n * // [\n *  { type: 'other', value: '5' },\n *  { type: 'en', value: 'romaji here' },\n *  { type: 'other', value: '...!?' },\n *  { type: 'ja', value: 'äººã€…æ¼¢å­—ã²ã‚‰ãŒãªã‚«ã‚¿ã€€ã‚«ãƒŠ' },\n *  { type: 'other', value: 'ï¼”ã€Œ' },\n *  { type: 'ja', value: 'ï¼³ï¼¨ï¼©ï¼¯' },\n *  { type: 'other', value: 'ã€ã€‚ï¼' },\n *  { type: 'en', value: ' ' },\n *  { type: 'other', value: 'Ù„Ù†Ø°Ù‡Ø¨' },\n *]\n */\nfunction tokenize(input, { compact = false, detailed = false } = {}) {\n  if (input == null || isEmpty(input)) {\n    return [];\n  }\n  const chars = [...input];\n  let initial = chars.shift();\n  let prevType = getType(initial, compact);\n  initial = detailed ? { type: prevType, value: initial } : initial;\n\n  const result = chars.reduce(\n    (tokens, char) => {\n      const currType = getType(char, compact);\n      const sameType = currType === prevType;\n      prevType = currType;\n      let newValue = char;\n\n      if (sameType) {\n        newValue = (detailed ? tokens.pop().value : tokens.pop()) + newValue;\n      }\n\n      return detailed\n        ? tokens.concat({ type: currType, value: newValue })\n        : tokens.concat(newValue);\n    },\n    [initial]\n  );\n  return result;\n}\n\nconst isLeadingWithoutInitialKana = (input, leading) => leading && !isKana(input[0]);\nconst isTrailingWithoutFinalKana = (input, leading) => !leading && !isKana(input[input.length - 1]);\nconst isInvalidMatcher = (input, matchKanji) =>\n  (matchKanji && ![...matchKanji].some(isKanji)) || (!matchKanji && isKana(input));\n\n/**\n * Strips [Okurigana](https://en.wikipedia.org/wiki/Okurigana)\n * @param  {String} input text\n * @param  {Object} [options={ leading: false, matchKanji: '' }] optional config\n * @return {String} text with okurigana removed\n * @example\n * stripOkurigana('è¸ã¿è¾¼ã‚€')\n * // => 'è¸ã¿è¾¼'\n * stripOkurigana('ãŠç¥ã„')\n * // => 'ãŠç¥'\n * stripOkurigana('ãŠè…¹', { leading: true });\n * // => 'è…¹'\n * stripOkurigana('ãµã¿ã“ã‚€', { matchKanji: 'è¸ã¿è¾¼ã‚€' });\n * // => 'ãµã¿ã“'\n * stripOkurigana('ãŠã¿ã¾ã„', { matchKanji: 'ãŠç¥ã„', leading: true });\n * // => 'ã¿ã¾ã„'\n */\nfunction stripOkurigana(input = '', { leading = false, matchKanji = '' } = {}) {\n  if (\n    !isJapanese(input) ||\n    isLeadingWithoutInitialKana(input, leading) ||\n    isTrailingWithoutFinalKana(input, leading) ||\n    isInvalidMatcher(input, matchKanji)\n  ) {\n    return input;\n  }\n\n  const chars = matchKanji || input;\n  const okuriganaRegex = new RegExp(\n    leading ? `^${tokenize(chars).shift()}` : `${tokenize(chars).pop()}$`\n  );\n  return input.replace(okuriganaRegex, '');\n}\n\nexport { ROMANIZATIONS, TO_KANA_METHODS, VERSION, bind, isHiragana, isJapanese, isKana, isKanji, isKatakana, isMixed, isRomaji, stripOkurigana, toHiragana, toKana, toKatakana, toRomaji, tokenize, unbind };\n//# sourceMappingURL=index.js.map\n","var arrayZip = zip;\n\n/*\n  zip([1, 2, 3]); // [[1], [2], [3]]\n  zip([1, 2, 3], ['a', 'b', 'c']); // [[1, 'a'], [2, 'b'], [3, 'c']]\n  zip([1, 2], ['a', 'b'], [true, false]); //[[1, 'a', true], [2, 'b', false]]\n\n  zip([1, 2, 3], ['a', 'b'], [true]);\n  // [[1, 'a', true], [2, 'b', undefined], [3, undefined, undefined]]\n\n  zip(undefined, {}, false, 1, 'foo'); // throws\n  zip([1, 2], ['a', 'b'], undefined, {}, false, 1, 'foo'); // throws\n*/\n\nfunction zip() {\n  var result = [];\n  var args = Array.prototype.slice.call(arguments);\n  var argsLen = args.length;\n  var maxLen = 0;\n  var i, j;\n\n  if (!argsLen) {\n    throw new Error('zip requires at least one argument');\n  }\n\n  for (i = 0; i < argsLen; i++) {\n    if (!Array.isArray(args[i])) {\n      throw new Error('all arguments must be arrays');\n    }\n    var arrLen = args[i].length;\n    if (arrLen > maxLen) {\n      maxLen = arrLen;\n    }\n  }\n\n  for (i = 0; i < maxLen; i++) {\n    var group = [];\n    for (j = 0; j < argsLen; j++) {\n      if (!Array.isArray(args[j])) {\n        throw new Error('all arguments must be arrays');\n      }\n      group[j] = args[j][i];\n    }\n    result[i] = group;\n  }\n\n  return result;\n}\n\nexport {arrayZip as default};\n","import { stripOkurigana, tokenize, isKanji, isKana, isHiragana, isKatakana } from 'wanakana';\nimport zip from 'just-zip-it';\n\n/**\n * Combines furigana with kanji into an array of string pairs.\n * @param  {String} word vocab kanji word\n * @param  {String} reading vocab kana reading\n * @param  {String|Object} furi furigana placement info\n * @return {Array} furigana/kanji pairs\n * @example\n * combineFuri('ãŠä¸–è¾ž', 'ãŠã›ã˜', '1:ã›;2:ã˜')\n * // => [['', 'ãŠ'], ['ã›', 'ä¸–'], ['ã˜', 'è¾ž']]\n * combineFuri('å¤§äººã—ã„', 'ãŠã¨ãªã—ã„') // smart fallbacks\n * // => [['ãŠã¨ãª', 'å¤§äºº'], ['', 'ã—ã„']]\n * combineFuri('ä½¿ã„æ–¹', 'ã¤ã‹ã„ã‹ãŸ') // smart fallbacks\n * // => [['ã¤ã‹', 'ä½¿'], ['', 'ã„'], ['ã‹ãŸ', 'æ–¹']]\n *\n * // special compound readings (ç¾©è¨“/ç†Ÿå­—è¨“) are spread across relevant kanji\n * combineFuri('èƒ¡åº§', 'ã‚ãã‚‰', '0:ã‚ãã‚‰')\n * // => [['ã‚ãã‚‰', 'èƒ¡åº§']]\n */\nexport function combineFuri(word = '', reading = '', furi = '') {\n  const furiLocs = parseFuri(furi);\n  // ç¾©è¨“/ç†Ÿå­—è¨“ words with a single furi loc: ä»Šæ—¥ \"0:ãã‚‡ã†\"\n  const isSpecialReading = furiLocs.length === 1 && [...word].every(isKanji);\n  const isKanaWord = [...word].every(isKana);\n  const isWanikaniMadness = [...reading].some(isHiragana) && [...reading].some(isKatakana);\n\n  if (word === reading || isKanaWord) {\n    return [['', word]];\n  }\n\n  if (!furi || isSpecialReading || isWanikaniMadness) {\n    return basicFuri(word, reading);\n  }\n\n  return generatePairs(word, furiLocs);\n}\n\n/**\n * Displays simple furigana by removing redundant kana\n * @param  {String} [word=''] 'ãŠè¦‹èˆžã„'\n * @param  {String} [reading=''] 'ãŠã¿ã¾ã„'\n * @return {Array} [['', 'ãŠ'], ['è¦‹èˆž', 'ã¿ã¾'], ['', 'ã„']]\n */\nexport function basicFuri(word = '', reading = '') {\n  // early return + guard against words like ï¼‘æ—¥ which are tokenized unfavourably\n  if ([...word].every((c) => !isKana(c))) {\n    return [[reading, word]];\n  }\n\n  const [bikago, okurigana] = [\n    reading.slice(0, word.length - stripOkurigana(word, { leading: true }).length),\n    reading.slice(stripOkurigana(reading, { matchKanji: word }).length),\n  ];\n\n  const innerWordTokens = tokenize(removeExtraneousKana(word, bikago, okurigana));\n  let innerReadingChars = removeExtraneousKana(reading, bikago, okurigana);\n\n  const kanjiOddKanaEvenRegex = RegExp(\n    innerWordTokens.map((char) => (isKanji(char) ? '(.*)' : `(${char})`)).join(''),\n  );\n\n  [, ...innerReadingChars] = innerReadingChars.match(kanjiOddKanaEvenRegex) || [];\n\n  const ret = zip(innerReadingChars, innerWordTokens).map(skipRedundantReadings);\n\n  if (bikago) {\n    ret.unshift(['', bikago]);\n  }\n\n  if (okurigana) {\n    ret.push(['', okurigana]);\n  }\n\n  return ret;\n}\n\nfunction removeExtraneousKana(str = '', leading = '', trailing = '') {\n  return str.replace(RegExp(`^${leading}`), '').replace(RegExp(`${trailing}$`), '');\n}\n\nfunction skipRedundantReadings([reading, word = '']) {\n  return !reading || reading === word ? ['', word] : [reading, word];\n}\n\nexport function parseFuri(data) {\n  return typeof data === 'string' ? parseFuriString(data) : parseFuriObject(data);\n}\n\n/**\n * Parses furigana placement object\n * @param  {Object} [locations={}] { 1:'ã›', 2:'ã˜' }\n * @return {Array} [ [[1, 2], 'ã›'], [[2, 3], 'ã˜'] ]\n */\nfunction parseFuriObject(locations = {}) {\n  return Object.entries(locations).map(([start, content]) => [\n    [Number(start), Number(start) + 1],\n    content,\n  ]);\n}\n\n/**\n * Parses furigana placement string\n * @param  {String} [locations=''] '1:ã›;2:ã˜'\n * @return {Array} [ [[1, 2], 'ã›'], [[2, 3], 'ã˜'] ]\n */\nfunction parseFuriString(locations = '') {\n  return locations.split(';').map((entry) => {\n    const [indexes, content] = entry.split(':');\n    const [start, end] = indexes.split('-').map(Number);\n    // NOTE: in the JMDict furistring data, the end index is either missing\n    // or it is listed as the *start* index of the final char Â¯\\_(ãƒ„)_/Â¯\n    // so we need to bump it either way to encompass that char\n    return [[start, end ? end + 1 : start + 1], content];\n  });\n}\n\n/**\n * Generates array pairs via furigana location data\n * @param  {String} word 'ãŠä¸–è¾ž'\n * @param  {Array} furiLocs [[[1, 2], 'ã›'], [[2, 3], 'ã˜']]\n * @return {Array} [['', 'ãŠ'], ['ã›', 'ä¸–'], ['ã˜', 'è¾ž']]\n */\nexport function generatePairs(word = '', furiLocs = []) {\n  let prevCharEnd = 0;\n\n  return furiLocs.reduce((pairs, [[start, end], furiText], index, source) => {\n    // if no furigana at this index, add intervening chars\n    if (start !== prevCharEnd) {\n      pairs.push(['', word.slice(prevCharEnd, start)]);\n    }\n\n    // add furigana and associated chars\n    pairs.push([furiText, word.slice(start, end)]);\n\n    // if no more furigana left, add any remaining chars/okurigana with blank furi\n    if (end < word.length && !source[index + 1]) {\n      pairs.push(['', word.slice(end)]);\n    }\n\n    prevCharEnd = end;\n    return pairs;\n  }, []);\n}\n","import React from 'react';\nimport { combineFuri } from './utils';\n\nexport function useFuriPairs(word, reading, furi) {\n  return React.useMemo(() => combineFuri(word, reading, furi), [word, reading, furi]);\n}\n","import React from 'react';\n\nimport { useFuriPairs } from './hooks';\n\nconst wrapperStyle = {\n  display: 'inline-flex',\n  flexFlow: 'row wrap',\n  fontFamily: `'ãƒ’ãƒ©ã‚®ãƒŽè§’ã‚´ ProN', 'Hiragino Kaku Gothic ProN', 'TakaoPã‚´ã‚·ãƒƒã‚¯', TakaoPGothic, 'æ¸¸ã‚´ã‚·ãƒƒã‚¯', 'æ¸¸ã‚´ã‚·ãƒƒã‚¯ä½“', YuGothic, 'Yu Gothic', 'ãƒ¡ã‚¤ãƒªã‚ª', Meiryo, 'ï¼­ï¼³ ã‚´ã‚·ãƒƒã‚¯', 'MS Gothic', HiraKakuProN-W3, 'MotoyaLCedar', 'Droid Sans Japanese', sans-serif`,\n};\n\nconst pairStyle = {\n  display: 'inline-flex',\n  fontSize: '24px',\n  lineHeight: '1',\n  flexFlow: 'column nowrap',\n  justifyContent: 'flex-end',\n  alignItems: 'center',\n  alignSelf: 'flex-end',\n};\n\nconst furiStyle = {\n  display: 'block',\n  fontSize: '0.5em',\n  letterSpacing: '-0.02em',\n  margin: '0 0.1em',\n  paddingTop: '0.2em',\n  paddingBottom: '0.1em',\n  // don't interfere with selection of the content text\n  userSelect: 'none',\n  opacity: '0.9',\n};\n\nconst textStyle = {\n  display: 'block',\n};\n\nexport function Wrapper({ style, ...props }) {\n  return <span lang=\"ja\" style={{ ...wrapperStyle, ...style }} {...props} />;\n}\n\nexport function Pair({ style, ...props }) {\n  return <span lang=\"ja\" style={{ ...pairStyle, ...style }} {...props} />;\n}\n\nexport function Furi({ style, ...props }) {\n  return <span lang=\"ja\" style={{ ...furiStyle, ...style }} {...props} />;\n}\n\nexport function Text({ style, ...props }) {\n  return <span lang=\"ja\" style={{ ...textStyle, ...style }} {...props} />;\n}\n\nexport function ReactFuri({ word, reading, furi, showFuri, render, ...props }) {\n  const pairs = useFuriPairs(word, reading, furi);\n\n  return typeof render === 'function' ? (\n    render({ pairs })\n  ) : (\n    <Wrapper {...props}>\n      {pairs.map(([furiText, text], index) => {\n        const uniquePairKey = text + index;\n\n        return (\n          <Pair key={uniquePairKey}>\n            {showFuri && <Furi>{furiText}</Furi>}\n            <Text>{text}</Text>\n          </Pair>\n        );\n      })}\n    </Wrapper>\n  );\n}\n\nReactFuri.defaultProps = {\n  word: '',\n  reading: '',\n  furi: '',\n  showFuri: true,\n};\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,MAAMA,CAACC,KAAK,EAAE;EACrB,IAAIA,KAAK,KAAK,IAAI,EAAE;IAClB,OAAO,MAAM;EACjB;EACE,IAAIA,KAAK,KAAKC,MAAM,CAACD,KAAK,CAAC,EAAE;IAC3B,OAAO,OAAOA,KAAK;EACvB;EACE,OAAO,EAAE,CAACE,QAAQ,CACfC,IAAI,CAACH,KAAK,CAAC,CACXI,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CACZC,WAAW,EAAE;AAClB;;AAEA;AACA;AACA;AACA;AACA;AACA,SAASC,OAAOA,CAACC,KAAK,EAAE;EACtB,IAAIR,MAAM,CAACQ,KAAK,CAAC,KAAK,QAAQ,EAAE;IAC9B,OAAO,IAAI;EACf;EACE,OAAO,CAACA,KAAK,CAACC,MAAM;AACtB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASC,aAAaA,CAAA,EAAwB;EAAA,IAAvBC,IAAI,GAAAC,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAAA,IAAEE,KAAK,GAAAF,SAAA,CAAAH,MAAA,OAAAG,SAAA,MAAAC,SAAA;EAAA,IAAEE,GAAG,GAAAH,SAAA,CAAAH,MAAA,OAAAG,SAAA,MAAAC,SAAA;EAC1C,IAAIN,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,MAAMK,IAAI,GAAGL,IAAI,CAACM,UAAU,CAAC,CAAC,CAAC;EAC/B,OAAOH,KAAK,IAAIE,IAAI,IAAIA,IAAI,IAAID,GAAG;AACrC;AAsDA,MAAMG,uBAAuB,GAAG,MAAM;AACtC,MAAMC,qBAAqB,GAAG,MAAM;AACpC,MAAMC,uBAAuB,GAAG,MAAM;AACtC,MAAMC,qBAAqB,GAAG,MAAM;AACpC,MAAMC,cAAc,GAAG,MAAM;AAC7B,MAAMC,YAAY,GAAG,MAAM;AAC3B,MAAMC,cAAc,GAAG,MAAM;AAC7B,MAAMC,YAAY,GAAG,MAAM;AAC3B,MAAMC,WAAW,GAAG,MAAM;AAC1B,MAAMC,SAAS,GAAG,MAAM;AAExB,MAAMC,oBAAoB,GAAG,MAAM,CAAC;AACpC,MAAMC,oBAAoB,GAAG,MAAM,CAAC;;AAGpC,MAAMC,eAAe,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACxC,MAAMC,iBAAiB,GAAG,CAACX,uBAAuB,EAAEC,qBAAqB,CAAC;AAC1E,MAAMW,iBAAiB,GAAG,CAACd,uBAAuB,EAAEC,qBAAqB,CAAC;AAC1E,MAAMc,qBAAqB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAC9C,MAAMC,qBAAqB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAC9C,MAAMC,qBAAqB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAC9C,MAAMC,qBAAqB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAC9C,MAAMC,wBAAwB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAEjD,MAAMC,cAAc,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACvC,MAAMC,cAAc,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACvC,MAAMC,gBAAgB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACzC,MAAMC,oBAAoB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAC7C,MAAMC,gBAAgB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACzC,MAAMC,uBAAuB,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAChD,MAAMC,UAAU,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACnC,MAAMC,QAAQ,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AAEjC,MAAMC,WAAW,GAAG,CAClBR,cAAc,EACdC,cAAc,EACdG,gBAAgB,EAChBF,gBAAgB,CACjB;AAED,MAAMO,qBAAqB,GAAG,CAC5BJ,uBAAuB,EACvBD,gBAAgB,EAChBD,oBAAoB,EACpBR,qBAAqB,EACrBC,qBAAqB,EACrBC,qBAAqB,EACrBC,qBAAqB,EACrBC,wBAAwB,CACzB;;AAED;AACA;AACA,MAAMW,eAAe,GAAG,CACtB,GAAGF,WAAW,EACd,GAAGC,qBAAqB,EACxBhB,iBAAiB,EACjBC,iBAAiB,EACjBF,eAAe,EACfc,UAAU,EACVC,QAAQ,CACT;AAED,MAAMI,cAAc,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC;AACvC,MAAMC,qBAAqB,GAAG,CAC5B,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA;AAChB,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA;AAChB,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA;AAChB,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA;AAChB,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA,CACjB;;AACD,MAAMC,kBAAkB,GAAG,CACzB,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA;AAChB,CAAC,MAAM,EAAE,MAAM,CAAC;AAAA,CACjB;;AAED,MAAMC,aAAa,GAAG,CAACH,cAAc,EAAE,GAAGC,qBAAqB,CAAC;AAEhE,MAAMG,qBAAqB,GAAG,CAC5B,CAAC,IAAI,EAAE,IAAI,CAAC,EACZ,CAAC,IAAI,EAAE,IAAI,CAAC,EACZ,CAAC,IAAI,EAAE,IAAI,CAAC,EACZ,CAAC,IAAI,EAAE,IAAI,CAAC,EACZ,GAAGF,kBAAkB,CACtB;;AAED;AACA;AACA;AACA;AACA;AACA,SAASG,cAAcA,CAAA,EAAY;EAAA,IAAX3C,IAAI,GAAAC,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAC/B,OAAOoC,eAAe,CAACO,IAAI,CAACC,MAAA;IAAA,IAAC,CAAC1C,KAAK,EAAEC,GAAG,CAAC,GAAAyC,MAAA;IAAA,OAAK9C,aAAa,CAACC,IAAI,EAAEG,KAAK,EAAEC,GAAG,CAAC;EAAA,EAAC;AAChF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS0C,UAAUA,CAAA,EAAsB;EAAA,IAArBjD,KAAK,GAAAI,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAAA,IAAE8C,OAAO,GAAA9C,SAAA,CAAAH,MAAA,OAAAG,SAAA,MAAAC,SAAA;EACrC,MAAM8C,SAAS,GAAG3D,MAAM,CAAC0D,OAAO,CAAC,KAAK,QAAQ;EAC9C,OAAOnD,OAAO,CAACC,KAAK,CAAC,GACjB,KAAK,GACL,CAAC,GAAGA,KAAK,CAAC,CAACoD,KAAK,CAAEjD,IAAI,IAAK;IAC3B,MAAMkD,IAAI,GAAGP,cAAc,CAAC3C,IAAI,CAAC;IACjC,OAAO,CAACgD,SAAS,GAAGE,IAAI,GAAGA,IAAI,IAAIH,OAAO,CAACI,IAAI,CAACnD,IAAI,CAAC;EAC3D,CAAK,CAAC;AACN;;AA6NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASoD,mBAAmBA,CAAA,EAAiB;EAAA,IAAhBC,SAAS,GAAApD,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EACzC,MAAMqD,UAAU,GAAG,EAAE;EAErB,IAAIjE,MAAM,CAACgE,SAAS,CAAC,KAAK,QAAQ,EAAE;IAClC9D,MAAM,CAACgE,OAAO,CAACF,SAAS,CAAC,CAACG,OAAO,CAACC,MAAA,IAAkB;MAAA,IAAjB,CAACC,IAAI,EAAEC,IAAI,CAAC,GAAAF,MAAA;MAC7C,IAAIG,OAAO,GAAGN,UAAU;MACxBI,IAAI,CAACG,KAAK,CAAC,EAAE,CAAC,CAACL,OAAO,CAAExD,IAAI,IAAK;QAC/B,IAAI4D,OAAO,CAAC5D,IAAI,CAAC,KAAKE,SAAS,EAAE;UAC/B0D,OAAO,CAAC5D,IAAI,CAAC,GAAG,EAAE;QAC5B;QACQ4D,OAAO,GAAGA,OAAO,CAAC5D,IAAI,CAAC;MAC/B,CAAO,CAAC;MACF4D,OAAO,CAAC,EAAE,CAAC,GAAGD,IAAI;IACxB,CAAK,CAAC;EACN;EAEE,OAAO,SAASG,OAAOA,CAACC,GAAG,EAAE;IAC3B,MAAMC,OAAO,GAAGC,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,SAAS,CAACJ,GAAG,CAAC,CAAC;IAE/C,SAASK,YAAYA,CAACC,UAAU,EAAEC,aAAa,EAAE;MAC/C,IAAID,UAAU,KAAKnE,SAAS,IAAIb,MAAM,CAACgF,UAAU,CAAC,KAAK,QAAQ,EAAE;QAC/D,OAAOC,aAAa;MAC5B;MACM,OAAO/E,MAAM,CAACgE,OAAO,CAACe,aAAa,CAAC,CAACC,MAAM,CACzC,CAACC,UAAU,EAAAC,MAAA,KAAsB;QAAA,IAApB,CAACzE,IAAI,EAAE0E,OAAO,CAAC,GAAAD,MAAA;QACpC;QACUD,UAAU,CAACxE,IAAI,CAAC,GAAGoE,YAAY,CAACC,UAAU,CAACrE,IAAI,CAAC,EAAE0E,OAAO,CAAC;QAC1D,OAAOF,UAAU;MAC3B,CAAS,EACDH,UACR,CAAO;IACP;IAEI,OAAOD,YAAY,CAACJ,OAAO,EAAEV,UAAU,CAAC;EAC5C,CAAG;AACH;AAwEA,MAAMqB,SAAS,GAAG;EAAEC,EAAE,EAAE,GAAG;EAAEC,EAAE,EAAE,GAAG;EAAEC,EAAE,EAAE,GAAG;EAAEC,EAAE,EAAE,GAAG;EAAEC,EAAE,EAAE;AAAG,CAAE;AACjE,MAAMC,YAAY,GAAG;EAAEC,CAAC,EAAE,GAAG;EAAEC,CAAC,EAAE,GAAG;EAAEC,CAAC,EAAE,GAAG;EAAEC,CAAC,EAAE,GAAG;EAAEC,CAAC,EAAE;AAAG,CAAE;;AAoB/D;AACsB/F,MAAM,CAACgG,MAAM,CACjC;EACEC,EAAE,EAAE,GAAG;EACPC,EAAE,EAAE,GAAG;EACPC,EAAE,EAAE,GAAG;EACPC,EAAE,EAAE;AACR,CAAG,EACDV,YAAY,EACZN,SACF;AAiJ8BvB,mBAAmB,CAAC;EAChDwC,EAAE,EAAE,GAAG;EACPC,EAAE,EAAE;AACN,CAAC;;AAoBD;AACA;AACA;AACA;AACA;AACA,SAASC,cAAcA,CAAA,EAAY;EAAA,IAAX9F,IAAI,GAAAC,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAC/B,IAAIL,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,OAAOA,IAAI,CAACM,UAAU,CAAC,CAAC,CAAC,KAAKY,oBAAoB;AACpD;;AAYA;AACA;AACA;AACA;AACA;AACA,SAAS6E,cAAcA,CAAA,EAAY;EAAA,IAAX/F,IAAI,GAAAC,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAC/B,IAAIL,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,IAAI8F,cAAc,CAAC9F,IAAI,CAAC,EAAE,OAAO,IAAI;EACrC,OAAOD,aAAa,CAACC,IAAI,EAAEW,cAAc,EAAEC,YAAY,CAAC;AAC1D;;AAoZA;AACA;AACA;AACA;AACA;AACA,SAASoF,YAAYA,CAAA,EAAY;EAAA,IAAXhG,IAAI,GAAAC,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAC7B,IAAIL,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,OAAOyC,aAAa,CAACG,IAAI,CAACqD,MAAA;IAAA,IAAC,CAAC9F,KAAK,EAAEC,GAAG,CAAC,GAAA6F,MAAA;IAAA,OAAKlG,aAAa,CAACC,IAAI,EAAEG,KAAK,EAAEC,GAAG,CAAC;EAAA,EAAC;AAC9E;;AA+BA;AACA;AACA;AACA;AACA;AACA,SAAS8F,cAAcA,CAAA,EAAY;EAAA,IAAXlG,IAAI,GAAAC,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAC/B,OAAOF,aAAa,CAACC,IAAI,EAAEa,cAAc,EAAEC,YAAY,CAAC;AAC1D;;AAEA;AACA;AACA;AACA;AACA;AACA,SAASqF,UAAUA,CAAA,EAAY;EAAA,IAAXnG,IAAI,GAAAC,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAC3B,IAAIL,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,OAAO+F,cAAc,CAAC/F,IAAI,CAAC,IAAIkG,cAAc,CAAClG,IAAI,CAAC;AACrD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASoG,MAAMA,CAAA,EAAa;EAAA,IAAZvG,KAAK,GAAAI,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EACxB,IAAIL,OAAO,CAACC,KAAK,CAAC,EAAE,OAAO,KAAK;EAChC,OAAO,CAAC,GAAGA,KAAK,CAAC,CAACoD,KAAK,CAACkD,UAAU,CAAC;AACrC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASE,UAAUA,CAAA,EAAa;EAAA,IAAZxG,KAAK,GAAAI,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAC5B,IAAIL,OAAO,CAACC,KAAK,CAAC,EAAE,OAAO,KAAK;EAChC,OAAO,CAAC,GAAGA,KAAK,CAAC,CAACoD,KAAK,CAAC8C,cAAc,CAAC;AACzC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASO,UAAUA,CAAA,EAAa;EAAA,IAAZzG,KAAK,GAAAI,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAC5B,IAAIL,OAAO,CAACC,KAAK,CAAC,EAAE,OAAO,KAAK;EAChC,OAAO,CAAC,GAAGA,KAAK,CAAC,CAACoD,KAAK,CAACiD,cAAc,CAAC;AACzC;;AAEA;AACA;AACA;AACA;AACA;AACA,SAASK,mBAAmBA,CAAA,EAAY;EAAA,IAAXvG,IAAI,GAAAC,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EACpC,IAAIL,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,OAAOA,IAAI,CAACM,UAAU,CAAC,CAAC,CAAC,KAAKW,oBAAoB;AACpD;;AAEA;AACA;AACA;AACA;AACA;AACA,SAASuF,WAAWA,CAAA,EAAY;EAAA,IAAXxG,IAAI,GAAAC,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAC5B,OAAOF,aAAa,CAACC,IAAI,EAAEe,WAAW,EAAEC,SAAS,CAAC,IAAIuF,mBAAmB,CAACvG,IAAI,CAAC;AACjF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASyG,OAAOA,CAAA,EAAa;EAAA,IAAZ5G,KAAK,GAAAI,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EACzB,IAAIL,OAAO,CAACC,KAAK,CAAC,EAAE,OAAO,KAAK;EAChC,OAAO,CAAC,GAAGA,KAAK,CAAC,CAACoD,KAAK,CAACuD,WAAW,CAAC;AACtC;;AAkXA;AACA;AACA;AACA;AACA;AACA,SAASE,wBAAwBA,CAAA,EAAY;EAAA,IAAX1G,IAAI,GAAAC,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EACzC,IAAIL,OAAO,CAACI,IAAI,CAAC,EAAE,OAAO,KAAK;EAC/B,OAAO0C,qBAAqB,CAACE,IAAI,CAAC+D,MAAA;IAAA,IAAC,CAACxG,KAAK,EAAEC,GAAG,CAAC,GAAAuG,MAAA;IAAA,OAAK5G,aAAa,CAACC,IAAI,EAAEG,KAAK,EAAEC,GAAG,CAAC;EAAA,EAAC;AACtF;;AAgEA;AACA;AACA;AACA;AACA;AACA,SAASwG,yBAAyBA,CAAA,EAAY;EAAA,IAAX5G,IAAI,GAAAC,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAC1C,IAAIL,OAAO,CAACI,IAAI,CAAC,IAAIuG,mBAAmB,CAACvG,IAAI,CAAC,EAAE,OAAO,KAAK;EAC5D,OAAOoC,qBAAqB,CAACQ,IAAI,CAACiE,MAAA;IAAA,IAAC,CAAC1G,KAAK,EAAEC,GAAG,CAAC,GAAAyG,MAAA;IAAA,OAAK9G,aAAa,CAACC,IAAI,EAAEG,KAAK,EAAEC,GAAG,CAAC;EAAA,EAAC;AACtF;AAEA,MAAM0G,aAAa,GAAIC,CAAC,IAAKA,CAAC,KAAK,GAAG;AACtC,MAAMC,aAAa,GAAID,CAAC,IAAKA,CAAC,KAAK,GAAG;AACtC,MAAME,WAAW,GAAIF,CAAC,IAAK,OAAO,CAAC5D,IAAI,CAAC4D,CAAC,CAAC;AAC1C,MAAMG,WAAW,GAAIH,CAAC,IAAK,OAAO,CAAC5D,IAAI,CAAC4D,CAAC,CAAC;AAE1C,MAAMI,WAAW,GAAG;EAClBC,EAAE,EAAE,IAAI;EACRC,EAAE,EAAE,IAAI;EACRC,MAAM,EAAE,gBAAgB;EACxBC,MAAM,EAAE,iBAAiB;EACzBC,OAAO,EAAE,oBAAoB;EAC7BC,OAAO,EAAE,qBAAqB;EAC9BC,KAAK,EAAE,OAAO;EACdC,QAAQ,EAAE,UAAU;EACpBC,QAAQ,EAAE,UAAU;EACpBC,KAAK,EAAE,OAAO;EACdC,KAAK,EAAE;AACT,CAAC;;AAED;AACA,SAASC,OAAOA,CAAClI,KAAK,EAAmB;EAAA,IAAjBmI,OAAO,GAAA/H,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,KAAK;EACrC,MAAM;IACJmH,EAAE;IAAEC,EAAE;IAAEC,MAAM;IAAEC,MAAM;IAAEC,OAAO;IAAEC,OAAO;IAAEC,KAAK;IAAEC,QAAQ;IAAEC,QAAQ;IAAEC,KAAK;IAAEC;EAChF,CAAG,GAAGX,WAAW;EAEf,IAAIa,OAAO,EAAE;IACX,QAAQ,IAAI;MACV,KAAKf,WAAW,CAACpH,KAAK,CAAC;QAAE,OAAOiI,KAAK;MACrC,KAAKZ,WAAW,CAACrH,KAAK,CAAC;QAAE,OAAOiI,KAAK;MACrC,KAAKhB,aAAa,CAACjH,KAAK,CAAC;QAAE,OAAOuH,EAAE;MACpC,KAAKV,wBAAwB,CAAC7G,KAAK,CAAC;QAAE,OAAOiI,KAAK;MAClD,KAAKd,aAAa,CAACnH,KAAK,CAAC;QAAE,OAAOwH,EAAE;MACpC,KAAKT,yBAAyB,CAAC/G,KAAK,CAAC;QAAE,OAAOiI,KAAK;MACnD,KAAKnF,cAAc,CAAC9C,KAAK,CAAC;QAAE,OAAOwH,EAAE;MACrC,KAAKrB,YAAY,CAACnG,KAAK,CAAC;QAAE,OAAOuH,EAAE;MACnC;QAAS,OAAOU,KAAK;IAC3B;EACA,CAAG,MAAM;IACL,QAAQ,IAAI;MACV,KAAKd,aAAa,CAACnH,KAAK,CAAC;QAAE,OAAOgI,KAAK;MACvC,KAAKf,aAAa,CAACjH,KAAK,CAAC;QAAE,OAAOgI,KAAK;MACvC,KAAKZ,WAAW,CAACpH,KAAK,CAAC;QAAE,OAAO0H,MAAM;MACtC,KAAKL,WAAW,CAACrH,KAAK,CAAC;QAAE,OAAOyH,MAAM;MACtC,KAAKZ,wBAAwB,CAAC7G,KAAK,CAAC;QAAE,OAAO2H,OAAO;MACpD,KAAKZ,yBAAyB,CAAC/G,KAAK,CAAC;QAAE,OAAO4H,OAAO;MACrD,KAAKjB,WAAW,CAAC3G,KAAK,CAAC;QAAE,OAAO6H,KAAK;MACrC,KAAK3B,cAAc,CAAClG,KAAK,CAAC;QAAE,OAAO8H,QAAQ;MAC3C,KAAKzB,cAAc,CAACrG,KAAK,CAAC;QAAE,OAAO+H,QAAQ;MAC3C,KAAKjF,cAAc,CAAC9C,KAAK,CAAC;QAAE,OAAOwH,EAAE;MACrC,KAAKrB,YAAY,CAACnG,KAAK,CAAC;QAAE,OAAOuH,EAAE;MACnC;QAAS,OAAOU,KAAK;IAC3B;EACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASG,QAAQA,CAACpI,KAAK,EAA8C;EAAA,IAA5C;IAAEmI,OAAO,GAAG,KAAK;IAAEE,QAAQ,GAAG;EAAK,CAAE,GAAAjI,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EACjE,IAAIJ,KAAK,IAAI,IAAI,IAAID,OAAO,CAACC,KAAK,CAAC,EAAE;IACnC,OAAO,EAAE;EACb;EACE,MAAMsI,KAAK,GAAG,CAAC,GAAGtI,KAAK,CAAC;EACxB,IAAIuI,OAAO,GAAGD,KAAK,CAACE,KAAK,EAAE;EAC3B,IAAIC,QAAQ,GAAGP,OAAO,CAACK,OAAO,EAAEJ,OAAO,CAAC;EACxCI,OAAO,GAAGF,QAAQ,GAAG;IAAEK,IAAI,EAAED,QAAQ;IAAEhJ,KAAK,EAAE8I;EAAO,CAAE,GAAGA,OAAO;EAEjE,MAAMI,MAAM,GAAGL,KAAK,CAAC5D,MAAM,CACzB,CAACkE,MAAM,EAAEzI,IAAI,KAAK;IAChB,MAAM0I,QAAQ,GAAGX,OAAO,CAAC/H,IAAI,EAAEgI,OAAO,CAAC;IACvC,MAAMW,QAAQ,GAAGD,QAAQ,KAAKJ,QAAQ;IACtCA,QAAQ,GAAGI,QAAQ;IACnB,IAAIE,QAAQ,GAAG5I,IAAI;IAEnB,IAAI2I,QAAQ,EAAE;MACZC,QAAQ,GAAG,CAACV,QAAQ,GAAGO,MAAM,CAACI,GAAG,EAAE,CAACvJ,KAAK,GAAGmJ,MAAM,CAACI,GAAG,EAAE,IAAID,QAAQ;IAC5E;IAEM,OAAOV,QAAQ,GACXO,MAAM,CAACK,MAAM,CAAC;MAAEP,IAAI,EAAEG,QAAQ;MAAEpJ,KAAK,EAAEsJ;IAAQ,CAAE,CAAC,GAClDH,MAAM,CAACK,MAAM,CAACF,QAAQ,CAAC;EACjC,CAAK,EACD,CAACR,OAAO,CACZ,CAAG;EACD,OAAOI,MAAM;AACf;AAEA,MAAMO,2BAA2B,GAAGA,CAAClJ,KAAK,EAAEmJ,OAAO,KAAKA,OAAO,IAAI,CAAC5C,MAAM,CAACvG,KAAK,CAAC,CAAC,CAAC,CAAC;AACpF,MAAMoJ,0BAA0B,GAAGA,CAACpJ,KAAK,EAAEmJ,OAAO,KAAK,CAACA,OAAO,IAAI,CAAC5C,MAAM,CAACvG,KAAK,CAACA,KAAK,CAACC,MAAM,GAAG,CAAC,CAAC,CAAC;AACnG,MAAMoJ,gBAAgB,GAAGA,CAACrJ,KAAK,EAAEsJ,UAAU,KACxCA,UAAU,IAAI,CAAC,CAAC,GAAGA,UAAU,CAAC,CAACvG,IAAI,CAAC6D,OAAO,CAAC,IAAM,CAAC0C,UAAU,IAAI/C,MAAM,CAACvG,KAAK,CAAE;;AAElF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASuJ,cAAcA,CAAA,EAAwD;EAAA,IAAvDvJ,KAAK,GAAAI,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAAA,IAAE;IAAE+I,OAAO,GAAG,KAAK;IAAEG,UAAU,GAAG;EAAE,CAAE,GAAAlJ,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,EAAE;EAC3E,IACE,CAAC6C,UAAU,CAACjD,KAAK,CAAC,IAClBkJ,2BAA2B,CAAClJ,KAAK,EAAEmJ,OAAO,CAAC,IAC3CC,0BAA0B,CAACpJ,KAAK,EAAEmJ,OAAO,CAAC,IAC1CE,gBAAgB,CAACrJ,KAAK,EAAEsJ,UAAU,CAAC,EACnC;IACA,OAAOtJ,KAAK;EAChB;EAEE,MAAMsI,KAAK,GAAGgB,UAAU,IAAItJ,KAAK;EACjC,MAAMwJ,cAAc,GAAG,IAAIC,MAAM,CAC/BN,OAAO,OAAAF,MAAA,CAAOb,QAAQ,CAACE,KAAK,CAAC,CAACE,KAAK,EAAE,OAAAS,MAAA,CAAQb,QAAQ,CAACE,KAAK,CAAC,CAACU,GAAG,EAAE,MACtE,CAAG;EACD,OAAOhJ,KAAK,CAAC0J,OAAO,CAACF,cAAc,EAAE,EAAE,CAAC;AAC1C;ACz8DA,IAAIG,QAAQ,GAAGC,GAAG;;AAElB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAASA,GAAGA,CAAA,EAAG;EACb,IAAIjB,MAAM,GAAG,EAAE;EACf,IAAIkB,IAAI,GAAGC,KAAK,CAACC,SAAS,CAAClK,KAAK,CAACD,IAAI,CAACQ,SAAS,CAAC;EAChD,IAAI4J,OAAO,GAAGH,IAAI,CAAC5J,MAAM;EACzB,IAAIgK,MAAM,GAAG,CAAC;EACd,IAAI3E,CAAC,EAAE4E,CAAC;EAER,IAAI,CAACF,OAAO,EAAE;IACZ,MAAM,IAAIG,KAAK,CAAC,oCAAoC,CAAC;EACzD;EAEE,KAAK7E,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG0E,OAAO,EAAE1E,CAAC,EAAE,EAAE;IAC5B,IAAI,CAACwE,KAAK,CAACM,OAAO,CAACP,IAAI,CAACvE,CAAC,CAAC,CAAC,EAAE;MAC3B,MAAM,IAAI6E,KAAK,CAAC,8BAA8B,CAAC;IACrD;IACI,IAAIE,MAAM,GAAGR,IAAI,CAACvE,CAAC,CAAC,CAACrF,MAAM;IAC3B,IAAIoK,MAAM,GAAGJ,MAAM,EAAE;MACnBA,MAAM,GAAGI,MAAM;IACrB;EACA;EAEE,KAAK/E,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG2E,MAAM,EAAE3E,CAAC,EAAE,EAAE;IAC3B,IAAIgF,KAAK,GAAG,EAAE;IACd,KAAKJ,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,OAAO,EAAEE,CAAC,EAAE,EAAE;MAC5B,IAAI,CAACJ,KAAK,CAACM,OAAO,CAACP,IAAI,CAACK,CAAC,CAAC,CAAC,EAAE;QAC3B,MAAM,IAAIC,KAAK,CAAC,8BAA8B,CAAC;MACvD;MACMG,KAAK,CAACJ,CAAC,CAAC,GAAGL,IAAI,CAACK,CAAC,CAAC,CAAC5E,CAAC,CAAC;IAC3B;IACIqD,MAAM,CAACrD,CAAC,CAAC,GAAGgF,KAAK;EACrB;EAEE,OAAO3B,MAAM;AACf;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,SAAS4B,WAATA,CAAA,EAAyD;EAApC,IAAAC,IAAoC,GAAApK,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAA7B,EAA6B;EAAzB,IAAAqK,OAAyB,GAAArK,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAf,EAAe;EAAX,IAAAsK,IAAW,GAAAtK,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAJ,EAAI;EAC9D,IAAMuK,QAAQ,GAAGC,SAAS,CAACF,IAAD,CAA1B,CAD8D;;EAG9D,IAAMG,gBAAgB,GAAGF,QAAQ,CAAC1K,MAAT,KAAoB,CAApB,IAAyB6K,kBAAA,CAAIN,IAAJ,EAAUpH,KAAV,CAAgBwD,OAAhB,CAAlD;EACM,IAAAmE,UAAU,GAAGD,kBAAI,CAAAN,IAAJ,EAAUpH,KAAV,CAAgBmD,MAAhB,CAAnB;EACA,IAAMyE,iBAAiB,GAAGF,kBAAI,CAAAL,OAAJ,EAAa1H,IAAb,CAAkByD,UAAlB,KAAiCsE,kBAAA,CAAIL,OAAJ,EAAa1H,IAAb,CAAkB0D,UAAlB,CAA3D;EAEA,IAAI+D,IAAI,KAAKC,OAAT,IAAoBM,UAAxB,EAAoC;IAClC,OAAO,CAAC,CAAC,EAAD,EAAKP,IAAL,CAAD,CAAP;EACD;EAED,IAAI,CAACE,IAAD,IAASG,gBAAT,IAA6BG,iBAAjC,EAAoD;IAClD,OAAOC,SAAS,CAACT,IAAD,EAAOC,OAAP,CAAhB;EACD;EAED,OAAOS,aAAa,CAACV,IAAD,EAAOG,QAAP,CAApB;AACD;AAED;AACA;AACA;AACA;AACA;AACA;;AACO,SAASM,SAATA,CAAA,EAA4C;EAAzB,IAAAT,IAAyB,GAAApK,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAlB,EAAkB;EAAd,IAAAqK,OAAc,GAAArK,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAJ,EAAI;;EACjD;EACA,IAAI0K,kBAAA,CAAIN,IAAJ,EAAUpH,KAAV,CAAgB,UAAC+H,CAAD;IAAA,OAAO,CAAC5E,MAAM,CAAC4E,CAAD,CAAd;EAAA,CAAhB,CAAJ,EAAwC;IACtC,OAAO,CAAC,CAACV,OAAD,EAAUD,IAAV,CAAD,CAAP;EACD;EAED,IAAAY,IAAA,GAA4B,CAC1BX,OAAO,CAAC5K,KAAR,CAAc,CAAd,EAAiB2K,IAAI,CAACvK,MAAL,GAAcsJ,cAAc,CAACiB,IAAD,EAAO;MAAErB,OAAO,EAAE;IAAX,CAAP,CAAd,CAAwClJ,MAAvE,CAD0B,EAE1BwK,OAAO,CAAC5K,KAAR,CAAc0J,cAAc,CAACkB,OAAD,EAAU;MAAEnB,UAAU,EAAEkB;IAAd,CAAV,CAAd,CAA8CvK,MAA5D,CAF0B,CAA5B;IAAOoL,MAAP,GAAAD,IAAA;IAAeE,SAAf,GAAAF,IAAA;EAKA,IAAMG,eAAe,GAAGnD,QAAQ,CAACoD,oBAAoB,CAAChB,IAAD,EAAOa,MAAP,EAAeC,SAAf,CAArB,CAAhC;EACI,IAAAG,iBAAiB,GAAGD,oBAAoB,CAACf,OAAD,EAAUY,MAAV,EAAkBC,SAAlB,CAA5C;EAEM,IAAAI,qBAAqB,GAAGjC,MAAM,CAClC8B,eAAe,CAACrH,GAAhB,CAAoB,UAACyH,KAAD;IAAW,OAAA/E,OAAO,CAAC+E,KAAD,CAAP,GAAgB,MAAhB,OAAA1C,MAAA,CAA6B0C,KAA7B,EAAX;EAAA,CAApB,CAAsE,CAAAC,IAAtE,CAA2E,EAA3E,CADkC,CAApC;EAdiD,IAAAC,KAAA,GAkBtBJ,iBAAiB,CAACK,KAAlB,CAAwBJ,qBAAxB,KAAkD,EAlB5B;EAAA,IAAAK,KAAA,GAAAC,QAAA,CAAAH,KAAA;EAkB3CJ,iBAlB2C,GAAAM,KAAA,CAAAlM,KAAA;EAoBjD,IAAMoM,GAAG,GAAGtC,QAAG,CAAC8B,iBAAD,EAAoBF,eAApB,CAAH,CAAwCrH,GAAxC,CAA4CgI,qBAA5C,CAAZ;EAEA,IAAIb,MAAJ,EAAY;IACVY,GAAG,CAACE,OAAJ,CAAY,CAAC,EAAD,EAAKd,MAAL,CAAZ;EACD;EAED,IAAIC,SAAJ,EAAe;IACbW,GAAG,CAACG,IAAJ,CAAS,CAAC,EAAD,EAAKd,SAAL,CAAT;EACD;EAED,OAAOW,GAAP;AACD;AAED,SAAST,oBAATA,CAAA,EAAqE;EAAvC,IAAAa,GAAuC,GAAAjM,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAjC,EAAiC;EAA7B,IAAA+I,OAA6B,GAAA/I,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAnB,EAAmB;EAAf,IAAAkM,QAAe,GAAAlM,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAJ,EAAI;EACnE,OAAOiM,GAAG,CAAC3C,OAAJ,CAAYD,MAAM,KAAAR,MAAA,CAAKE,OAAL,CAAlB,GAAmC,EAAnC,CAAuC,CAAAO,OAAvC,CAA+CD,MAAM,IAAAR,MAAA,CAAIqD,QAAJ,EAArD,OAAuE,EAAvE,CAAP;AACD;AAED,SAASJ,qBAATA,CAAqDK,KAAA;EAAA,IAAAC,KAAA,GAAAC,cAAA,CAAAF,KAAA;IAArB9B,OAAqB,GAAA+B,KAAA;IAAAE,MAAA,GAAAF,KAAA;IAAZhC,IAAY,GAAAkC,MAAA,cAAL,EAAK,GAAAA,MAAA;EACnD,OAAO,CAACjC,OAAD,IAAYA,OAAO,KAAKD,IAAxB,GAA+B,CAAC,EAAD,EAAKA,IAAL,CAA/B,GAA4C,CAACC,OAAD,EAAUD,IAAV,CAAnD;AACD;AAEM,SAASI,SAATA,CAAmB+B,IAAnB,EAAyB;EAC9B,OAAO,OAAOA,IAAP,KAAgB,QAAhB,GAA2BC,eAAe,CAACD,IAAD,CAA1C,GAAmDE,eAAe,CAACF,IAAD,CAAzE;AACD;AAED;AACA;AACA;AACA;AACA;;AACA,SAASE,eAATA,CAAA,EAAyC;EAAhB,IAAAC,SAAgB,GAAA1M,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAJ,EAAI;EACvC,OAAOV,MAAM,CAACgE,OAAP,CAAeoJ,SAAf,EAA0B5I,GAA1B,CAA8B,UAAA6I,KAAA;IAAA,IAAAC,KAAA,GAAAP,cAAA,CAAAM,KAAA;MAAEzM,KAAF,GAAA0M,KAAA;MAASC,OAAT,GAAAD,KAAA;IAAA,OAAsB,CACzD,CAACE,MAAM,CAAC5M,KAAD,CAAP,EAAgB4M,MAAM,CAAC5M,KAAD,CAAN,GAAgB,CAAhC,CADyD,EAEzD2M,OAFyD,CAAtB;EAAA,CAA9B,CAAP;AAID;AAED;AACA;AACA;AACA;AACA;;AACA,SAASL,eAATA,CAAA,EAAyC;EAAhB,IAAAE,SAAgB,GAAA1M,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAJ,EAAI;EAChC,OAAA0M,SAAS,CAAC9I,KAAV,CAAgB,GAAhB,EAAqBE,GAArB,CAAyB,UAACiJ,KAAD,EAAW;IACzC,IAAAC,YAAA,GAA2BD,KAAK,CAACnJ,KAAN,CAAY,GAAZ,CAA3B;MAAAqJ,aAAA,GAAAZ,cAAA,CAAAW,YAAA;MAAOE,OAAP,GAAAD,aAAA;MAAgBJ,OAAhB,GAAAI,aAAA;IACqB,IAAAE,kBAAA,GAAAD,OAAO,CAACtJ,KAAR,CAAc,GAAd,CAAmB,CAAAE,GAAnB,CAAuBgJ,MAAvB,CAArB;MAAAM,mBAAA,GAAAf,cAAA,CAAAc,kBAAA;MAAOjN,KAAP,GAAAkN,mBAAA;MAAcjN,GAAd,GAAAiN,mBAAA,IAFyC;IAIzC;IACA;;IACA,OAAO,CAAC,CAAClN,KAAD,EAAQC,GAAG,GAAGA,GAAG,GAAG,CAAT,GAAaD,KAAK,GAAG,CAAhC,CAAD,EAAqC2M,OAArC,CAAP;EACD,CAPM,CAAP;AAQD;AAED;AACA;AACA;AACA;AACA;AACA;;AACO,SAAS/B,aAATA,CAAA,EAAiD;EAA1B,IAAAV,IAA0B,GAAApK,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAnB,EAAmB;EAAf,IAAAuK,QAAe,GAAAvK,SAAA,CAAAH,MAAA,QAAAG,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAJ,EAAI;EAClD,IAAAqN,WAAW,GAAG,CAAlB;EAEO,OAAA9C,QAAQ,CAACjG,MAAT,CAAgB,UAACgJ,KAAD,EAAkCC,KAAA,EAAAC,KAAlC,EAAyCC,MAAzC,EAAoD;IAAA,IAAAC,KAAA,GAAArB,cAAA,CAAAkB,KAAA;MAAAI,MAAA,GAAAtB,cAAA,CAAAqB,KAAA;MAA1CxN,KAA0C,GAAAyN,MAAA;MAAnCxN,GAAmC,GAAAwN,MAAA;MAA7BC,QAA6B,GAAAF,KAAA;;IACzE;IACI,IAAAxN,KAAK,KAAKmN,WAAd,EAA2B;MACzBC,KAAK,CAACtB,IAAN,CAAW,CAAC,EAAD,EAAK5B,IAAI,CAAC3K,KAAL,CAAW4N,WAAX,EAAwBnN,KAAxB,CAAL,CAAX;IACD,CAJwE;;IAOzEoN,KAAK,CAACtB,IAAN,CAAW,CAAC4B,QAAD,EAAWxD,IAAI,CAAC3K,KAAL,CAAWS,KAAX,EAAkBC,GAAlB,CAAX,CAAX,EAPyE;;IAUzE,IAAIA,GAAG,GAAGiK,IAAI,CAACvK,MAAX,IAAqB,CAAC4N,MAAM,CAACD,KAAK,GAAG,CAAT,CAAhC,EAA6C;MAC3CF,KAAK,CAACtB,IAAN,CAAW,CAAC,EAAD,EAAK5B,IAAI,CAAC3K,KAAL,CAAWU,GAAX,CAAL,CAAX;IACD;IAEDkN,WAAW,GAAGlN,GAAd;IACA,OAAOmN,KAAP;EACD,CAhBM,EAgBJ,EAhBI,CAAP;AAiBD;AC7IM,SAASO,YAATA,CAAsBzD,IAAtB,EAA4BC,OAA5B,EAAqCC,IAArC,EAA2C;EACzC,OAAAwD,KAAK,CAACC,OAAN,CAAc;IAAA,OAAM5D,WAAW,CAACC,IAAD,EAAOC,OAAP,EAAgBC,IAAhB,CAAjB;EAAA,CAAd,EAAsD,CAACF,IAAD,EAAOC,OAAP,EAAgBC,IAAhB,CAAtD,CAAP;AACD;;;;;;ACDD,IAAM0D,YAAY,GAAG;EACnBC,OAAO,EAAE,aADU;EAEnBC,QAAQ,EAAE,UAFS;EAGnBC,UAAU;AAHS,CAArB;AAMA,IAAMC,SAAS,GAAG;EAChBH,OAAO,EAAE,aADO;EAEhBI,QAAQ,EAAE,MAFM;EAGhBC,UAAU,EAAE,GAHI;EAIhBJ,QAAQ,EAAE,eAJM;EAKhBK,cAAc,EAAE,UALA;EAMhBC,UAAU,EAAE,QANI;EAOhBC,SAAS,EAAE;AAPK,CAAlB;AAUA,IAAMC,SAAS,GAAG;EAChBT,OAAO,EAAE,OADO;EAEhBI,QAAQ,EAAE,OAFM;EAGhBM,aAAa,EAAE,SAHC;EAIhBC,MAAM,EAAE,SAJQ;EAKhBC,UAAU,EAAE,OALI;EAMhBC,aAAa,EAAE,OANC;EAOhB;EACAC,UAAU,EAAE,MARI;EAShBC,OAAO,EAAE;AATO,CAAlB;AAYA,IAAMC,SAAS,GAAG;EAChBhB,OAAO,EAAE;AADO,CAAlB;AAIO,SAASiB,OAATA,CAAsClE,IAAA;EAAnB,IAAAmE,KAAmB,GAAAnE,IAAA,CAAnBmE,KAAmB;IAATC,KAAS,GAAAC,wBAAA,CAAArE,IAAA,EAAAsE,SAAA;EACpC,oBAAAxB,KAAA,CAAAyB,aAAA,SAAAC,QAAA;IAAMC,IAAI,EAAC,IAAX;IAAgBN,KAAK,EAAAO,cAAA,CAAAA,cAAA,KAAO1B,YAAP,GAAwBmB,KAAxB;EAArB,GAA0DC,KAA1D,CAAP;AACD;AAEM,SAASO,IAATA,CAAmClE,KAAA;EAAnB,IAAA0D,KAAmB,GAAA1D,KAAA,CAAnB0D,KAAmB;IAATC,KAAS,GAAAC,wBAAA,CAAA5D,KAAA,EAAAmE,UAAA;EACjC,oBAAA9B,KAAA,CAAAyB,aAAA,SAAAC,QAAA;IAAMC,IAAI,EAAC,IAAX;IAAgBN,KAAK,EAAAO,cAAA,CAAAA,cAAA,KAAOtB,SAAP,GAAqBe,KAArB;EAArB,GAAuDC,KAAvD,CAAP;AACD;AAEM,SAASS,IAATA,CAAmClE,KAAA;EAAnB,IAAAwD,KAAmB,GAAAxD,KAAA,CAAnBwD,KAAmB;IAATC,KAAS,GAAAC,wBAAA,CAAA1D,KAAA,EAAAmE,UAAA;EACjC,oBAAAhC,KAAA,CAAAyB,aAAA,SAAAC,QAAA;IAAMC,IAAI,EAAC,IAAX;IAAgBN,KAAK,EAAAO,cAAA,CAAAA,cAAA,KAAOhB,SAAP,GAAqBS,KAArB;EAArB,GAAuDC,KAAvD,CAAP;AACD;AAEM,SAASW,IAATA,CAAmC5D,KAAA;EAAnB,IAAAgD,KAAmB,GAAAhD,KAAA,CAAnBgD,KAAmB;IAATC,KAAS,GAAAC,wBAAA,CAAAlD,KAAA,EAAA6D,UAAA;EACjC,oBAAAlC,KAAA,CAAAyB,aAAA,SAAAC,QAAA;IAAMC,IAAI,EAAC,IAAX;IAAgBN,KAAK,EAAAO,cAAA,CAAAA,cAAA,KAAOT,SAAP,GAAqBE,KAArB;EAArB,GAAuDC,KAAvD,CAAP;AACD;AAEM,SAASa,SAATA,CAAwE7D,KAAA;EAAnD,IAAAhC,IAAmD,GAAAgC,KAAA,CAAnDhC,IAAmD;IAA7CC,OAA6C,GAAA+B,KAAA,CAA7C/B,OAA6C;IAApCC,IAAoC,GAAA8B,KAAA,CAApC9B,IAAoC;IAA9B4F,QAA8B,GAAA9D,KAAA,CAA9B8D,QAA8B;IAApBC,MAAoB,GAAA/D,KAAA,CAApB+D,MAAoB;IAATf,KAAS,GAAAC,wBAAA,CAAAjD,KAAA,EAAAgE,UAAA;EACvE,IAAA9C,KAAK,GAAGO,YAAY,CAACzD,IAAD,EAAOC,OAAP,EAAgBC,IAAhB,CAA1B;EAEA,OAAO,OAAO6F,MAAP,KAAkB,UAAlB,GACLA,MAAM,CAAC;IAAE7C,KAAK,EAALA;EAAF,CAAD,CADD,gBAGLQ,KAAC,CAAAyB,aAAA,CAAAL,OAAD,EAAaE,KAAb,EACG9B,KAAK,CAACxJ,GAAN,CAAU,UAAA6I,KAAA,EAAmBa,KAAnB,EAA6B;IAAA,IAAAZ,KAAA,GAAAP,cAAA,CAAAM,KAAA;MAA3BiB,QAA2B,GAAAhB,KAAA;MAAjByD,IAAiB,GAAAzD,KAAA;IACtC,IAAM0D,aAAa,GAAGD,IAAI,GAAG7C,KAA7B;IAEA,oBACEM,KAAA,CAAAyB,aAAA,CAACI,IAAD;MAAMY,GAAG,EAAED;IAAX,GACGJ,QAAQ,iBAAIpC,KAAC,CAAAyB,aAAA,CAAAM,IAAD,EAAO,MAAAjC,QAAP,CADf,eAEEE,KAAC,CAAAyB,aAAA,CAAAQ,IAAD,EAAO,MAAAM,IAAP,CAFF,CADF;EAMD,CATA,CADH,CAHF;AAgBD;AAEDJ,SAAS,CAACO,YAAV,GAAyB;EACvBpG,IAAI,EAAE,EADiB;EAEvBC,OAAO,EAAE,EAFc;EAGvBC,IAAI,EAAE,EAHiB;EAIvB4F,QAAQ,EAAE;AAJa,CAAzB"},"metadata":{},"sourceType":"module"}